[{"title":"Kafa重复消费与消息丢失解决方案","url":"/2023/03/28/Kafa重复消费与消息丢失解决方案/","content":"\n# kafka的重复消费与消息丢失解决方案\n\n　　在使用kafka的过程中或者面试的过程中，kafka的消息重复消费问题和消息丢失问题都是比较重要的方面，这里记录一下重复消费和消息丢失的解决方案，不讲具体原理。\n\n<!-- more -->\n\n- 重复消费：\n\n  出现重复消费的场景主要有两种：一种是 Consumer 在消费过程中，应用进程被强制kill掉或者发生异常退出（挂掉…），另一种则是Consumer消费的时间过长。\n\n  - 针对消费端挂掉等原因导致重复消费：\n\n    - 对消息增加标识，可以保存在第三方介质中，例如：Redis，MySQL中，在处理数据之前先判断第三方介质中是否已经存在这个标识了\n\n    - 将版本号（offset）存到消息中，在处理消息的的时候用这个版本号做乐观锁，只有当前版本号大于之前的版本号才能继续处理。\n\n  - 针对 Consumer 消费时间过长导致的重复消费：\n\n    - 提高单条消息的处理速度，比如对消息处理比较耗时是就可以采用异步处理或者多线程的方式处理消息\n    - 根据实际场景可将 `max.poll.interval.ms` (等待新消息最大时长)值设置大一点，避免不必要的rebalance，此外可适当减小 `max.poll.records` (一次拉取消息条数)的值，默认值是500，可根据实际消息速率适当调小。\n\n- 消息丢失：\n\n  消息丢失的场景在生产端和消费端都会发生，这里分别说怎么处理\n\n  - 生产端：：\n\n    - 通过设置ACK模式来解决。0、1、-1三种模式。\n      1. 0：不进行消息确认\n      2. 1：leader确认即可\n      3. -1：leader 和 follower 都要确认\n    - 引入重试机制，设置重试次数和重试间隔\n    - 采用集群，kafka的多副本机制可以保证集群的可靠新，当 leader 宕机后，会有新的 follower 选举晋升为leader\n\n  - 消费端：\n\n    　　消费端出现消息丢失问题的主要场景就是消费消息的过程中出现了异常，但是此时 offset 已经提交了，这就导致了消息丢失，这个问题也好解决，可以用下面的解决方案：\n\n    - kafka 的 offset 提交分为 自动 和 手动 两种，而引起消息丢失大概率是因为自动提交了 offset，我们可已将 offset 设置为手动提交，在我们消费完消息，处理完业务之后在进行提交 offset 的操作。\n","tags":["kafka"],"categories":["技术问题","kafka"]},{"title":"SpringCloudAlibaba-Seata分布式事务","url":"/2023/03/26/SpringCloudAlibaba-Seata分布式事务/","content":"\n# 一、什么是Seata\n\n　　Seata是一款开源的分布式事务解决方案，提供分布式框架的分布式事务处理，为用户提供了 AT，TCC，SAGA和XA事务模式，为用户打造一站式的分布式事务解决方案\n\n<!-- more -->\n\n　　在了解分布式事务之前我们要先了解一个协议，就是**2PC** 两阶段提交协议，目前市面上面的多种分布式解决方案也都是采用了这种协议，那什么是 **2PC** 两阶段提交协议呢。\n\n　　**2PC** 就是将事务的提交分为两个阶段：**perpare**（预处理）、**commit**（提交）两个阶段。\n\n　　在分布式事务中会先由事务协调者进行预处理阶段，就是先向事务的参与者发出通知，事务的的参与者接到通知后会进行预处理判断是否满足提交事务的条件，预处理后会返回给事务协调者一个应答。当所有的参与者都处理完成并回复应答就会进行下一个阶段，也就是提交或回滚的阶段\n\n![图片加载失败](1.png)\n\n# 二、Seata的三大角色\n\n1. **TC(Transaction coordinator) - 事务协调者**\n\n   维护全局和分支事务的状态，驱动全局事务提交或回滚\n\n2. **TM(Transaction Manager) - 事务管理器**\n\n   定义全局事务的范围：开始、提交、回滚全局事务\n\n3. **RM(Resource Manager) - 资源管理器**\n\n   管理分支实物处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚\n\n<font color=\"red\">其中，TC 为单独部署的 Server 服务端，TM和RM为嵌入到应用中的 Client 客户端</font>\n\n# 三、AT模式与TCC模式\n\n## 1、AT模式（auto transcation）\n\n　　AT 模式是一种无入侵的分布式事务解决方案，阿里Seata框架实现了该模式。\n\n　　在 AT 模式下，用户只需要关注自己的 “业务SQL”，用户的“业务SQL”作为第一阶段，Seata框架会自动生成事务的二阶段提交和回滚操作。\n\n### 1.一阶段\n\n　　在一阶段，Seata会拦截“业务SQL”，首先解析 SQL 语义，找到“业务SQL”要更新的业务数据，在业务数据被更新前，将其保存成一个“before image”，然后执行“业务SQL”更新业务数据，在业务数据被更新后，再将其保存成“after image”，最后生成一个行锁，避免其他业务操作读取到这条数据。以上操作全部在一个数据库事务中完成，这样保证了一阶段提交原子性。\n\n　　这就是一阶段提交，可以理解为在一阶段就已经将我们想要执行的SQL执行了，不过是同时保存了SQL执行前后的数据快照以及行锁。执行前后的快照数据就是保证数据的回滚、提交。行锁则是因为我们的SQL已经执行了，但是整个分布式事务还未完成，防止其他事务读取。\n\n![图片加载失败](2.png)\n\n### 2.二阶段提交\n\n　　二阶段如果是提交的话，因为“业务SQL”在一阶段已经提交至数据库，所以 Seata 框架只需要将一阶段保存的快照数据和行锁删除掉，就完成数据清理即可。\n\n![图片加载失败](3.png)\n\n### 3.二阶段回滚\n\n　　二阶段如果是回滚的话，Seata 就需要回滚一阶段已经执行的“业务SQL”，还原业务数据。回滚的方式就是使用一阶段中创建的“before image”快照数据来还原业务数据；但是还原之前要先校验脏写，对比“数据库当前业务数据”与“before image”，如果两份数据完全一致就证明没有脏写，可以还原业务数据，如果不一致就证明又脏写，出现脏写就需要转人工处理了。\n\n　　其实脏写基本上是不可能发生的，因为在一阶段中执行“业务SQL“后已经进行了行锁的操作。\n\n![图片加载失败](4.png)  \n\n## 2、TCC模式（Try Confirm Cancel）\n\n### 1.二阶段提交处理\n\n　　TCC 模式需要用户根据自己的业务场景实现Try、Confirm 和 Cancel 三个操作；事务发起方在第一阶段执行 Try 方式，在第二阶段提交执行 Confirm 方法，二阶段回滚执行 Cancel 方法。\n\n　　就是 TCC 模式就是在第一阶段会通知所有事务的参与者尝试执行，准备所需资源。第二阶段执行业务修改数据库，发生错误进行回滚，回复已修改数据库。\n\n　　例如：支付订单与减库存的业务场景\n\n- 一阶段：将订单的状态修改为 “支付中”，库存服务记录需要减少的库存数量\n- 二阶段：\n  - 提交：将订单的状态修改为 “已支付”，库存服务则减少相应的库存数量\n  - 取消：如果在一阶段或者二阶段提交的业务处理中发生错误，则进行回滚操作，也就是将订单状态恢复，将已经减少的库存加回去或者清空一阶段中记录的需要减少的库存数量。\n\n![图片加载失败](5.png)\n","tags":["Seata"],"categories":["技术学习","SpringCloudAlibaba","Seata"]},{"title":"Sentinel&Nacos注册为Linux服务","url":"/2023/03/26/Sentinel-Nacos注册为Linux服务/","content":"\n# 一、环境准备\n\n因为每次启动服务器/虚拟机都要重新启动Nacos和Sentinel等一堆东西，所以为了方便将Nacos和Sentinel注册为Linux的服务，并设置开机自启。\n\n首先我们在我们的服务器上面准备以下文件：\n\n- Nacos\n- Sentinel\n\n<!-- more -->\n\n# 二、编写Nacos.service与Sentinel.service文件\n\n首先我们需要在`/usr/lib/systemd/system/`目录下创建如下服务文件\n\nNacos.service文件如下：\n\n~~~shell\n[Unit]\nDescription=Nacos service\nAfter=network.target\n\n[Service]\nPrivateTmp=true\nRestart=on-failure\nRestartSec=5\nType=forking\nExecStart=/bin/bash /home/nacos/bin/startup.sh  #启动命令 启动脚本换成自己对应的目录即可\nExecStop=/bin/bash /home/nacos/bin/shutdown.sh #停止命令 停止脚本换成自己对应的目录即可\n\n[Install]\nWantedBy=multi-user.target\n~~~\n\nSentinel.service\n\n~~~shell\n[Unit]\nDescription=Sentinel-Dashboard service\nAfter=network.target\n\n[Service]\nPrivateTmp=true\nRestart=always\nRestartSec=5\nExecStart=/usr/software/jdk-11.0.14/bin/java -Dserver.port=8858 -Dproject.name=sentinel-dashboard -jar /home/sentinel-dashboard/sentinel-dashboard-1.8.6.jar  #启动命令\nExecStop=/usr/bin/kill -15  $MAINPID #停止命令\n\n[Install]\nWantedBy=multi-user.target\n~~~\n\n这里要注意一下，service文件中的Java环境为你自己服务器中的jdk绝对目录\n\n# 三、启动服务并设置开机自启\n\n1. 启动服务执行以下命令：\n\n   `systemctl start nacos.service`\n\n   `systemctl start sentinel.service`\n\n2. 停止服务执行以下命令：\n\n   `systemctl stop nacos.service`\n\n   `systemctl stop sentinel.service`\n\n3. 设置服务开机自启执行以下命令：\n\n   `systemctl enable nacos.service`\n\n   `systemctl enable sentinel.service`\n\n4. 关闭服务开启自启执行以下命令：\n\n   `systemctl disable nacos.service`\n\n   `systemctl disable sentinel.service` \n\n如果对服务文件进行了编辑，在编辑后需要执行以下命令重新加载服务文件：\n\n`systemctl daemon-reload nacos.service`\n\n`systemctl daemon-reload sentinel.service`\n\n\n\n查看服务日志使用以下命令：\n\n`journalctl -f -u 服务名`\n\n-f 参数为滚动实时打印日志，如果不需要可以不加。\n","tags":["Linux服务注册"],"categories":["Linux","服务注册"]},{"title":"SpringCloudAlibaba-Sentinel服务高可用","url":"/2023/03/05/SpringCloudAlibaba-Sentinel服务高可用/","content":"\n# 一、什么是Sentinel\n\nSentinel是Alibaba开源的，面向分布式服务架构的高可用组件。其拥有多维度的流控降级能力，主要以流量为切入点，从限流、流量整形、熔断降级、系统负载保护、热点防护等多个维度来帮助开发者稳定微服务的稳定性。我们可以通过[官网](https://github.com/alibaba/Sentinel/wiki/)的文档了解到更多。\n\n<!--more-->\n\n# 二、依赖引入配置\n\n这里只是使用了单纯的Sentinel，并没有整合SpringCloudAlibaba，后面会写到整合到SpringCloudAlibaba框架的项目中。\n\n1. 依赖引入\n\n   ~~~xml\n   <!-- sentinel -->\n   <dependency>\n       <groupId>com.alibaba.csp</groupId>\n       <artifactId>sentinel-core</artifactId>\n   </dependency>\n   <!-- 使用sentinel的注解 -->\n   <dependency>\n       <groupId>com.alibaba.csp</groupId>\n       <artifactId>sentinel-annotation-aspectj</artifactId>\n   </dependency>\n   ~~~\n\n2. 如果要使用Sentinel的注解还需要将SentinelResourceAspect类型的bean加入到spring的容器中\n\n   ~~~java\n   /**\n    * @ClassName SentinelConfig\n    * @Description\n    * @Author sunyu\n    * @Date 2023/3/6 21:56\n    * @Version 1.0\n    **/\n   @Component\n   public class SentinelConfig {\n   \n   \n       /**\n        * @Description 配置启动Sentinel的注解\n        * @Author sy\n        * @Date 2023/3/6\n        * @Version 1.0\n        **/\n       @Bean\n       public SentinelResourceAspect sentinelResourceAspect() {\n           return new SentinelResourceAspect();\n       }\n   }\n   ~~~\n\n   \n\n# 三、基于代码控流和降级的示例\n\n这里只演示简单的流控和降级的代码示例，值得注意的是 **流控规则一般在被调用端** 而 **熔断降级规则一般在调用端**\n\n```java\n/**\n * @ClassName SentinelContoller\n * @Description Sentinel 流控实例\n * @Author sunyu\n * @Date 2023/3/5 20:32\n * @Version 1.0\n **/\n@Slf4j\n@RestController\n@RequestMapping(value = \"/sentinel\")\npublic class SentinelController {\n\n    private static final String RESOURCE_NAME = \"hello\";\n\n    private static final String USER_RESOURCE_NAME = \"user\";\n\n    private static final String DEGRADE_RESOURCE_NAME = \"degrade\";\n\n    /**\n     * @Description 测试流控接口\n     * @Author sy\n     * @Date 2023/3/6\n     * @Version 1.0\n     **/\n    @GetMapping(\"/hello\")\n    public String hello() {\n        Entry entry = null;\n        try {\n            // sentinel 针对资源进行的限制\n            entry = SphU.entry(RESOURCE_NAME);\n            String result = \"Hello World!\";\n            log.info(result);\n            return result;\n        } catch (BlockException e) {\n            // 自愿访问组织，被限流或被降级\n            // 进行相应的处理操作\n            log.info(\"被限流了\");\n            return \"被流控了！\";\n        } catch (Exception e) {\n            // 若需要配置降级规则，需要通过这种方式记录业务异常\n            Tracer.traceEntry(e, entry);\n        }finally {\n            if (entry != null) {\n                entry.exit();\n            }\n        }\n        return null;\n    }\n\n\n    /**\n     * @Description 测试流控注解接口\n     * @SentinelResource 改善接口中资源定义和被流控降级后的处理方法\n     * value: 定义的资源名称\n     * blockHandler: 被流控降级后的处理方法(默认该方法必须生命在同一个类中)（优先级高于fallback）\n     * blockHandlerClass: 可以将处理方法放到别的类中\n     * fallback: 异常的处理方法\n     * fallbackClass: 可以异常的处理方法放在白的类中\n     * ExceptionsToIgnore：排除异常不被fallback拦截\n     * @Author sy\n     * @Date 2023/3/6\n     * @Version 1.0\n     **/\n    @GetMapping(\"/user\")\n    @SentinelResource(value = USER_RESOURCE_NAME, blockHandler = \"blockHandleForUser\")\n    public String user(String id) {\n        log.info(\"user:\" + id);\n        return \"user\";\n    }\n\n    /**\n     * @Description 被流控后的处理方法，该方法必须是由public声明的，入参与返回值要与原方法一致\n     * @Author sy\n     * @Date 2023/3/6\n     * @Version 1.0\n     **/\n    public String blockHandleForUser(String id, BlockException e) {\n        e.printStackTrace();\n        log.info(\"user被流控了\");\n        return \"user被流控了\";\n    }\n\n\n    /**\n     * @Description 测试熔断降级接口\n     * @Author sy\n     * @Date 2023/3/6\n     * @Version 1.0\n     **/\n    @GetMapping(\"/degrade\")\n    @SentinelResource(value = DEGRADE_RESOURCE_NAME, entryType = EntryType.IN, blockHandler = \"blockHandleForDegrade\")\n    public String degrade() {\n        int s = 1 / 0;\n        return \"degrade\";\n    }\n\n    /**\n     * @Description 被熔断降级后的处理方法，该方法必须是由public声明的，入参与返回值要与原方法一致\n     * @Author sy\n     * @Date 2023/3/6\n     * @Version 1.0\n     **/\n    public String blockHandleForDegrade(BlockException e) {\n        e.printStackTrace();\n        log.info(\"user被熔断了\");\n        return \"user被熔断了\";\n    }\n\n\n    /**\n     * @Description 初始化流控规则\n     * @PostConstruct 注解是Spring的注解，作用就是当当前类被加载的时候就会初始化当前这个方法\n     * @Author sy\n     * @Date 2023/3/5\n     * @Version 1.0\n     **/\n    @PostConstruct\n    private static void initFlowRules() {\n        // 流控规则\n        List<FlowRule> rules = new ArrayList<>();\n        // 定义流控对象\n        FlowRule ruleHello = new FlowRule();\n        // 设置受保护的资源\n        ruleHello.setResource(RESOURCE_NAME);\n        // 设置流控规则策略 QPS/线程数\n        ruleHello.setGrade(RuleConstant.FLOW_GRADE_QPS);\n        // 阈值\n        ruleHello.setCount(1);\n        rules.add(ruleHello);\n\n        // 为使用@SentinelResouce注解的接口定义流控规则\n        // 定义流控对象\n        FlowRule ruleUser = new FlowRule();\n        // 设置受保护的资源\n        ruleUser.setResource(USER_RESOURCE_NAME);\n        // 设置流控规则策略 QPS/线程数\n        ruleUser.setGrade(RuleConstant.FLOW_GRADE_QPS);\n        // 阈值\n        ruleUser.setCount(1);\n        rules.add(ruleUser);\n        // 加载配置好的规则\n        FlowRuleManager.loadRules(rules);\n\n    }\n\n    /**\n     * @Description 初始化降级规则\n     * @Author sy\n     * @Date 2023/3/6\n     * @Version 1.0\n     **/\n    @PostConstruct\n    public void initDegradeRule() {\n        List<DegradeRule> list = new ArrayList<>();\n        // 定义降级规则对象\n        DegradeRule degradeRule = new DegradeRule();\n        // 定义降级规则资源\n        degradeRule.setResource(DEGRADE_RESOURCE_NAME);\n        // 设置熔断降级的策略：异常数   多种策略：慢调用策略、异常比例、异常数策略\n        degradeRule.setGrade(RuleConstant.DEGRADE_GRADE_EXCEPTION_COUNT);\n        // 阈值\n        degradeRule.setCount(2);\n        // 熔断时长  熔断过后会进入半开状态，回复调用的第一次调用就发生异常的话会直接进行熔断，不会根据这里的配置进行判断\n        degradeRule.setTimeWindow(10);\n        // 熔断触发的最小请求数，请求数小于该值时即使异常比率超出阈值也不会熔断\n        degradeRule.setMinRequestAmount(2);\n        // 间隔时长，可以理解为触发异常需要在这个时间间隔内\n        degradeRule.setStatIntervalMs(60 * 1000);\n        list.add(degradeRule);\n\n        // 加载降级规则\n        DegradeRuleManager.loadRules(list);\n\n    }\n\n}\n```\n\n到这里简单的通过代码方式定义流控和熔断降级规则的示例就完成了，可以通过调用下面的接口测试：\n\n- 基于catch的方式捕获流控：xxxxxxxx/hello\n- 基于@SentinelResource 的方式捕获流控：xxxxxxx/user\n- 熔断降级：xxxxxxx/degrade\n\n# 四、整合到SpringCloudAlibaba架构的项目中\n\n这里可以参考SpringCloudAlibaba的[官方文档](https://github.com/alibaba/spring-cloud-alibaba/wiki/Sentinel)来做\n\n## 1、引入依赖\n\n这里先将我们之前引入的依赖注释掉，在加入👇🏻的依赖，在测试一下依然是可以实现上面的流控和熔断降级规则的。\n\n~~~xml\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>\n</dependency>\n~~~\n\n## 2、加入Sentinel 控制台\n\n我们可以从[sentinel tag页面](https://github.com/alibaba/Sentinel/tags)获取到想要的版本\n\n1. 通过一下命令启动sentinel dashboard服务，可以根据我们的实际情况修改端口，更多用法及参数可以查看[sentinel-dashboard文档](https://github.com/alibaba/Sentinel/wiki/%E6%8E%A7%E5%88%B6%E5%8F%B0)\n\n   ~~~java\n   java -Dserver.port=8858 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard.jar\n   ~~~\n\n   访问8858端口就可以进入到控制台页面了\n\n   ![图片加载失败](1.png)\n\n## 3、将服务注册进入到Sentinel控制台中\n\n一共有两种方式，分别是通过启动参数配置和通过yml文件配置\n\n1. 通过启动参数配置：在启动参数中添加`-Dcsp.sentinel.dashboard.server=sentinel服务的ip:8858`\n\n   ![图片加载失败](2.png)\n\n   当我们启动后会发现服务并没有注册到Sentinel的控制台中，这时我们只需要访问几次要注册进去的服务的接口，你就会发现服务已经注册到Sentinel中了\n\n   ![图片加载失败](3.png)\n\n2. 通过yml配置：在yml中添加👇🏻配置，这里要注意client-ip的不要写错，我就因为没有写和写成了Sentinel服务端的ip导致应用服务注册不到Sentinel，卡了一晚上\n\n   ```yaml\n   spring:\n     cloud:\n       sentinel:\n         transport:\n           # 客户端ip，就是你要注册进Sentinel的服务的所在ip\n           client-ip: 192.168.0.101\n           # Sentinel控制ip端口\n           dashboard: 192.168.0.107:8858\n         # 服务启动自动注册到Sentinel的服务端\n         eager: true\n   ```\n   \n   ![图片加载失败](4.png)\n\n# 五、整合OpenFeign\n\n## 1、添加相关依赖\n\n```xml\n<!--nacos服务注册发现-->\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n</dependency>\n<!-- openfeign -->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-openfeign</artifactId>\n</dependency>\n<!-- sentinel -->\n<dependency>\n<groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>\n    <version>${alibaba.sentinel.version}</version>\n</dependency>\n```\n\n上面三个依赖是必须的。\n\n## 2、配置yml配置文件\n\n开启OpenFeign对Sentinel的支持\n\n~~~yml\nfeign:\n  sentinel:\n    enabled: true\n~~~\n\n## 3、实现你的OpenFeign接口类\n\n~~~java\n@Component\npublic class StockSentinelFallback implements Stock{\n    @Override\n    public String reduceStock() {\n        return null;\n    }\n\n    @Override\n    public String reduceStock2() {\n        return \"降级了2\";\n    }\n}\n~~~\n\n## 4、修改对应的OpenFeign接口类\n\n只需要在`@FeignClient`注解中增加fallback入参即可，指定实现类\n\n~~~java\n@FeignClient(name = \"stock\", path = \"/stock\", fallback = StockSentinelFallback.class)\npublic interface Stock {\n\n    /**\n     * @Description 这里的接口就与调用的Controller里面的接口一直就可以了，其实将对应的接口复制过来就可以了，只不过是没有实现的\n     * @Author sy\n     * @Date 2023/3/5\n     * @Version 1.0\n     **/\n    @PostMapping(value = \"/reduceStock\")\n    public String reduceStock();\n\n    @PostMapping(value = \"/reduceStock2\")\n    public String reduceStock2();\n}\n~~~\n\n上面的代码中`/reduceStock2`是用于做降级熔断测试的接口，所以在测试类中只写了reduceStock2的返回值。\n\n\n\n\n\n# 问题记录\n\n1. 本地服务无法注册到服务器的Sentinel dashboard中\n\n   这个问题可能有以下几种原因，这里只写我遇到的：\n\n   - `yml`配置文件中的 `client-ip` 配置项没有配置或者配置错误，这个配置项在上面有提到过，是配置你的服务所在ip，如果Sentinel dashboard和服务是在一台机器启动的则可以忽略这个配置\n\n   - 版本对应的问题，我一直以为官方的版本对应应该是没有问题的。各种怀疑自己的配置或者网络问题。突然想起版本对应才发现这个问题，`spring-cloud-alibaba-dependencies:2.2.9.RELEASE`对应`spring-cloud-starter-alibaba-sentinel:2.2.8.RELEASE`，这个是经过我不懈测试后可以正常将服务注册到Sentinel dashboard中的版本\n\n     \n","tags":["Sentinel"],"categories":["技术学习","SpringCloudAlibaba","Sentinel"]},{"title":"SpringCloudAlibaba-OpenFeign的引入及使用","url":"/2023/03/05/SpringCloudAlibaba-OpenFegin的引入及使用/","content":"\n# 一、OpenFeign是什么\n\n 　　 OpenFeign是SpringCloud对Fegin的封装升级，包含了SpringMVC，Ribbon等功能，可以使用SpringMVC的相关注解，通常我们在调用别的服务的接口的时候分别都是使用HttpClient或者RestTemplate等通过指定URL地址等操作去调用别的服务的接口。在微服务中，我们可以通过引入OpenFeign组件实现更方便的服务间的调用，最简单的就是可以通过指定其他服务的名字来调用相应接口。\n\n<!--more-->\n\n# 二、引入依赖以及配置\n\n1. 首先我们在我们想要使用的服务下面引入依赖\n\n   ~~~xml\n   <dependency>\n       <groupId>org.springframework.cloud</groupId>\n       <artifactId>spring-cloud-starter-openfeign</artifactId>\n   </dependency>\n   ~~~\n\n2. 在启动类上面加上启用OpenFeign的注解：`@EnableFeignClients`\n\n3. 配置打印日志调用日志的配置类\n\n   ~~~java\n   /**\n    * @Description\n    * OpenFeign配置类\n    * 如果加了@Configuration注解则为全局配置，所有Feign接口都有效\n    * 如果想要实现局部配置，则不需要配置@Configuration注解，在想要启用这个配置的Feign接口上面指定这个配置类\n    * @Author sy\n    * @Date 2023/3/5\n    * @Version 1.0\n    **/\n   @Configuration\n   public class FeignConfig {\n   \n       /** \n        * @Description 日志级别\n        * @Author sy\n        * @Date 2023/3/5\n        * @Version 1.0\n        **/\n       @Bean\n       public Logger.Level feignLoggerLevel() {\n           return Logger.Level.FULL;\n       }\n   }\n   ~~~\n\n4. 配置yml配置文件\n\n   ```yaml\n   logging:\n     level:\n       # 指定对应包的日志级别\n       com.sy.springcloud.service.openFeign: debug\n   ```\n\n   \n\n# 三、实际使用\n\n```java\n/**\n * @Description\n * feign接口\n * name：对应的调用的服务的实例名称\n * path：对应的调用的接口的地址，就是对应的Controller指定的@RequestMapping()配置的地址\n * configuration = FeignConfig.class，可以加入这个配置，这个配置用于这个接口使用的feign配置类，就是局部配置的时候使用的\n * @Author sy\n * @Date 2023/3/5\n * @Version 1.0\n **/\n@FeignClient(name = \"stock\", path = \"/stock\")\npublic interface Stock {\n\n    /**\n     * @Description 这里的接口就与调用的Controller里面的接口一直就可以了，其实将对应的接口复制过来就可以了，只不过是没有实现的\n     * @Author sy\n     * @Date 2023/3/5\n     * @Version 1.0\n     **/\n    @PostMapping(value = \"/reduceStock\")\n    public String reduceStock();\n}\n```\n\n到这里，最基本的配置使用可以了。后面还会增加更多使用的配置\n\n\n\n# 四、契约模式\n\n　　将OpenFeign的注解还原成原生注解，使用场景：例如我们的项目是一个早期版本的SpringCloud，当你想要对框架进行升级，那么由于早期的框架使用的是Feign组件，当你升级后要使用的是OpenFegin组件，就会出现兼容性的问题，那这里就可以使用这个契约模式去指定某些接口使用原生注解。这里可以通过多种配置方式来实现，我们这里就演示简单的两种分别是全局模式与局部模式：\n\n1. 全局模式：还是可以通过配置类来实现\n\n   ```java\n   @Configuration\n   public class FeignConfig {\n   \n       /**\n        * @Description 日志级别\n        * @Author sy\n        * @Date 2023/3/5\n        * @Version 1.0\n        **/\n       @Bean\n       public Logger.Level feignLoggerLevel() {\n           return Logger.Level.FULL;\n       }\n   \n       /**\n        * @Description 契约模式，将OpenFeign注解还原成原生注解，基本不会使用到\n        * @Author sy\n        * @Date 2023/3/5\n        * @Version 1.0\n        **/\n       @Bean\n       public Contract feignContract() {\n           return new Contract.Default();\n       }\n   }\n   ```\n\n2. 通过yml的方式来配置局部\n\n   ```yaml\n   # feign局部配置\n   feign:\n     client:\n       config:\n         # 对应的服务名称\n         stock:\n           # 日志级别\n           logger-level: basic\n           # 契约模式，还原Feign原生注解\n           contract: feign.Contract.Default\n   ```\n\n# 五、超时时间\n\n可以配置连接超时时间，与请求处理超时时间\n\n1. 通过配置类配置\n\n   ```java\n   /**\n    * @Description\n    * OpenFeign配置类\n    * 如果加了@Configuration注解则为全局配置，所有Feign接口都有效\n    * 如果想要实现局部配置，则不需要配置@Configuration注解，在想要启用这个配置的Feign接口上面指定这个配置类\n    * @Author sy\n    * @Date 2023/3/5\n    * @Version 1.0\n    **/\n   @Configuration\n   public class FeignConfig {\n   \n       /**\n        * @Description 日志级别\n        * @Author sy\n        * @Date 2023/3/5\n        * @Version 1.0\n        **/\n       @Bean\n       public Logger.Level feignLoggerLevel() {\n           return Logger.Level.FULL;\n       }\n   \n       /**\n        * @Description 契约模式，将OpenFeign注解还原成原生注解，基本不会使用到\n        * @Author sy\n        * @Date 2023/3/5\n        * @Version 1.0\n        **/\n       @Bean\n       public Contract feignContract() {\n           return new Contract.Default();\n       }\n   \n       /**\n        * @Description 超时时间配置，第一个参数配置的是连接超时时间，第二个参数配置的是请求处理超时时间\n        * @Author sy\n        * @Date 2023/3/5\n        * @Version 1.0\n        **/\n       @Bean\n       public Request.Options options() {\n           return new Request.Options(5000, 10000);\n       }\n   }\n   ```\n\n2. 通过yml配置文件配置\n\n   ~~~yml\n   # feign局部配置\n   feign:\n     client:\n       config:\n         # 对应的服务实例名称\n         stock:\n           # 日志级别\n           logger-level: basic\n           # 契约模式，还原Feign原生注解\n           contract: feign.Contract.Default\n           # 连接超时时间配置\n           connect-timeout: 5000\n           # 请求处理超时时间配置\n           read-timeout: 10000\n   ~~~\n\n   \n","tags":["OpenFegin"],"categories":["技术学习","SpringCloudAlibaba","OpenFegin"]},{"title":"SpringCloudAlibaba-Ribbon负载均衡","url":"/2023/02/27/SpringCloudAlibaba-Ribbon负载均衡/","content":"\n# \t一、什么要进行负载均衡\n\n负载均衡就是为避免所有请求都打到一个服务器上面，导致服务器异常儿产生的服务不可问题。\n\n下面我们就来自定负载均衡的策略，我这边实现的只有一下三种，但是实际上根据业务需求的不同会产生各种均衡策略：\n\n- 根据权重随机选择一个实例\n- 优先选择同集群\n- 优先选择同版本同集群的示例（金丝雀发布---实现同版本同集群优先负载均衡策略）\n\n<!--more--> \n\n# 二、自定义负载均衡策略\n\n这里我先将我的目录放在这里，下面是各种实现\n\n![图片加载失败](1.png)\n\n### 第一步：自定义一个负载均衡的配置类\n\n这里使用我们自定义的全局配置类\n\n```java\npackage com.sy.springcloud.config.ribbon;\n\n\nimport com.sy.ribbon.GlobalRibbonConfig;\nimport org.springframework.cloud.netflix.ribbon.RibbonClients;\nimport org.springframework.context.annotation.Configuration;\n\n@Configuration\n@RibbonClients(defaultConfiguration = GlobalRibbonConfig.class)\npublic class CustomeRibbonConfig {\n}\n\n```\n\n### 第二步：在我们的全局配置类中配置我们想要使用的自定义的负载均衡策略\n\n```java\npackage com.sy.ribbon;\n\nimport com.netflix.loadbalancer.IRule;\nimport com.sy.springcloud.config.ribbon.rule.TheSameClusterPriorityRule;\nimport com.sy.springcloud.config.ribbon.rule.TheSameClusterPriorityWithVersionRule;\nimport com.sy.springcloud.config.ribbon.rule.WeightedBalancerRule;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.stereotype.Component;\n\n/**\n * 全局负载均衡配\n */\n@Component\npublic class GlobalRibbonConfig {\n\n    @Bean\n    public IRule iRule() {\n        // 实现带有权重的负载均衡策略\n        return new WeightedBalancerRule();\n        // 实现同集群优先的负载均衡策略\n        //return new TheSameClusterPriorityRule();\n        // 实现同版本同集群优先的负载均衡策略（必须同版本，可以不同集群）\n        //return new TheSameClusterPriorityWithVersionRule();\n    }\n\n}\n\n```\n\n### 第三步：自定义我们的负载均衡策略\n\n#### 第1种类型：根据权重随机选择一个实例\n\n~~~ java\npackage com.sy.springcloud.config.ribbon.rule;\n\nimport com.alibaba.cloud.nacos.NacosServiceManager;\nimport com.alibaba.cloud.nacos.ribbon.NacosServer;\nimport com.alibaba.nacos.api.naming.NamingService;\nimport com.alibaba.nacos.api.naming.pojo.Instance;\nimport com.netflix.client.config.IClientConfig;\nimport com.netflix.loadbalancer.AbstractLoadBalancerRule;\nimport com.netflix.loadbalancer.BaseLoadBalancer;\nimport com.netflix.loadbalancer.Server;\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.beans.factory.annotation.Autowired;\n\n/**\n * 根据权重随机选择一个实例\n */\n@Slf4j\npublic class WeightedBalancerRule extends AbstractLoadBalancerRule {\n\n    @Autowired\n    private NacosServiceManager nacosServiceManager;\n    @Override\n    public void initWithNiwsConfig(IClientConfig iClientConfig) {\n\n    }\n\n    @Override\n    public Server choose(Object o) {\n        try {\n            log.info(\"key:{}\",o);\n            // 调用父类方法，获得当前使用的均衡负载器\n            BaseLoadBalancer loadBalancer = (BaseLoadBalancer) this.getLoadBalancer();\n            // 获取目标服务的名称\n            String serviceName = loadBalancer.getName();\n            // 获取nacos的服务发现的API\n            NamingService namingService = nacosServiceManager.getNamingService();\n\n            // 根据名称获取服务发现实例，在selectOneHealthyInstance中，nacos实现了权重的负载均衡算法\n            Instance instance = namingService.selectOneHealthyInstance(serviceName);\n\n            return new NacosServer(instance);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return null;\n    }\n}\n\n~~~\n\n#### 第2种类型：优先选择同集群\n\n~~~java\npackage com.sy.springcloud.config.ribbon.rule;\n\n\nimport com.alibaba.cloud.nacos.NacosDiscoveryProperties;\nimport com.alibaba.cloud.nacos.NacosServiceManager;\nimport com.alibaba.cloud.nacos.ribbon.NacosServer;\nimport com.alibaba.nacos.api.naming.NamingService;\nimport com.alibaba.nacos.api.naming.pojo.Instance;\nimport com.netflix.client.config.IClientConfig;\nimport com.netflix.loadbalancer.AbstractLoadBalancerRule;\nimport com.netflix.loadbalancer.BaseLoadBalancer;\nimport com.netflix.loadbalancer.Server;\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.beans.factory.annotation.Autowired;\n\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.stream.Collectors;\n\n/**\n * 同集群优先调用--负载均衡策略\n */\n@Slf4j\npublic class TheSameClusterPriorityRule extends AbstractLoadBalancerRule {\n\n    @Autowired\n    private NacosServiceManager nacosServiceManager;\n\n    @Autowired\n    private NacosDiscoveryProperties nacosDiscoveryProperties;\n\n\n    @Override\n    public void initWithNiwsConfig(IClientConfig iClientConfig) {\n\n    }\n\n    @Override\n    public Server choose(Object o) {\n        try {\n            // 获取服务所在的集群名称\n            String clusterName = nacosDiscoveryProperties.getClusterName();\n            log.info(\"当前集群名称：{}\", clusterName);\n            // 获取当前的负载均衡器\n            BaseLoadBalancer loadBalancer = (BaseLoadBalancer) this.getLoadBalancer();\n            // 获取目标服务的实例名称\n            String serviceName = loadBalancer.getName();\n            log.info(\"目标服务的实例名称：{}\", serviceName);\n            // 获取nacos服务注册发现的api\n            NamingService namingService = nacosServiceManager.getNamingService();\n            // 通过namimgService获取当前注册的所有实例\n            List<Instance> allInstance = namingService.getAllInstances(serviceName);\n\n            List<Instance> sameClusterInstanceList;\n            // 过滤筛选同集群下的服务实例\n            sameClusterInstanceList = allInstance.stream().filter(instance -> instance.getClusterName().equals(clusterName)).collect(Collectors.toList());\n            log.info(\"统计群的服务实例：{}\", sameClusterInstanceList);\n            Instance toBeChooseInstance;\n            // 选择合适的服务实例\n            if (sameClusterInstanceList == null || sameClusterInstanceList.size() == 0) {\n                // 从其他集群中随机选择一个服务实例\n                toBeChooseInstance = WeightedBalancer.chooseInstanceByRandomWeight(allInstance);\n                log.info(\"跨集群调用---{}\", toBeChooseInstance.getPort());\n            } else {\n                // 从本集群中随机选择一个服务实例\n                toBeChooseInstance = WeightedBalancer.chooseInstanceByRandomWeight(sameClusterInstanceList);\n                log.info(\"同集群调用---{}\", toBeChooseInstance.getPort());\n            }\n            return new NacosServer(toBeChooseInstance);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n\n        return null;\n    }\n}\n\n~~~\n\n这里以及下一种类型会用到一个类，这个类的作用是根据在符合的实例中随机选择一个\n\n~~~java\npackage com.sy.springcloud.config.ribbon.rule;\n\nimport com.alibaba.nacos.api.naming.pojo.Instance;\nimport com.alibaba.nacos.client.naming.core.Balancer;\n\nimport java.util.List;\n\n/**\n * 根据权重随机选择一个实例\n */\npublic class WeightedBalancer extends Balancer {\n    public static Instance chooseInstanceByRandomWeight(List<Instance> instanceList) {\n        return getHostByRandomWeight(instanceList);\n    }\n}\n\n~~~\n\n#### 第3种类型：同版本同集群优先择负载均衡策略\n\n这个策略也可以叫做金丝雀发布策略：灰度测试的场景下可以使用\n\n~~~java\npackage com.sy.springcloud.config.ribbon.rule;\n\n\nimport com.alibaba.cloud.nacos.NacosDiscoveryProperties;\nimport com.alibaba.cloud.nacos.NacosServiceManager;\nimport com.alibaba.cloud.nacos.ribbon.NacosServer;\nimport com.alibaba.nacos.api.naming.NamingService;\nimport com.alibaba.nacos.api.naming.pojo.Instance;\nimport com.netflix.client.config.IClientConfig;\nimport com.netflix.loadbalancer.AbstractLoadBalancerRule;\nimport com.netflix.loadbalancer.BaseLoadBalancer;\nimport com.netflix.loadbalancer.Server;\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.beans.factory.annotation.Autowired;\n\nimport java.util.List;\nimport java.util.stream.Collectors;\n\n/**\n * 同版本同集群优先调用--负载均衡策略（金丝雀/灰度测试）\n * 1、优先同版本同集群的服务调用\n * 2、没有 条件1的，同版本跨集群的服务调用\n * 3、不可以进行不同版本的服务调用\n */\n@Slf4j\npublic class TheSameClusterPriorityWithVersionRule extends AbstractLoadBalancerRule {\n\n    @Autowired\n    private NacosServiceManager nacosServiceManager;\n\n    @Autowired\n    private NacosDiscoveryProperties nacosDiscoveryProperties;\n\n\n    @Override\n    public void initWithNiwsConfig(IClientConfig iClientConfig) {\n\n    }\n\n    @Override\n    public Server choose(Object o) {\n        try {\n            // 获取服务所在的集群名称\n            String clusterName = nacosDiscoveryProperties.getClusterName();\n            // 获取服务的版本号\n            String version = nacosDiscoveryProperties.getMetadata().get(\"version\");\n            log.info(\"当前集群名称：{},服务版本号：{}\", clusterName, version);\n            // 获取当前的负载均衡器\n            BaseLoadBalancer loadBalancer = (BaseLoadBalancer) this.getLoadBalancer();\n            // 获取目标服务的实例名称\n            String serviceName = loadBalancer.getName();\n            log.info(\"目标服务的实例名称：{}\", serviceName);\n            // 获取nacos服务注册发现的api\n            NamingService namingService = nacosServiceManager.getNamingService();\n            // 通过namimgService获取当前注册的所有实例\n            List<Instance> allInstance = namingService.getAllInstances(serviceName);\n\n            // 过滤筛选同版本的服务\n            List<Instance> sameVersionInstance;\n            sameVersionInstance = allInstance.stream().filter(instance -> instance.getMetadata().get(\"version\").equals(version)).collect(Collectors.toList());\n\n\n            // 过滤筛选同版本下的同集群的服务实例\n            List<Instance> sameClusterInstanceList;\n            sameClusterInstanceList = sameVersionInstance.stream().filter(instance -> instance.getClusterName().equals(clusterName)).collect(Collectors.toList());\n            log.info(\"统计群的服务实例：{}\", sameClusterInstanceList);\n            Instance toBeChooseInstance;\n            // 选择合适的服务实例（必须同版本）\n            if (sameClusterInstanceList == null || sameClusterInstanceList.size() == 0) {\n                // 从所有同版本的服务实例中选一个\n                toBeChooseInstance = WeightedBalancer.chooseInstanceByRandomWeight(sameVersionInstance);\n                log.info(\"跨集群调用---{}\", toBeChooseInstance.getPort());\n            } else {\n                // 从本集群中随机选择一个服务实例\n                toBeChooseInstance = WeightedBalancer.chooseInstanceByRandomWeight(sameClusterInstanceList);\n                log.info(\"同集群调用---{}\", toBeChooseInstance.getPort());\n            }\n            return new NacosServer(toBeChooseInstance);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n\n        return null;\n    }\n}\n\n~~~\n\n三种配置到这里就完事了，接下来就可以在Nacos中配置权重与版本号进行测试了\n","tags":["Ribbon"],"categories":["技术学习","SpringCloudAlibaba","Ribbon"]},{"title":"Docker部署Nginx","url":"/2023/02/22/Docker部署Nginx/","content":"\n# 前言\n\n在上一篇中使用Docker部署了Nacos，Nacos在集群下是需要Nginx进行代理，负载均衡的。所以就有了这一遍帖子。\n\n<!-- more -->\n\n## 1、拉取 Nginx 镜像\n\n使用`docker pull nginx`命令拉取 Nginx 镜像\n\n## 2、创建挂载目录\n\n1. 创建配置文件目录\n\n   `mkdir -p /home/nginx/conf`\n\n2. 创建站点目录\n\n   `mkdir -p /home/nginx/html`\n\n3. 创建Nginx日志目录\n\n   `mkdir -p /home/nginx/log`\n\n## 3、将容器中的配置文件等复制到宿主机对应目录中\n\n1. 启动 nginx 容器\n\n   `docker run --name nginx -p 80:80 -d nginx`\n\n2. 将容器中的 nginx.conf 文件复制到宿主机的挂载目录中\n\n   `docker cp nginx:/etc/nginx/nginx.conf /home/nginx/conf/`\n\n3. 将容器中的 conf.d 文件复制到宿主机的挂载目录中\n\n   `docker cp nginx:/etc/nginx/conf.d /home/nginx/conf/`\n\n4. 将容器中的 html 文件复制到宿主机的挂载目录中\n\n   `docker cp nginx:/usr/share/nginx/html /home/nginx/html/`\n\n## 4、创建启动脚本\n\n执行以下命令启动 Nginx 容器：\n\n```shell\ndocker run --name nginx -p 5000:80 \\ \n       -v /home/nginx/conf/nginx.conf:/etc/nginx/nginx.conf \\ \n       -v /home/nginx/conf/conf.d:/etc/nginx/conf.d \\ \n       -v /home/nginx/log:/var/log/nginx \\ \n       -v /home/nginx/html:/usr/share/nginx/html \\ \n       -d nginx\n```\n\n## 5、设置代理\n\n将以下配置配置到nginx.conf配置文件的http下即可\n\n```properties\n\t\t\t\tupstream nacoscluster {\n                server 192.168.0.107:8848;\n                server 192.168.0.108:8848;\n                server 192.168.0.109:8848;\n        }\n\n        server {\n                listen 80;\n                server_name localhost;\n\n                location /nacos/{\n                        proxy_pass http://nacoscluster/nacos/;\n                }\n        }\n\n```\n\n\n\n","tags":["Nginx"],"categories":["技术学习","SpringCloudAlibaba"]},{"title":"Docker部署Nacos","url":"/2023/02/21/Docker部署Nacos/","content":"\n# 前言\n\n　　因为最近在准备面试，也在学习一些技术，目前正在看 SpringCloudAlibaba 这一套框架，在进行 Nacos 集群部署的时候感觉每次都要解压什么的太麻烦了，所以决定直接用 Docker 去进行部署。这篇文章也会一点点慢慢完善的。好了，话不多说👇🏻就要开始了\n\n<!-- more -->\n\n## 1、拉取 Nacos 镜像\n\n 执行 `docker pull nacos/nacos-server:v2.1.0` 命令拉取nacos镜像\n\n## 2、在本机创建nacos容器需要挂载的目录\n\n![图片加载失败](1.png)\n\n## 3、编写nacos的配置文件\n\n这里的配置文件不是修改容器内的配置文件，而是编辑挂载目录中的配置文件：\n\n1. 在conf目录下执行`vim application.properties` 命令编写配置文件\n\n2. 在配置文件中添加一下内容，这里可以根据你需要的配置进行修改，只添加自己需要的就好，就会覆盖掉容器内对应的配置\n\n   mysql：nacos数据库脚本：[nacos-db.sql](nacos-db.sql)\n\n   ```properties\n   #*************** Config Module Related Configurations ***************#\n   ### If use MySQL as datasource:\n   spring.datasource.platform=mysql\n   \n   ### Count of DB:\n   db.num=1\n   #连接mysql8.0数据库\n   ### Connect URL of DB:\n   db.url.0=jdbc:mysql://这里填写你数据的ip:3306/nacos?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useUnicode=true&useSSL=false&serverTimezone=UTC&useSSL=false\n   db.user.0=root\n   db.password.0=root\n   ```\n\n\n## 4、到这里就配置好了，可以使用命令进行启动了\n\n执行以下命令启动nacos容器：\n\n```dockerfile\ndocker  run --name nacos -p 8848:8848 \\\n        --privileged=true \\\n        --restart=always \\\n        -e JVM_XMS=128m \\\n        -e JVM_XMX=128m \\\n        -e MODE=standalone \\\n        -e PREFER_HOST_MODE=ip \\\n        -v /home/nacos/logs:/home/nacos/logs \\\n        -v /home/nacos/conf/application.properties:/home/nacos/conf/application.properties \\\n        -d nacos/nacos-server:v2.1.0\n\n```\n\n这里我们指定了 `-e MODE=stanalone` 参数，这个参数的含义是单机启动，如果是集群启动，这里需要进行修改。\n\n这条命令我们可以保存为一个shell脚本，需要的时候执行就可以了。\n\n## 5、Nacos 集群\n\n首先你需要三台虚拟机，或者直接在一台机器上面启动三个端口不通Nacos容器。\n\n1. 将 Nacos 启动模式修改为集群 `-e MODE=cluster`\n\n2. 增加集群节点 `-e NACOS_SERVERS=\"192.168.0.108:8848 192.168.0.109:8848\"`这里的ip、端口根据自己的环境进行配置即可。\n\n","tags":["Nacos"],"categories":["技术学习","SpringCloudAlibaba"]},{"title":"面试记录、问题","url":"/2022/11/25/面试记录、问题/","content":"\n# 2022-11-25-1（三方支付）\n\n## 1、i++是否是线程安全11\n\n<!-- more -->\n\n如果是<font color=\"red\">全局变量</font>，则 `i++` 不是线程安全的。因为java在处理 `i++` 的时候是分步操作的，编译后相当于 `i= i+1`。这样的话如果第一条线程执行进来，但是还没有执行到 `i++` 的时候，第二条线程进来了，这个时候 i 的值还是原来的值。所以是线程不安全的。\n\n解决方案：使用 `synchronization` 或者使用 `AtomicInteger`.\n\n## 2、线程不安全会有什么问题\n\n会造成数据紊乱，导致业务数据错误等。例如抢票，如果线程不安全则会发生票数错误，多个人抢了票，但是剩余票数只减1，这种问题。\n\n## 3、线程池创建方式及主要参数\n\n线程池的创建主要有两种：\n\n1. 通过Executors创建，分别可以创建：\n\n   - FixedThreadPool(5) 固定大小的线程池，可以指定并发数量。超过则在队列中等待。\n   - CachedThreadPool() 可缓存线程池，若线程数超过处理所需，则会在缓存一段时间后被回收。如果线程不够则会创建新的线程。\n   - SingleThreadPool() 创建单个线程的线程池，保证了先进先出的顺序。\n   - ScheduledThreadPool() 可以执行延时任务的线程池\n   - SingleThreadScheduledExecutor() 创建一个单线程的可执行延时任务的线程池\n   - WorkStealingPool() 创建一个抢占式执行的线程池（任务执行顺序不确定）\n\n2. 通过 ThreadPoolExecutor 创建，也是阿里规范中推荐使用的方式，因为他可以明确线程池的规则，避免了资源耗尽等问题\n\n   主要参数：\n\n   - corePoolSize：核心线程数，一直保持存活的线程数。当线程数小于核心线程数的时候，即使有空闲线程，来了新任务也会创建新的线程处理。\n\n   - maxPoolSize：最大线程数。当线程数 >= 核心线程数，且队列已满，则会创建新的线程处理。当线程数 = 最大线程数的时候，则会拒绝任务并抛出异常，这个可以根据拒绝策略决定处理方式。\n\n   - keepAliveTime：线程空闲时间，当线程的空闲时间达到设定值的时候会退出，直到线程数量 = 核心线程数为止。如果设置了allowCoreThreadTimeout = true，则核心线程也会超时退出。\n\n   - TimeUnit：时间单位\n\n   - BlockQueue：任务队列，可指定容量，当核心线程数达到最大的是后，再来新的任务则会放在这个队列中等待\n\n   - ThreadFactory：线程工厂\n\n   - reJectedExecutionHandler：任务拒绝处理器。\n\n     两种情况会拒绝处理任务：\n\n     - 当线程数达到最大线程数，且队列已满，怎会拒绝新任务\n     - 当线程池的 shutdown() 被调用的时候，会等待队列中的任务执行完毕，再shutdown。如果在调用 shutdown 和线程池真正shutdwon之间进来新任务，则会拒绝。\n\n     ThreadPoolExecutor有几个自己的内部实现来处理：\n\n     - AbortPolicy：默认值，丢弃任务，抛运行时异常\n     - CallerRunsPolicy：创建新线程执行任务\n     - DiscardPolicy：忽视，什么都不管\n     - DiscarOldestPolicy：从队列中踢出最先进入（最后一个执行）的任务\n     - 还可以实现ReJectedExecutionHandler来自定义拒绝策略。\n\n## 4、如何解决sql慢查询\n\n1. 数据库创建是否适合，例如：根据表涉及的业务选择不同的存储引擎，数据量的大小考虑是否需要分库分表\n2. 主键是否自增类型，否则可能会引发页面分裂和记录迁移\n3. 是否过多的表关联查询，根据阿里规范来说是建议不要超过三张表的关联查询\n4. 创建索引，这里并不是说创建的索引越多越好，也要考虑到一下几种情况\n   - 表涉及的业务是否会频繁发生变化，毕竟数据修改是要涉及到构建索引的\n   - 创建的索引是否命中\n   - 尽量使用联合索引，要考虑最左匹配原则\n   - 索引失效\n     - 最左匹配原则为满足\n     - 计算、函数、类型转换都会导致索引失效\n     - 不等于也会导致索引失效\n     - is null 可以使用索引，但是is not null 就无法使用索引\n     - like 通配符以左模糊查询会导致索引失效\n     - or 关键字前后只要存咋非索引的列都会导致索引失效 \n5. 考虑全表扫描问题，如果只是查询一条数据的话就可以加上 `limit 1` 使查询到就立即返回，不进行全表扫描\n6. 使用代码来进行处理，必要的情况下可以多次查询，之后在处理数据\n\n## 5、什么情况下会发生锁表问题\n\n锁表主要发生在 insert、update、delete中\n\n1. A程序执行了对tabbleA的insert，还没有commite时，B程序也对tableA进行了insert，这样就会发生锁表的问题\n2. 锁表常发生在并发的情况而不是并行，并行时，一个线程操作数据库，另一个线程是不能操作数据库的，这里是cpu的 i/o 分配原则\n\n怎么减少锁表的发生概率：\n\n减少insert、update、delete语句的执行到commite之间的时间，具体说就是批量执行尽量改成单个执行\n\n## 6、频繁FullGC会产生什么问题，怎么引起的，怎么解决\n\n1. ","tags":["Java 面试"],"categories":["Java 面试题"]},{"title":"Docker学习","url":"/2021/08/26/Docker学习/","content":"\n# 一、环境准备\n\n- linux系统，本人使用的是centos8，最小化安装\n\n<!-- more -->\n\n# 二、安装\n\n1. 下载 **docker** 脚本\n\n   - 可以通过 [get.docker](https://get.docker.com/) 下载 **docker** 的安装脚本\n\n     ![图片加载失败](1.png)\n\n   - 直接通过 ``curl -fsSL get.docker.com -o get-docker.sh`` 命令下载 **docker** 脚本\n\n     ![图片加载失败](2.png)\n\n2. 执行脚本\n\n   ![图片加载失败](3.png)\n\n3. 验证\n\n   - 执行 ``docker version`` 查看 **docker** 版本\n\n     ![图片加载失败](4.png)\n\n     在上图中我们可以看到 **docker** 的版本等信息，并且可以看到 **docker** 没有连接。这是因为没有启动 **docker** 的服务\n\n   - 执行 ``systemctl start docker`` 启动 **docker** 的服务\n\n     ![图片加载失败](5.png)\n\n     启动后我们已经可以看到 **docker** 的服务的相关信息了\n\n到这里，**docker** 就已经安装完成了\n\n# 三、容器的快速上手\n\n## 1、docker 的命令行\n\n- 我们可以通过 ``docker`` 命令查看都有什么可以执行的命令\n\n  ![图片加载失败](6.png)\n\n- **docer** 命令行的结构:\n\n  ```shell\n  docker 想要操作的对象\n  ```\n\n  例如：\n\n  - 我们可以输入 ``docker container --help`` 查看都有什么可以执行的命令\n\n    ![图片加载失败](7.png)\n\n    ```shell\n    # 列出当前运行的容器\n    docker container ls\n    \n    # 列出所有容器\n    docker container ls -a\n    ```\n\n  - 我们也可以输入 ``docker container ls --help`` 来查看都有什么参数\n\n    ![图片加载失败](8.png)\n\n    **Aliases：**ls 可以替换成什么\n\n    **Options：**可以使用的参数选项\n\n\n## 2、docker 的镜像 VS 容器\n\n### 1.**image** 镜像\n\n- **Docker image** 是一个 **read only** 文件\n- 这个文件包含文件系统，源码，库文件，依赖，工具等一些运行 **application** 所需要的文件\n- 可以理解成一个模板\n- **Docker image** 具有分层的概念\n\n### 2.**container** 容器\n\n- 可以理解成：“一个运行中的 **docker image**” \n- 实质是复制 **image** 并在 **image** 最上层加上一层 **read write** 的层（称之为 **container layer**，容器层）\n- 基于同一个 **image** 可以创建多个 **container**\n\n### 3.docker image 的获取\n\n- 自己制作\n- 从 **registry** 拉取（比如 **docker hub**）\n\n## 3、容器的基本操作\n\n### 1.创建一个容器\n\n我们可以通过 `docker container run [image_REPOSITORY]` 来创建一个容器\n\n![图片加载失败](9.png)\n\n这里我们可以看到已经成功运行了，我们可以重新打开一个窗口查看一下正在运行的 **container**。\n\n![图片加载失败](10.png)\n\n\n\n### 2.停止容器\n\n我们可以通过 `docker container stop [IDs or NAMES]` 或者 `ctrl + c` 来停止一个容器\n\n**注意：**在 **windows** 中使用 `ctrl + c`并不能停止容器，实际上还是在后台运行的\n\n![图片加载失败](11.png)\n\n### 3.重新启动停止的容器\n\n我们可以通过 `docker container start [IDs or NAMES]` 来重新启动容器 \n\n![图片加载失败](15.png)\n\n### 4.删除容器\n\n我们可以通过 `docker container rm [IDs or NAMES]` 来删除一个容器\n\n首先，我们查看所有容器：\n\n![图片加载失败](12.png)\n\n我们可以看到，这里有一个已经停止了的容器，接下来我们删除掉这个容器，再查看一遍\n\n![图片加载失败](13.png)\n\n通过上图我们可以看到容器已经被删除了。\n\n## 4、容器的两种模式（attached、detached）\n\n### 1.attached\n\n这里我们使用 `docker container run -p 80:80 nginx` 来创建一个容器，`-p 80:80` 的意思是将容器的内部端口映射到外部端口上。\n\n![图片加载失败](19.png)\n\n我们可以看到已经启动成功了。\n\n接下来，我们在浏览器访问一下虚拟机的 **80** 端口\n\n![图片加载失败](20.png) \n\n![图片加载失败](21.png)\n\n可以看到，可以成功访问，并且已经打印了相关日志 \n\n<font color=\"red\">其实，attached 模式就是，我们的命令会与容器共享。就像我们在 linux 或者 mac 的系统上创建一个 docker 容器后，会显式的显示在窗口中，当我们执行 `ctrl + c` 后，容器也会停止，这就是 attached 模式</font>\n\n### 2.detached\n\n这里我们使用 `docker container run -d -p 80:80 nginx` 来创建一个容器。其中 `-d` 是指使用 **detached** 模式启动。\n\n![图片加载失败](22.png)\n\n这里我们可以看到，我们只能看到容器的 **id**，并不能看到相关一些信息，也可以看到容器已经成功自动了。\n\n接下来，我们在浏览器访问一下虚拟机的 **80** 端口，就可以看到相关的日志信息并没有打印。\n\n如果，我现在想 **attach** 到容器中该怎么做呢？\n\n我们可以执行 **docker container attach [id or names]**，来 **attach** 到我们的容器。\n\n![图片加载失败](23.png)\n\n通过上图我们可以看到已经成功 **attach** 到我们的容器中了\n\n如果我们不想 **attach** 到我们的容器中，并且还想看日志怎么办呢？\n\n这时，我们可以执行 `docker container logs -f [ids or NAMES]` 来查看日志。**-f** 是动态的跟踪我们的日志\n\n![图片加载失败](24.png)\n\n## 5、容器的交互模式\n\n1. 我们创建一个 **ubuntu** 容器\n\n   ```shell\n   # -it 是指交互式的模式\n   # sh 执行的命令，就是进入到交互式的 ubuntu 的命令行\n   docker container run -it ubuntu sh\n   ```\n\n   ![图片加载失败](25.png)\n\n   这里我们可以看到已经进入到了 **ubuntu** 的命令行了。\n\n   当我们执行 **exit** 退出后，在查看容器运行情况，可以看到 **ubuntu** 这个容器已经退出了。\n\n   ![图片加载失败](26.png)\n\n2. 交互式的进入到已经启动的容器中\n\n   ```shell\n   # exec 执行\n   # -it 交互模式\n   # sh 命令行\n   docker container exec -it 79 sh\n   ```\n\n   这里可以看到我们已经进来了。\n\n   ![图片加载失败](27.png)\n\n   这个时候我们再次执行 **exit**，并查看容器的启动情况。\n\n   ![图片加载失败](28.png)\n\n   这是因为，我们只是退出了交互式的shell，并不影响这个容器。<font color=\"red\">因为我们交互式的创建一个容器和交互式的进入某个容器是不一样的</font>\n\n## 6、容器和虚拟机的区别（Container vs VM）\n\n![图片加载失败](29.png)\n\n虚拟机是在 **hypervisor** 虚拟化层上创建一整个操作系统，而容器是在 **Container Engine** 容器引擎上的程序，就是一个进程。\n\n**容器不是Mini虚拟机：**\n\n- 容器其实是进程\n- 容器中的进程被限制了对 **CPU** 内存等资源的访问\n- 当进程结束后，容器就退出了。\n\n通过 `docker container top [id name]` 来查看容器运行了那些进程\n\n![图片加载失败](30.png)\n\n使用 `pstree -halps id` 查看进程的依赖关系，使用 `yum install psmisc` 或者 `apt-get install psmisc` 安装\n\n![图片加载失败](31.png)\n\n![图片加载失败](32.png)\n\n## 7、docker container run 容器创建的背后发生了什么？\n\n`docker container run -d -p 80:80 --name test nginx`\n\n1. 在本地查找是否有 **nginx** 这个 **image** 镜像，但是发现没有\n2. 去远程的 **image registry** 查找 **nginx** 镜像（默认的 **registry** 是 **Docker Hub**）\n3. 下载最新版的 **nginx** 镜像（**nginx:latest** 默认）\n4. 基于 **nginx** 镜像来创建一个新的容器，并准备运行\n5. **docker engine** 分配个这个容器一个虚拟的 **IP** 地址\n6. 在宿主机上打开 80 端口并把容器的 80 端口转发到宿主机上\n7. 启动容器，运行指定的命令\n\n# 四、镜像的创建使用管理和发布\n\n## 1、镜像的获取\n\n- `pull from registry(online)` 从 **registry** 拉取\n  - **public** 公有\n  - **private** 私有\n- `build from Dockerfile(online)` 从 **Dockerfile** 构建\n- `load from file(offline)` 文件导入（离线）\n\n[Dockerhub 官网](https://hub.docker.com/)、[Red Hat quay](recovery.quay.io)\n\n## 2、镜像的获取\n\n### 1.在 dockerhub 或 quay.io 获取\n\n1. 我们先看到一下 **image** 都有哪些命令\n\n   ![图片加载失败](33.png)\n\n2. **pull** 拉取镜像\n\n   - 在 **Docker hub** 找到要拉取的镜像，执行命令拉取即可。\n\n     ![图片加载失败](34.png)\n\n     这里我们可以看到要执行的命令是：`docker pull nginx`，这是早期版本的命令，建议使用：`docker image pull nginx`\n\n   - 我们还可以拉取别的版本的\n\n     ![图片加载失败](35.png)\n\n     这里我们使用：`docker image pull nginx:1.20.1` 就可以拉取了。\n\n3. 查看某个镜像的详细信息\n\n   使用 `docker image inspect imageID` 即可\n\n4. 删除\n\n   使用 `docker image rm imageID` 即可。\n\n   <font color=\"red\">需要注意的是，如果镜像有某个容器在使用的话是无法删除的。我必须删除掉使用的容器再能删除</font>\n\n### 2.导入导出方式\n\n1. 导出\n\n   我们可以再别的电脑或者环境中保存一个镜像的文件。\n\n   ```shell\n   # nginx:1.20.1 要保存的镜像以及版本，如果不添加版本默认latest版本\n   # -o 是指 output 输出\n   # nginx.image 保存的文件名字\n   docker image save nginx:1.20.1 -o nginx\n   ```\n\n   ![图片加载失败](36.png)\n\n2. 导入\n\n   我们先把 1.20.1 版本的删除掉，在进行导入查看\n\n   ![图片加载失败](37.png)\n\n   ```shell\n   # -i 是指 input 输入\n   docker image load -i nginx\n   ```\n\n   ![图片加载失败](38.png)\n\n### 3.Dockerfile 方式\n\n#### 1）什么是 Dockerfile?\n\n- 是用于构建 **docker** 镜像的文件\n- 包含了构建镜像所需的指令\n- 有特定的语法规则\n\n#### 2）举例：执行一个 Python 程序\n\n假如我们要在一台 **ubuntu 21.04** 上运行下面这个 **hello.py** 的 **Python** 程序\n\n**hello.py** 的文件内容：\n\n```python\nprint(\"hello docker\")\n```\n\n第一步，准备 **Python** 的环境\n\n```shell\napt-get update && /\nDEBIAN_FRONTEND=noninteractive apt-get install --no-install-recommends -y python3.9 python3-pip python3.9-dev\n```\n\n第二步，运行 **hello.py**\n\n```shell\n$ python3 hello.py\n输入：hello docker\n```\n\n#### 3）一个 Dockerfile 的基本结构\n\n1. **Dockerfile**\n\n   ```dockerfile\n   # 引入 ubuntu:21.04 镜像\n   FROM ubuntu:21.04\n   # 执行命令安装 python 的环境\n   RUN apt-get update && \\\n   \tDEBIAN_FRONTEND=noninteractive apt-get install --no-install-recommends -y python3.9 python3-pip python3.9-dev\n   # 将本地的 hello.py 文件添加到 / 根目录下\n   ADD hello.py /\n   # 执行命令\n   CMD [\"python3\",\"/hello.py\"]\n   ```\n\n   详细可见 [Dockerfile 官方文档](https://docs.docker.com/engine/reference/builder/)\n\n   ![图片加载失败](39.png)\n\n2. **通过 Dockerfile 构建镜像**\n\n   由于我的 **centos** 是一台虚拟机，并且没有做桥接，所以在 **centos** 中拉下来的镜像网络不通无法进行 **apt-get update**，所以在我的另一台 **kali** 系统的电脑上进行的测试，<font color=\"red\">并且后续所有测试都在 **kali** 上进行</font>\n\n   - 首先我们先将 **hello.py** 和 **Dockerfile** 准备好\n\n     ![图片加载失败](40.png)\n\n   - 通过 `docker image build` 进行构建\n\n     ```shell\n     # -f DockerFile 的名字\n     # -t 构建后镜像名称\n     # . 当前目录下\n     docker image build -t hello .\n     \n     docker image build -f DockfileName -t Tag .\n     ```\n     \n     ![图片加载失败](41.png)\n     \n   - 可以看到镜像已经构建成功了\n   \n     ![图片加载失败](42.png)\n   \n   - 使用构建的镜像创建容器\n   \n     ![图片加载失败](43.png)\n   \n     可以看到，**hello docker** 已经打印出来了，并且容器已经退出了。\n   \n     ![图片加载失败](44.png)\n   \n   - 为甚么直接退出了？\n   \n     因为 **Dockerfile** 中的 `CMD [\"python3\",\"/hello.py\"]` 执行完之后就停了，这个进程停了，容器自然就停了\n\n### 4、通过 **container** 容器生成一个镜像\n\n我们可以使用 `docker container commit contaienrId ImageName` 命令，根据 **container** 生成一个镜像\n\n![图片加载失败](51.png)\n\n## 3、镜像的分享\n\n### 1.可以通过导出的方式进行分享\n\n```shell\n# nginx:1.20.1 要保存的镜像以及版本，如果不添加版本默认latest版本\n# -o 是指 output 输出\n# nginx.image 保存的文件名字\ndocker image save nginx:1.20.1 -o nginx\n```\n\n### 2.push 到 dockerhub 中进行分享\n\n1. 首先要在 **dockerhub** 注册一个账号，我们的镜像格式都是 **id/imageName**\n\n2. 在 **push** 之前我们的镜像 **tag** 要符合我们 **dockerhub** 的规范\n\n   - 我们可以通过重新构建来修改镜像的 **tag**\n\n     ```shell\n     docker image build -t DockerhubID/imageName:version .\n     ```\n\n   - 我们还可以通过已经存在的镜像复制一个新的镜像\n\n     ```shell\n     docker image tag hello sunyubk/hello:1.0\n     ```\n\n     ![图片加载失败](45.png)\n\n   <font color=\"red\">注意：通过以上两种方式生成的新的镜像的 id 是相同的，无法根据 id 进行删除，所以我们可以通过 image:tag 删除</font>\n\n3. push\n\n   - 在 **push **之前我们还需要登录到 **dockerhub**，`docker login`\n\n     ![图片加载失败](46.png)\n\n     这里可以看到我们已经登录成功了\n\n   - 我们可以通过 `docker image push sunyubk/hello:1.0` 进行 **push **了。\n\n     ![图片加载失败](47.png)\n\n   - **push ** 后我们就可以在我们的 **dockerhub** 中看到我们 **push** 的镜像了\n\n     ![图片加载失败](48.png)\n\n4. 拉取测试\n\n   - 我们先将本地的 **sunyubk/hello:1.0** 这个镜像删除掉在进行拉取\n\n     ![图片加载失败](49.png)\n\n   - 我们将镜像拉取下来，并运行测试\n\n     ![图片加载失败](50.png)\n\n# 五、Dockerfile\n\n## 1、基础镜像的选择\n\n- 官方镜像优于非官方镜像，如果没有官方镜像，则尽量选择 **Dockerfile** 开源的\n- 固定版本 **tag** 而不是每次都是用 **latest**\n- 尽量选择体积小的镜像\n\n## 2、通过 RUN 执行指令\n\n`RUN` 主要用于在 **image** 里执行指令，比如安装软件，下载文件等。\n\n```shell\n$ apt-get update\n$ apt-get install wget\n$ wget wget https://github.com/ipinfo/cli/releases/download/ipinfo-2.0.1/ipinfo_2.0.1_linxu_amd64.tar.gz\n$ tar -zxvf ipinfo_2.0.1_linxu_amd64.tar.gz\n$ mv ipinfo_2.0.1_linxu_amd64.tar.gz /usr/bin/ipinfo\n$ rm -rf ipinfo_2.0.1_linxu_amd64.tar.gz\n```\n\n**Dockerfile**\n\n```dockerfile\nFROM ubuntu:21.04\nRUN apt-get update\nRUN apt-get install wget\nRUN wget https://github.com/ipinfo/cli/releases/download/ipinfo-2.0.1/ipinfo_2.0.1_linxu_amd64.tar.gz\nRUN tar -zxvf ipinfo_2.0.1_linxu_amd64.tar.gz\nRUN ipinfo_2.0.1_linxu_amd64.tar.gz /usr/bin/ipinfo\nRUN rm -rf ipinfo_2.0.1_linxu_amd64.tar.gz\n```\n\n**镜像的大小和分层**\n\n每个 `RUN` 命令的执行都会产生一层 **image layer** ，这样会导致镜像比较臃肿。\n\n**改进版 Dockerfile**\n\n```dockerfile\nFROM ubuntu:21.04\nRUN apt-get update $$ \\\n\tapt-get install wget $$ \\\n\twget https://github.com/ipinfo/cli/releases/download/ipinfo-2.0.1/ipinfo_2.0.1_linxu_amd64.tar.gz $$ \\\n\ttar -zxvf ipinfo_2.0.1_linxu_amd64.tar.gz $$ \\\n\tmv ipinfo_2.0.1_linxu_amd64.tar.gz /usr/bin/ipinfo $$ \\\n\trm -rf ipinfo_2.0.1_linxu_amd64.tar.gz\n```\n\n这样编写的 **Dockerfile** 只会通过一个 `RUN` 命令执行，只会产生一层。\n\n## 3、文件复制和目录操作\n\n1. 文件复制\n\n   往镜像中复制文件有两种方式，分别是 `copy` 和 `add`。\n\n   **复制普通文件**\n\n    `copy` 和 `add` 都可以把 **local** 的一个文件复制到镜像中，如果目标目录不存在，则会自动创建\n\n   ```dockerfile\n   FROM python:3.9.5-alpine3.13\n   COPY hello.py /app/hello.py\n   ```\n\n   **复制压缩文件**\n\n   `add` 比 `copy` 高级一点的地方就是，如果复制一个 **gzip** 等压缩文件时，`add` 会帮助我们去自动解压缩文件。\n\n   ```dockerfile\n   FROM python:3.9.5-alpine3.13\n   ADD hello.tar.gz /app/\n   ```\n\n   **如何选择**\n\n   在 `copy` 和 `add` 指令的选择的时候，可以遵循这样的原则，所有文件复制均使用 `copy`，仅在需要自动解压缩的场合使用 `add`。\n\n2. 目录操作\n\n   **目录切换**\n\n   `WORKDIR` 切换目录，如果要切换的目录不存在，则创建目录\n\n   ```dockerfile\n   FROM python:3.9.5-alpine3.13\n   WORKDIR /app\n   COPY hello.py /hello.py\n   ```\n\n## 4、构建参数和环境变量（ARG vs ENV）\n\n`ARG` 和 `ENV` 是经常被混淆的两个 **Dockerfile** 的语法，都可以用来设置一个 **变量**。但实际上两者会有很多的不同。\n\n```dockerfile\nFROM ubuntu:21.04\nRUN apt-get update $$ \\\n\tapt-get install wget $$ \\\n\twget https://github.com/ipinfo/cli/releases/download/ipinfo-2.0.1/ipinfo_2.0.1_linxu_amd64.tar.gz $$ \\\n\ttar -zxvf ipinfo_2.0.1_linxu_amd64.tar.gz $$ \\\n\tmv ipinfo_2.0.1_linxu_amd64.tar.gz /usr/bin/ipinfo $$ \\\n\trm -rf ipinfo_2.0.1_linxu_amd64.tar.gz\n```\n\n**ENV**\n\n```dockerfile\nFROM ubuntu:21.04\nENV VERSION=2.0.1\nRUN apt-get update $$ \\\n\tapt-get install wget $$ \\\n\twget https://github.com/ipinfo/cli/releases/download/ipinfo-${VERSION}/ipinfo_${VERSION}_linxu_amd64.tar.gz $$ \\\n\ttar -zxvf ipinfo_${VERSION}_linxu_amd64.tar.gz $$ \\\n\tmv ipinfo_${VERSION}_linxu_amd64.tar.gz /usr/bin/ipinfo $$ \\\n\trm -rf ipinfo_${VERSION}_linxu_amd64.tar.gz\n```\n\n**ARG**\n\n```dockerfile\nFROM ubuntu:21.04\nARG VERSION=2.0.1\nRUN apt-get update $$ \\\n\tapt-get install wget $$ \\\n\twget https://github.com/ipinfo/cli/releases/download/ipinfo-${VERSION}/ipinfo_${VERSION}_linxu_amd64.tar.gz $$ \\\n\ttar -zxvf ipinfo_${VERSION}_linxu_amd64.tar.gz $$ \\\n\tmv ipinfo_${VERSION}_linxu_amd64.tar.gz /usr/bin/ipinfo $$ \\\n\trm -rf ipinfo_${VERSION}_linxu_amd64.tar.gz\n```\n\n**区别**\n\n![图片加载失败](52.png)\n\n- **ARG** 使用的范围是 **Dockerfile** 构建的阶段，构建后则无法使用了，因为这个变量不会保存在镜像中。\n- **ENV** 使用的范围不仅是在 **Dockerfile** 构建的阶段，而且这个变量会作为 **环境变量** 保存在镜像中，当我们使用这个镜像去创建容器的时候也可以使用这个变量\n\n<font color=\"red\">ARG 还可一在构建的时候动态的修改值， ENV 则不可以</font>\n\n![图片加载失败](53.png)\n\n例如：\n\n```dockerfile\ndocker image build -f ./Dockerfile-arg -t ipinfo-arg-2.0.0 --build-arg VERSION=2.0.0 .\n```\n\n## 5、CMD 容器启动命令\n\n**CMD** 可以用来设置容器启动时默认会执行的命令。\n\n- 容器启动时默认执行的命令\n- 如果 **docker container run** 启动容器是指定了其它命令，则 **CMD** 命令会被忽略\n- 如果定义了多个 **CMD** ，只有最后一个会被执行\n\n## 6、ENTRYPOINT 容器启动命令\n\n**ENTRYPOINT** 也可以设置容器启动时要执行的命令，但是和 **CMD** 是有区别的。\n\n- **CMD** 设置的命令，可以再 `docker container run` 时传入其他命令，覆盖掉 **CMD** 命令，但是 **ENTRYPOINT** 所设置的命令是一定会被执行的。\n- **ENTRYPOINT** 和 **CMD** 可以联合使用，**ENTRYPOINT** 设置执行的命令，**CMD** 传递参数\n\n1. 准备三个 **Dockerfile**，并构建成相应的镜像\n\n   **Dockerfile-cmd**\n\n   ```dockerfile\n   FROM ubuntu:21.04\n   CMD [\"echo\",\"hello docker\"]\n   ```\n\n   **Dockerfile-entrypoint**\n\n   ```dockerfile\n   FROM ubuntu:21.04\n   ENTRYPOINT [\"echo\",\"hello docker\"]\n   ```\n\n   **Dockerfile-both**\n\n   ```dockerfile\n   FROM ubuntu:21.04\n   ENTRYPOINT [\"echo\"]\n   CMD []\n   ```\n\n   ![图片加载失败](54.png)\n\n2. 根据镜像创建容器\n\n   ```shell\n   # -rm 运行后删除容器\n   docker container run --rm -it imagename\n   ```\n\n   **demo-cmd**\n\n   在下图中可以看到，如果在创建容器的时候指定命令，则 **CMD** 中的命令不会运行\n\n   ![图片加载失败](55.png)\n\n   **demo-entrypoint**\n\n   在下图中可以看到，如果在创建容器的时候指定指令，指令会作为参数传递进去，原本 **Dockerfile-entrypoint** 中的 **ENTRYPOINT** 肯定会执行。\n\n   ![图片加载失败](56.png)\n\n   **demo-bot**\n\n   在下图 中可以看到：\n\n   第一遍命令什么都没有打印，这是因为 **Dockerfile-both** 中的 **ENTRYPOINT** 执行了 `echo` ,但是并没有设置要打印的值。\n\n   第二遍命令打印了创建容器是指定的命令，这是因为将指定的命令作为参数传递进去了。\n\n   ![图片加载失败](56.png)\n\n## 7、Shell 格式和 Exec 格式\n\n**CMD** 和 **ENTRYPOINT** 都支持 **Shell** 格式和 **Exec** 格式\n\n**Shell** 格式\n\n```shell\nCMD echo \"hello docker\"\nENTRYPOINT echo \"hello docker\"\n```\n\n**Exec** 格式\n\n```shell\nCMD [\"echo\",\"hello docker\"]\nENTRYPOINT [\"echo\",\"hello docker\"]\n```\n\n**注意 Shell 脚本问题**\n\n```dockerfile\nFROM ubuntu:21.04\nENV NAME=docker\nCMD echo \"hello $NAME\"\n```\n\n假如我们要把上面的 **CMD** 改成 **Exec** 格式，下面这样改是不行的。\n\n```dockerfile\nFROM ubuntu:21.04\nENV NAME=docker\nCMD CMD [\"echo\",\"hello $NAME\"]\n```\n\n它会打印出 `hello $NAME`，而不是 `hello docker`。这里就需要以 **shell** 脚本的方式去执行\n\n```dockerfile\nFROM ubuntu:21.04\nENV NAME=docker\nCMD CMD [\"sh\",\"-c\",\"echo hello $N\"]\n```\n\n# 六、数据持久化\n\n为什么需要数据持久化：因为当我们将容器（**cotainer**）删除之后，那么我们容器中的数据也会被删除。（数据不随着 Container 的结束而结束）\n\n## 1、Data volume\n\n**Data volume** 是 **Docker** 一个<font color=\"red\">卷</font> 的概念，就是 **Docker** 管理宿主机文件系统的一部分，默认位于 `/var/lib/docker/volumes` 目录中。\n\n这里我们使用 **mysql** 的镜像来演示：\n\n1. 首先我们先准备 **mysql:5.7** 的镜像\n\n   ![图片加载失败](58.png)\n\n2. 创建容器\n\n   关于 **MySQL** 镜像的使用可以参考：[dockerhub中mysql](https://hub.docker.com/_/mysql)\n\n   ```shell\n   -e 设置mysql root用户的密码\n   -v 使用volume持久化数据 volume 名称：容器内目录，如果不指定则会默认生成一个随机的文件\n   docker container run -d --name mysql_5.7 -e MYSQL_ROOT_PASSWORD=root -v mysql_data:/var/lib/mysql mysql:5.7\n   ```\n\n   ![图片加载失败](59.png)\n\n3. 进入容器进行测试\n\n   - 我们交互式的进入到容器的中，并连接进入mysql，并且查看数据库，可以看到数据库是初始化的状态。\n\n     ![图片加载失败](60.png)\n\n   - 我们创建一个数据库，并退出到容器\n\n     ![图片加载失败](61.png)\n\n   - 我们进入容器的 `/var/lib/mysql` 目录下，也可以看到我们创建的数据库在这里生成了文件夹\n\n     ![图片加载失败](62.png)\n\n4. 退出容器，查看我们本地 **volume**文件\n\n   - 查看 **volume** 列表\n\n     ```shell\n     docker volume ls\n     ```\n\n     ![图片加载失败](63.png)\n\n   - 查看对应的文件信息\n\n     ```shell\n     docker volume inspect mysql_data\n     ```\n\n     ![图片加载失败](64.png)\n\n     这里看到的目录就是与容器中 **mysql** 目录绑定的目录\n\n   - 我们查看目录下的文件\n\n     ![图片加载失败](65.png)\n\n     可以看到，`test` 已经在目录下了。\n\n   **测试：**\n\n   1. 我们在容器中创建文件/文件夹，会不会同步到对应的volume中？\n\n      - 我们先进入容器中\n\n      - 在持久化的目录中新建一个文件夹\n\n        ![图片加载失败](66.png)\n\n      - 我们在 volume 中产看\n\n        ![图片加载失败](67.png)\n\n        可以看到，我们创建的文件夹在 volume 中已经出现了\n\n   2. 如果我们将 volume 中的文件删除，容器中会同步么？\n\n      - 我们删除 volume 目录中创建的文件夹\n\n      - 我们回到容器中的目录查看\n\n        ![图片加载失败](67.png)\n\n        可以看到，文件夹也不见了\n\n   通过这个测试，我们可以看出，**volume** 帮我们做了一个类似软连接的功能。在容器里面的改动，可以再宿主机中感知，而在宿主机里面的改动，在容器中也可以感知。\n\n   **注意：**\n\n   - 如果 **volume** 是空的，而 **container** 中有内容，那么 **docker** 会将 **container** 中的内容拷贝到 **volume** 中\n   - 如果 **volume** 中已经有内容，则会将 **container** 中的目录覆盖掉。\n\n# 命令行小技巧\n\n## 1、批量操作\n\n1. 我们可以通过 `docker container ls -aq` 获取到所有 **container** 的id\n\n   ![图片加载失败](14.png)\n\n2. 我们可以通过参数的方式将这些 **id**，进行一个传递\n\n   - 批量启动\n\n     ![图片加载失败](16.png)\n\n   - 批量停止\n\n     ![图片加载失败](17.png)\n\n   - 批量删除\n\n     ![图片加载失败](18.png)\n\n## 2、系统清理\n\n1. 我们可以使用 `docker container prune -f`，来清理掉已经停止的容器\n2. 我们可以使用 `docker image prune -a`，来清理掉没有使用的镜像y\n","tags":["Docker"],"categories":["技术学习","Docker"]},{"title":"Redis学习","url":"/2021/08/06/Redis学习/","content":"\n# 一、环境准备\n\n- linux系统，本人使用的是centos8，最小化安装\n- [Redis下载](https://download.redis.io/releases/redis-6.2.5.tar.gz?_ga=2.264706890.49166100.1628230335-321395705.1628230335)\n\n<!-- more -->\n\n# 二、安装\n\n1. 首先通过 **tar -zxvg xxxxx** 将 **Redis** 解压，目录随意，本人是在 **/usr/local/** 下创建了一个文件夹用来安装使用\n\n2. 解压过后执行 **make** 命令编译，执行的时候会检测你的系统是否缺少依赖之类的，如果没问题会进行编译\n\n   ![图片加载失败](1.png)\n\n3. 编译成功后，执行 **make test** 命令检测一下是否有什么错误\n\n   - 小编这里就出现了错误\n\n     ![图片加载失败](2.png)\n\n     这个错误的意思是：如果想要执行 **make test** 命令需要一个 **tcl 8.5** 的库，如果想要 **test** 就要安装这个库\n\n     ![图片加载失败](3.png)\n\n4. 执行 **make PREFIX /usr/local/redis install** 安装， **PREFIX /usr/local/redis ** 为指定安装目录\n\n   ![图片加载失败](4.png)\n\n   安装好之后则会在 **/usr/local/redis** 下生成 **bin** 文件夹，内含文件如下\n\n   ![图片加载失败](5.png)\n\n   他们分别是：\n\n   ```shell\n   redis-benchmark   #redis 性能测试工具\n   redis-check-aof   #检查aof日志的工具\n   redis-check-rdb   #检查rdb日志的工具\n   redis-cli         #redis 连接的客户端\n   redis-sentinel    #哨兵模式\n   redis-server\t  #redis 服务进程\n   ```\n\n\n# 三、配置\n\n1. 从源代码目录复制 **redis.conf** 文件到 **bin** 同级\n\n   ![图片加载失败](6.png)\n\n2. 注释掉 **bind** 配置，如果不注释的话，默认只有 **127.0.0.1** 也就是本机可以连接\n\n   ![图片加载失败](13.png)\n\n3. 保护模式设置，关闭保护模式，如果开启的话，redis只能本机访问\n\n   ![图片加载失败](14.png)\n\n4. **backlog** 连接队列\n\n   ![图片加载失败](15.png)\n\n5. 配置 **redis** 后台启动\n\n   ![图片加载失败](16.png)\n\n6. 日志文件配置，默认为空，即在那个目录启动，日志文件就在那个目录下生成\n\n   ![图片加载失败](17.png)\n\n7. 数据库个数\n\n   ![图片加载失败](18.png)\n\n# 四、启动与连接\n\n1. 显示启动 **redis-server** 服务\n\n   ```shell\n   # 启动 bin 目录下的 redis-server，并指定使用我们刚才拷贝过来的 redis.conf 配置文件\n   ./bin/redis-server ./redis.conf\n   ```\n\n   ![图片加载失败](7.png)\n\n2. 隐式启动 **redis-server** 服务\n\n   修改 **redis.conf** 配置文件\n\n   ![图片加载失败](9.png)\n\n3. 连接 **redis-cli** 客户端，并测试\n\n   ```shell\n   # 启动客户端\n   ./bin.redis-cli\n   \n   # 新增key-velue, 存储字符串 双引号 可有可无\n   set word \"hello world\"\n   \n   # 根据key查询\n   get word\n   ```\n\n   ![图片加载失败](8.png)\n\n4. 关闭\n\n   - 显示启动的 **redis-server** 直接按 **ctrl + c** 即可\n\n   - 隐式启动的 **redis-server** 需要查询到进程后，根据进程ID杀死进程即可\n\n     ![图片加载失败](10.png)\n\n   - 关闭 **redis-cli** 输入 **exit** 即可\n\n# 五、操作命令\n\n在操作之前我们先要知道：\n\n1. **redis** 中都有哪些数据类型：**string、list、set、zset(order set)、hash**\n2. **redis** 中共有16个数据库（空间），使用**select 0** 切换，默认使用 0号库\n\n## 1、基础操作\n\n### 1）新增\n\n1. 字符串（string）\n\n   ```shell\n   # set key value\n   set site www.baidu.com\n   ```\n   \n2. 追加\n\n   ```shell\n   # 向指定的 key 追加值，如果key不存在则创建并返回value长度，如果存在则向value后追加，并返回追加后的value长度\n   append key value\n   ```\n\n   \n\n### 2）删除\n\n1. 字符串（string）\n\n   ```shell\n   # 单个 del key\n   del site\n   \n   #批量删除\n   del sit age\n   ```\n\n### 3）修改\n\n1. 字符串（string）\n\n   ```shell\n   # 修改值 set key value\n   set site www.baidu.com\n   \n   #修改 key 名称，如果修改后的key name 存在，则会覆盖修改后的key name 的值\n   rename age agee\n   \n   #修改 key 名称，检查修改后的key name是否存在，如果不存在返回1，表示成功，否则返回0，修改不成功\n   # nx: not exists 是否存在\n   renamenx age site \n   ```\n\n### 4）查询\n\n1. 字符串（string）\n\n   ```shell\n   # get key\n   get site\n   \n   # 查询并修改\n   getset site test\n   ```\n\n### 5）各种查询\n\n1. **\\*** 的使用\n\n   ```shell\n   # 查询所有key\n   keys *\n   \n   # 模糊匹配\n   keys si*\n   ```\n\n2. **[]** 的使用\n\n   ```shell\n   # 比较精确的匹配，匹配中括号中的字符\n   keys sit[ey]\n   ```\n\n3. **？**的使用\n\n   ```shell\n   # ? 匹配单个字符\n   keys si?e\n   ```\n\n4. 随机返回一个key\n\n   ```shell\n   randomkey\n   ```\n\n5. 查看 **key** 的类型：\n\n   ```shell\n   # type key\n   type site\n   ```\n\n6. 查看某个 **key** 是否存在：\n\n   ```shell\n   # 存在返回 1，不存在返回 0\n   exists site\n   ```\n\n7. 获取 **value** 的长度\n\n   ```shell\n   strlen key\n   ```\n\n### 6）key 移动\n\n```shell\n# 将 key 移动至1号库\nmove site 1\n```\n\n### 7 ）key 递增/减\n\n```shell\n# 设置整型 key，每次递增 1\nincr key\n\n# 设置整型 key，每次递减 1\ndecr key\n\n# 设置整型 key，递增10，即步长\nincrby key 10\n\n# 浮点数类型 递增，没有相应的递减\nincrbyfloat key 1.1\n\n#设置整型 key，递减10，即步长\ndecrby key 10\n```\n\n\n\n### 8）key 的生命周期\n\n```shell\n# 查询key的有效期\n# 已过期/不过期的key 返回-1，Redis2.8后不存在的key 返回-2\n# 返回 秒\nttl site\n# 返回 毫秒\npttl site\n\n# 设置key的生命周期\n# 秒\nexpire site 10\n# 毫秒\npexpire site 10000\n\n# 设置key永久有效\npersist key\n```\n\n### 9）切换数据库，默认有16个\n\n```shell\nselect 0\n```\n\n### 10）清空数据库\n\n```shell\nflushdb\n```\n\n## 2、各种数据类型的操作\n\n### 2-1、string（字符串）类型\n\n#### 1）新增\n\n```shell\n# ex:设置生命周期秒数\n# px:设置生命周期毫秒数\n# 生命周期设置ex/px同时写的时候以后面的有效期为准\n# nx:表示 key 不存在时，执行操作\n# xx:表示 key 存在时，执行操作\nset key value [ex 秒数][px 毫秒数] [nx]/[xx]\n\n# 20 秒过期，value为10\nset age 20 10\n\n# 一次性新增多个键值\nmset key value key value\n```\n\n#### 2）查询\n\n```\nget key\n\n# 获取多个key\nmget key1 key2 key3\n```\n\n#### 3）删除\n\n````shell\n# 单个 del key\ndel site\n\n#批量删除\ndel sit age\n````\n\n#### 4）偏移量\n\n```shell\n# 偏移 从下标位置向后替换\nsetrange key index value\n\n# start,stop可以为负数，则是从value末尾开始，\ngetrange key start stop\n```\n\n![图片加载失败](12.png)\n\n### 2-2、list（列表）类型\n\n#### 1）新增\n\n```shell\n# 从左侧推入\nlpush list a b c d\n\n# 从右侧推入\nrpush list a b c d\n\n# 插入值，在列表中找到某个值，并在其前或后插入值，如果没有找到则会返回 -1\n# 如果找到了多个值，则会在第一个找到的值前后插入值。\nlinsert key after|before search value\neg:\n# 在key为num的列表中找到3，并在3的前面插入2\nlinsert num before 3 2\n```\n\n#### 2）查询\n\n````shell\n# 范围取值\nlrange list 0 1\nlrange list 0 -1\n\n# 根据下标获取元素\nlindex list index\n\n# 获取列表长度\nllen key\n````\n\n#### 3） 删除（弹出）\n\n```shell\n# 删除整个key\ndel key\n\n# 弹出元素\nlpop list\nrpop list\n\n# 删除元素\n# count 删除几个，正数代表从左向右删除，负数代表从右向左删除\n# value 根据值删除\nlrem key count value\neg: \nlrem list 1 value\nlrem list -1 value \n\n\n# 等待弹出\n# 如果key中没有元素，则等待有值了之后弹出\n# timeout 为0 则一直等待\n# 适用场景：长轮询，在线聊天\nbrpop/blpop key timeout\n```\n\n#### 4）剪切\n\n```shell\n# 剪切后key的值就变为剪切的值\nltrim key start stop\n```\n\n\n\n#### 5）弹出并插入\n\n```shell\n# 在第一个列表的右侧弹出一个元素，并插入到第二个列表的左侧，成功会返回弹出插入的值\n# 原子性操作\n\n# 适用场景:\n# 两个列表: task[a,b,c,d] bak[]\n# 执行任务时可以使用此命令:task[a,b,c] bak[d],执行命令后会返回弹出并插入的值，也就是d\n# 这个时候我们就知道该执行任务：d\n# 如果执行成功则在bak中，pop掉d\n# 如果执行失败，或者没有执行，那么bak中的d还在。下次再执行任务的时候去bak中拿就好了。\nrpoplpush key1 key2\n```\n\n### 2-3、set（集合）类型，无序\n\n#### 1）新增\n\n```shell\nsadd key value1 value2 ...\n```\n\n#### 2）查询\n\n```shell\n# 随机查询出一个元素，或指定count个元素\nsrandmember key count\n\n# 查询集合所有元素\nsmembers key\n\n# 判断value是否包含在集合中，是返回1，否则返回0\nsismember key value \n\n# 查询集合共有多少个元素\nscard key\n```\n\n#### 3）删除（弹出）\n\n```shell\n# 删除元素(根据值删除)\nsrem key value1 value2\n\n# 弹出\n# 随机删除一个元素并返回pop出的值，count可以指定随机删除多少个\nspop key count\n```\n\n#### 4）更多\n\n```shell\n# 删除指定集合重元素，并将删除的元素添加到另一个集合\nsmove sourcr target value\n\n# 交集\nsinter key1 key2 key3\n# 查询出交集并存储在一个key(targer)中\nsinterstore target key1 key2 key3\n\n# 并集\nsunion key1 key2 key3\n\n\n# 差集,key1 与 key2 key3 的差集,返回key1中存在，其他key中不存在的\nsdiff key1 key2 key3\n```\n\n### 2-4、Hash（哈希）类型\n\n#### 1）新增\n\n```shell\n# 单个，如果field已经存在则会覆盖原有的value\nhset key field value\neg：\nhset user id 1\nhset user name zhangsan\n\n# 如果key中field不存在，添加成功，否则添加失败\nhsetnx key field value\n\n# 批量为key设置hash值\nhmset key field1 value1 field2 value2\n```\n\n#### 2）查询\n\n```shell\n# 根据key的属性查询value\nhget key field\n\n# 查询key中是否存在某个field\nhexists key field\n\n# 查询key中所有的field\nhkeys key\n\n# 查询key中所有value\nhvals key\n```\n\n#### 3）删除\n\n```shell\ndel key\n```\n\n#### 4）更多\n\n```shell\n# 为key中field对应的value增加量操作，针对数字的value\nhincrby key field increment\neg：\nhset user id 1\nhincrby user id 12\nresult：13\n```\n\n\n\n### 2-5、zset(order set) 有序集合\n\n#### 1）新增\n\n``` shell\n# 根据order排序\nzadd key order1 value1 order2 value2\n```\n\n#### 2）查询\n\n```shell\n# 把集合排序后，返回范围内数据[start，stop]\n# 注意这里是先进行“排序”，在拿 start - stop(下标/排名)的值\n# 默认升序\nzrange key start stop \n# 降序\nzrevrange key start stop\n\n# 这里也是和集合升序排序后取值，这里的min,max指的是实际排序的值\n# limit 分页\n# offset 偏移量，从那个开始算\n# N 查多少个\n# withscores 实际分数\nzrangebyscorce key min max withscores limit offset N\neg:\nzadd test 1 a 3 c 2 b 4 d 6 f 9 i 8 h\nzrangebyscore test 4 8 \n# result：d f h\nzrangebyscore test 4 8 withscores\n# result：d 4 f 6 h 8\nzrange test 4 8\n# result：f h i\nzrangebyscore test 1 8 limit 1 2\n# result：b c\n\n\n# 先对集合生序排序，再查询value 在key中拍第几个，从0开始。\nzrank key value\n# 降序\nzrevrank key value\n```\n\n#### 3）删除\n\n```shell\n# 根据元素删除\nzrem key value\n\n# 按排名删除（下标）\nzremrangebyrank test 0 1\neg:\nzadd test 1 a 3 c 2 b 4 d 6 f 9 i 8 h\n# 删除的就是： a b\n\n# 按分数（排序实际的值）删除\nzremrangebyscore test 2 8 \neg:\nzadd test 1 a 3 c 2 b 4 d 6 f 9 i 8 h\n# 删除的就是: b c d f h\n```\n\n#### 4） 更多\n\n```shell\n# 统计集合内一共有多少个\nzcard key\n\n# 统计集合内指定范围内的\nzcount ket start stop\n```\n\n# 六、发布和订阅\n\n## 1、什么是发布和订阅\n\n1. **Redis** 发布订阅（**pub/sub**）是一种消息通信模式：发送者（**pub**）发送消息，订阅者（**sub**）订阅消息\n2. **Redis** 客户端可以订阅任意数量的频道\n\n![图片加载失败](19.png)\n\n## 2、发布和订阅命令行示例\n\n```shell\n# 分别打开三个四个窗体\n# 前三个窗口用于订阅消息，最后一个用于发布消息\n# 前三个窗口分别执行以下命令\nsubscribe a1\nsubscribe a2\nsubscribe a1 a2\n\n# 最后一个窗口执行以下命令\npublish a1 hello\npublish a2 world\n\n# 最后查看前三个窗体分别接收到了那个消息\n```\n\n订阅消息：\n\n![图片加载失败](20.png)\n\n![图片加载失败](21.png)\n\n![图片加载失败](22.png)\n\n发布消息：\n\n![图片加载失败](23.png)\n\n# 七、新数据类型\n\n## 1、Bitmaps（位操作）\n\n```shell\n# 设置 key 偏移量的位置 是1/0\nsetbit key offset value\n\n# 获取 key 偏移量的位置的 值\ngetbit key offset\n\n------------------------------------------------------------------\n\n# 获取 key 开始-结束 有多少个1\n# 这里的 start，top指的是字节组\n# 即 01000000 8个bit 为一个字节组\n# \nbitcount key start top\neg：\nsetbit a 1000 0\nsetbit a 0 1\nsetbit a 2 1\n# a中的二进制，也就是 位 是： 10100000\n# 查询所有，即返回a中bit为1的个数\nbitcount a \n\nsetbit a 8 1\n# a中的二进制，也就是 位 是：10100000 10000000\n\n# 这里 start：0 指的就是：10100000\n# 这里 end：1 指的就是： 10000000\n# 这个返回 2\nbitcount a 0 0 \n# 这个返回 3\nbitcount a 0 1\n\n\n------------------------------------------------------------------\n\n# 多个key 按位操作 \n# operation 可以是: AND OR NOT XOR\nbitop operation destkey key1 [key2...]\neg:\nsetbit lower 2 1\nset char Q\n# char 和 lower 做or才操作，比较后 char的第二位变成了1 ，结果放在cahr上\n# 第一个 char 表示放在那个key上\nbitop and lower char char lower\n```\n\n## 2、HyperLogLog（基数统计）\n\n什么是基数：假如现在有这么一组数据{1,3,5,7,5,7,8}， 那么他的基数就是{1,3,5,7,8}\n\n### 1）新增\n\n```shell\npfadd key elements\neg:\npfadd program java php java\nresult: java php\n```\n\n### 2）查询\n\n```shell\n# 统计基数个数\npfcount program \nresult: 2\n```\n\n### 3）更多\n\n```shell\n# 合并，将多个 key 的元素合并到一个目标 key 中\npfmerge target keys\neg:\npfadd k1 a b\npfmerge k2 program k1\nresult: 4\n```\n\n## 3、Geospatial（地理信息的缩写）\n\n注：该类型就是元素的 2 维坐标。在地图上就是经纬度。**redis** 基于该类型，提供了经纬度设置，查询，范围查询，距离查询，经纬度 **Hash** 等操作.\n\n### 1）新增\n\n```shell\n#  经度 纬度 名称\ngeoadd key longitude latitude member\neg:\ngeoadd china:city 121.47 31.23 shanghai 106.50 29.53 chongqing\n\n# 两极无法直接添加，一般会下载城市数据，通过 java 程序一次性导入。\n# 有效的经度从 -180 度到 180 度。有效的纬度从 -85.05112878 度到 85.05112878 度。\n```\n\n### 2）查询\n\n```shell\n# 获得指定地区的坐标值\ngeopos key member\neg:\ngeopos china:city shanghai\nresult:\n1) 121.47000163793563843  # 经度\n2) 31.22999903975783553   # 纬度\n\n\n# 获取两位位置的直线距离\n# m 米 默认值\n# km 千米\n# mi 英里\n# ft 英尺\ngeodist key member1 member2 [m|km|ft|mi]\neg:\ngeodist china:city shanghai chongqing\n\n# 查询给定经纬度为中心，半径内的元素\ngeoradius key  longitude latitude radius [m|km|ft|mi]\neg:\n# 查询 key 中 经纬度为中心 1000 公里内的元素\ngeoradius china:city 110 30 1000 km\n```\n\n# 八、Jedis 操作\n\n## 1、Jedis 连接测试\n\n1. 创建一个 **Maven** 工程\n\n2. **pom** 文件中增加依赖\n\n   ```xml\n   <dependency>\n       <groupId>redis.clients</groupId>\n       <artifactId>jedis</artifactId>\n       <version>3.6.3</version>\n   </dependency>\n   ```\n\n3. 创建一个类并测试\n\n   ![图片加载失败](24.png)\n\n4. 启动 **main** 方法\n\n   ![图片加载失败](28.png)\n\n<font color=\"red\">**注意：**</font>这里可能会发生报错，可能是由于虚拟机防火墙为关闭导致的\n\n![图片加载失败](25.png)\n\n关闭防火墙：\n\n1. 执行 **systemctl status firewalld** 查看防火墙状态\n\n   ![图片加载失败](26.png)\n\n2. 执行**systemctl stop firewalld** 关闭防火墙，在查看防火墙状态\n\n   ![图片加载失败](27.png)\n\n3. 禁用防火墙：**systemctl disable firewalld**\n\n## 2、测试相关数据类型\n\n<font color=\"red\">**注：**</font>因为和命令行操作相同，所以就不所有命令都进行测试了\n\n### 1）String 类型\n\n```java\n    /**\n     * 字符串类型测试\n     */\n    @Test\n    public void test1() {\n        Jedis jedis = new Jedis(\"192.168.111.144\", 6379);\n        // 单个 key-value 设置\n        jedis.set(\"name\", \"zhangsan\");\n        String name = jedis.get(\"name\");\n        System.out.println(name);\n\n        // 多个 key-value 设置\n        jedis.mset(\"age\", \"12\", \"sex\", \"man\");\n        List<String> keys = jedis.mget(\"name\", \"age\", \"sex\");\n        System.out.println(keys);\n\n        // 获取所有 key\n        Set<String> set = jedis.keys(\"*\");\n        for (String str : set) {\n            System.out.println(\"key：\" + str);\n            String value = jedis.get(str);\n            System.out.println(\"value：\" + value);\n        }\n\n        // 判断 key 是否存在\n        System.out.println(jedis.exists(\"name\"));\n        // 设置 key 过期时间，这里 expire 方法过期了，可以使用 JedisCommands 实现\n        jedis.expire(\"test_key\", 30);\n        // 查看 key 的过期时间\n        System.out.println(jedis.ttl(\"test_key\"));\n        \n        jedis.close();\n    }\n```\n\n### 2）List 类型\n\n```java\n    /**\n     * List 类型测试\n     */\n    @Test\n    public void test_list() {\n        Jedis jedis = new Jedis(\"192.168.111.144\", 6379);\n        jedis.flushDB();\n        jedis.lpush(\"list\", \"a\", \"b\");\n        jedis.rpush(\"list\", \"c\");\n\n        String val1 = jedis.lindex(\"list\", 1);\n        System.out.println(val1);\n\n        List<String> list = jedis.lrange(\"list\", 0, -1);\n        for (String str : list) {\n            System.out.println(str);\n        }\n\n        jedis.close();\n    }\n```\n\n### 3）Set 类型\n\n```java\n    /**\n     * set 类型测试\n     */\n    @Test\n    public void test_set() {\n        Jedis jedis = new Jedis(\"192.168.111.144\", 6379);\n        jedis.flushDB();\n        jedis.sadd(\"set\", \"set1\", \"set2\", \"set3\");\n\n        // 随机查询出一个元素，或指定count个元素\n        List<String> values = jedis.srandmember(\"set\", 2);\n        for (String str : values) {\n            System.out.println(str);\n        }\n\n        // 查询集合所有元素\n        Set<String> all = jedis.smembers(\"set\");\n        for (String str : all) {\n            System.out.println(str);\n        }\n\n        // 查询集合共有多少个元素\n        Long count = jedis.scard(\"set\");\n        System.out.println(count);\n        \n        jedis.close();\n    }\n```\n\n### 4）Hash 类型\n\n```java\n    /**\n     * Hash 类型测试\n     */\n    @Test\n    public void test_hash() {\n        Jedis jedis = new Jedis(\"192.168.111.144\", 6379);\n        jedis.flushDB();\n        Map<String, String> map = new HashMap<>();\n        map.put(\"name\", \"zhangsan\");\n        map.put(\"age\", \"18\");\n        map.put(\"sex\", \"man\");\n        jedis.hset(\"user\", map);\n\n        // 如果 key 中 field 不存在，添加成功，否则添加失败\n        jedis.hsetnx(\"user\", \"city\", \"beijing\");\n\n        // 根据 key 的属性查询 value\n        String name = jedis.hget(\"user\", \"name\");\n        System.out.println(name);\n\n        // 查询 key 中是否存在某个 field\n        Boolean hexists = jedis.hexists(\"user\", \"address\");\n        System.out.println(hexists);\n\n        // 查询 key 中所有的 field\n        Set<String> user = jedis.hkeys(\"user\");\n        for (String str : user) {\n            System.out.println(str);\n        }\n\n        // 查询 key 中所有 value\n        List<String> value = jedis.hvals(\"user\");\n        for (String str : value) {\n            System.out.println(str);\n        }\n\n        jedis.close();\n    }\n```\n\n### 5）ZSet 类型\n\n```java\n    /**\n     * zset 类型\n     */\n    @Test\n    public void test_zset() {\n        Jedis jedis = new Jedis(\"192.168.111.144\", 6379);\n        jedis.flushDB();\n\n        Map<String, Double> map = new HashMap<>();\n        map.put(\"age\", (double)2);\n        jedis.zadd(\"user\", (double) 1, \"name\");\n        jedis.zadd(\"user\", map);\n\n        // 升序排序后查询\n        Set<String> user = jedis.zrange(\"user\", 0, -1);\n        for (String str : user) {\n            System.out.println(str);\n        }\n\n        // 降序排序后查询\n        Set<String> user1 = jedis.zrevrange(\"user\", 0, -1);\n        for (String str : user1) {\n            System.out.println(str);\n        }\n        \n        jedis.close();\n    }\n```\n\n## 3、模拟发送验证码\n\n要求：\n\n1. 输入手机号，点击发送后随机生成 6 位数字码，两分钟有效。\n2. 输入验证码，点击验证，返回成功或失败。\n3. 每个手机号每天只能输入 3 次。\n\n### 1）创建一个生成验证码的方法\n\n```java\n    public String getCode() {\n        Random random = new Random();\n        StringBuilder code = new StringBuilder();\n        for (int i = 0; i < 6; i++) {\n            code.append(random.nextInt(10));\n        }\n        return code.toString();\n    }\n```\n\n### 2）创建生成验证码的方法\n\n```java\n    @Override\n    public Boolean createCodeByPhoneNum(String phoneNum) {\n\n        boolean result = true;\n\n        Jedis jedis = new Jedis(\"192.168.111.144\", 6379);\n\n        // 验证码发送次数\n        String sendCountKey = \"sendCode\" + phoneNum + \":count\";\n        // 验证码 key\n        String codeKey = \"code\" + phoneNum + \":code\";\n        // 验证码\n        String code = getCode();\n        // 是否可以存入验证码\n        boolean saveCode = true;\n\n        // 1、获取手机号对应发送的次数\n        String count = jedis.get(sendCountKey);\n        if (count == null) {\n            // 没有发送过，设置发送次数为1\n            jedis.setex(sendCountKey, 24 * 60 * 60, \"1\");\n        } else if (Integer.parseInt(count) < 3) {\n            // 发送次数 +1\n            jedis.incr(sendCountKey);\n        } else if (Integer.parseInt(count) > 2) {\n            // 已经发送三次了\n            saveCode = false;\n            result = false;\n            //jedis.close();\n        }\n\n        // 2、保存验证码\n        if (saveCode) {\n            jedis.setex(codeKey, 60 * 2, code);\n        }\n\n        jedis.close();\n        return result;\n    }\n```\n\n### 3）创建校验验证码的方法\n\n```java\n    @Override\n    public Boolean verifyCodeByPhoneNum(String phoneNum, String code) {\n\n        Jedis jedis = new Jedis(\"192.168.111.144\", 6379);\n\n        // 验证码 key\n        String codeKey = \"code\" + phoneNum + \":code\";\n\n        // 获取验证码\n        String redisCode = jedis.get(codeKey);\n\n        jedis.close();\n        if (redisCode == null) {\n            return false;\n        } else if (redisCode.equals(code)) {\n            return true;\n        } else {\n            return false;\n        }\n    }\n```\n\n\n\n# 九、SpringBoot 整合 Redis\n\n## 1、在 pom 文件中引入相关依赖\n\n```xml\n        <!--redis-->\n        <dependency>\n            <groupId>redis.clients</groupId>\n            <artifactId>jedis</artifactId>\n            <version>3.6.3</version>\n        </dependency>\n\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-data-redis</artifactId>\n            <version>2.5.3</version>\n        </dependency>\n\n        <dependency>\n            <groupId>org.apache.commons</groupId>\n            <artifactId>commons-pool2</artifactId>\n            <version>2.8.0</version>\n        </dependency>\n```\n\n## 2、application.yml 配置 redis 相关配置\n\n```yaml\nspring:\n  redis:\n#    Redis 服务器地址\n    host: 192.168.111.144\n#    端口\n    port: 6379\n#    数据库索引\n    database: 0\n#    连接超时时间（毫秒）\n#    timeout: 1800000\n    jedis:\n      pool:\n#        连接池最大连接数（负数表示没有限制）\n        max-active:\n#        最大阻塞等待时间（负数表示没有限制）\n        max-wait: -1\n#        连接池中最大空闲连接\n        max-idle: 5\n#        连接池值最小空闲连接\n        min-idle: 0\n```\n\n## 3、配置 redis 配置类\n\n```java\n@EnableCaching\n@Configuration\npublic class RedisConfig {\n    @Bean\n    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException {\n        // 我们为了自己开发方便，一般直接使用 <String, Object>\n        // 两个泛型都是 Object, Object 的类型，我们后使用需要强制转换 <String, Object>\n        RedisTemplate<String, Object> template = new RedisTemplate<>();\n        template.setConnectionFactory(redisConnectionFactory);\n        setRedisTemplate(template);\n        template.afterPropertiesSet();\n        return template;\n    }\n\n\n    private void setRedisTemplate(RedisTemplate<String, Object> template) {\n        // Json序列化配置\n        Jackson2JsonRedisSerializer<Object> jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer<>(Object.class);\n\n        ObjectMapper objectMapper = new ObjectMapper();\n        objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);\n        // 解决jackson2无法反序列化LocalDateTime的问题\n        objectMapper.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS);\n        objectMapper.registerModule(new JavaTimeModule());\n\n        // 该方法过时\n        // om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);\n        // 上面 enableDefaultTyping 方法过时，使用 activateDefaultTyping\n        objectMapper.activateDefaultTyping(LaissezFaireSubTypeValidator.instance, ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY);\n        jackson2JsonRedisSerializer.setObjectMapper(objectMapper);\n\n        // String 的序列化\n        StringRedisSerializer stringRedisSerializer = new StringRedisSerializer();\n        // key采用String的序列化方式\n        template.setKeySerializer(stringRedisSerializer);\n        // hash的key也采用String的序列化方式\n        template.setHashKeySerializer(stringRedisSerializer);\n        // value序列化方式采用jackson\n        template.setValueSerializer(jackson2JsonRedisSerializer);\n        // hash的value序列化方式采用jackson\n        template.setHashValueSerializer(jackson2JsonRedisSerializer);\n        // 设置值（value）的序列化采用FastJsonRedisSerializer。\n        // 设置键（key）的序列化采用StringRedisSerializer。\n        template.afterPropertiesSet();\n    }\n\n}\n```\n\n## 4、redis 工具类\n\n使用的时候注入即可\n\n```java\npackage com.sy.jedis_redisdemo.utils;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.data.redis.core.RedisTemplate;\nimport org.springframework.stereotype.Component;\nimport org.springframework.util.CollectionUtils;\n\nimport java.util.Collection;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * @ClassName RedisUtil\n * @Description TODO\n * @Author sy\n * @Date 2021/8/15 22:20\n * @Version 1.0\n **/\n@Component\npublic class RedisUtil {\n\n\n    @Autowired\n    private RedisTemplate<String, Object> redisTemplate;\n\n\n    // =============================common============================\n\n\n    /**\n     * sy\n     * 监视 key\n     * @param key  键\n     */\n    public boolean watch(String key) {\n        try {\n            if (key != null && key != \"\") {\n                redisTemplate.watch(key);\n            }\n            return true;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return false;\n        }\n    }\n\n    /**\n     * sy\n     * 监视 key\n     * @param keys  键\n     */\n    public boolean watch(Collection<String> keys) {\n        try {\n            if (keys != null && keys.size()>0) {\n                redisTemplate.watch(keys);\n            }\n            return true;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return false;\n        }\n    }\n\n    /**\n     * sy\n     * 解除监视 key\n     */\n    public boolean unwatch() {\n        try {\n            redisTemplate.unwatch();\n            return true;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return false;\n        }\n    }\n\n\n    /**\n     * 指定缓存失效时间\n     *\n     * @param key  键\n     * @param time 时间(秒)\n     */\n    public boolean expire(String key, long time) {\n        try {\n            if (time > 0) {\n                redisTemplate.expire(key, time, TimeUnit.SECONDS);\n            }\n            return true;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return false;\n        }\n    }\n\n\n    /**\n     * 根据key 获取过期时间\n     *\n     * @param key 键 不能为null\n     * @return 时间(秒) 返回0代表为永久有效\n     */\n    public long getExpire(String key) {\n        return redisTemplate.getExpire(key, TimeUnit.SECONDS);\n    }\n\n\n    /**\n     * 判断key是否存在\n     *\n     * @param key 键\n     * @return true 存在 false不存在\n     */\n    public boolean hasKey(String key) {\n        try {\n            return redisTemplate.hasKey(key);\n        } catch (Exception e) {\n            e.printStackTrace();\n            return false;\n        }\n    }\n\n\n    /**\n     * 删除缓存\n     *\n     * @param key 可以传一个值 或多个\n     */\n    @SuppressWarnings(\"unchecked\")\n    public void del(String... key) {\n        if (key != null && key.length > 0) {\n            if (key.length == 1) {\n                redisTemplate.delete(key[0]);\n            } else {\n                redisTemplate.delete((Collection<String>) CollectionUtils.arrayToList(key));\n            }\n        }\n    }\n\n\n    // ============================String=============================\n\n\n    /**\n     * 普通缓存获取\n     *\n     * @param key 键\n     * @return 值\n     */\n    public Object get(String key) {\n        return key == null ? null : redisTemplate.opsForValue().get(key);\n    }\n\n\n    /**\n     * 普通缓存放入\n     *\n     * @param key   键\n     * @param value 值\n     * @return true成功 false失败\n     */\n\n\n    public boolean set(String key, Object value) {\n        try {\n            redisTemplate.opsForValue().set(key, value);\n            return true;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return false;\n        }\n    }\n\n\n    /**\n     * 普通缓存放入并设置时间\n     *\n     * @param key   键\n     * @param value 值\n     * @param time  时间(秒) time要大于0 如果time小于等于0 将设置无限期\n     * @return true成功 false 失败\n     */\n\n\n    public boolean set(String key, Object value, long time) {\n        try {\n            if (time > 0) {\n                redisTemplate.opsForValue().set(key, value, time, TimeUnit.SECONDS);\n            } else {\n                set(key, value);\n            }\n            return true;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return false;\n        }\n    }\n\n\n    /**\n     * 递增\n     *\n     * @param key   键\n     * @param delta 要增加几(大于0)\n     */\n    public long incr(String key, long delta) {\n        if (delta < 0) {\n            throw new RuntimeException(\"递增因子必须大于0\");\n        }\n        return redisTemplate.opsForValue().increment(key, delta);\n    }\n\n\n    /**\n     * 递减\n     *\n     * @param key   键\n     * @param delta 要减少几(小于0)\n     */\n    public long decr(String key, long delta) {\n        if (delta < 0) {\n            throw new RuntimeException(\"递减因子必须大于0\");\n        }\n        return redisTemplate.opsForValue().increment(key, -delta);\n    }\n\n\n    // ================================Map=================================\n\n\n    /**\n     * HashGet\n     *\n     * @param key  键 不能为null\n     * @param item 项 不能为null\n     */\n    public Object hget(String key, String item) {\n        return redisTemplate.opsForHash().get(key, item);\n    }\n\n\n    /**\n     * 获取hashKey对应的所有键值\n     *\n     * @param key 键\n     * @return 对应的多个键值\n     */\n    public Map<Object, Object> hmget(String key) {\n        return redisTemplate.opsForHash().entries(key);\n    }\n\n\n    /**\n     * HashSet\n     *\n     * @param key 键\n     * @param map 对应多个键值\n     */\n    public boolean hmset(String key, Map<String, Object> map) {\n        try {\n            redisTemplate.opsForHash().putAll(key, map);\n            return true;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return false;\n        }\n    }\n\n\n    /**\n     * HashSet 并设置时间\n     *\n     * @param key  键\n     * @param map  对应多个键值\n     * @param time 时间(秒)\n     * @return true成功 false失败\n     */\n    public boolean hmset(String key, Map<String, Object> map, long time) {\n        try {\n            redisTemplate.opsForHash().putAll(key, map);\n            if (time > 0) {\n                expire(key, time);\n            }\n            return true;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return false;\n        }\n    }\n\n\n    /**\n     * 向一张hash表中放入数据,如果不存在将创建\n     *\n     * @param key   键\n     * @param item  项\n     * @param value 值\n     * @return true 成功 false失败\n     */\n    public boolean hset(String key, String item, Object value) {\n        try {\n            redisTemplate.opsForHash().put(key, item, value);\n            return true;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return false;\n        }\n    }\n\n\n    /**\n     * 向一张hash表中放入数据,如果不存在将创建\n     *\n     * @param key   键\n     * @param item  项\n     * @param value 值\n     * @param time  时间(秒) 注意:如果已存在的hash表有时间,这里将会替换原有的时间\n     * @return true 成功 false失败\n     */\n    public boolean hset(String key, String item, Object value, long time) {\n        try {\n            redisTemplate.opsForHash().put(key, item, value);\n            if (time > 0) {\n                expire(key, time);\n            }\n            return true;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return false;\n        }\n    }\n\n\n    /**\n     * 删除hash表中的值\n     *\n     * @param key  键 不能为null\n     * @param item 项 可以使多个 不能为null\n     */\n    public void hdel(String key, Object... item) {\n        redisTemplate.opsForHash().delete(key, item);\n    }\n\n\n    /**\n     * 判断hash表中是否有该项的值\n     *\n     * @param key  键 不能为null\n     * @param item 项 不能为null\n     * @return true 存在 false不存在\n     */\n    public boolean hHasKey(String key, String item) {\n        return redisTemplate.opsForHash().hasKey(key, item);\n    }\n\n\n    /**\n     * hash递增 如果不存在,就会创建一个 并把新增后的值返回\n     *\n     * @param key  键\n     * @param item 项\n     * @param by   要增加几(大于0)\n     */\n    public double hincr(String key, String item, double by) {\n        return redisTemplate.opsForHash().increment(key, item, by);\n    }\n\n\n    /**\n     * hash递减\n     *\n     * @param key  键\n     * @param item 项\n     * @param by   要减少记(小于0)\n     */\n    public double hdecr(String key, String item, double by) {\n        return redisTemplate.opsForHash().increment(key, item, -by);\n    }\n\n\n    // ============================set=============================\n\n\n    /**\n     * 根据key获取Set中的所有值\n     *\n     * @param key 键\n     */\n    public Set<Object> sGet(String key) {\n        try {\n            return redisTemplate.opsForSet().members(key);\n        } catch (Exception e) {\n            e.printStackTrace();\n            return null;\n        }\n    }\n\n\n    /**\n     * 根据value从一个set中查询,是否存在\n     *\n     * @param key   键\n     * @param value 值\n     * @return true 存在 false不存在\n     */\n    public boolean sHasKey(String key, Object value) {\n        try {\n            return redisTemplate.opsForSet().isMember(key, value);\n        } catch (Exception e) {\n            e.printStackTrace();\n            return false;\n        }\n    }\n\n\n    /**\n     * 将数据放入set缓存\n     *\n     * @param key    键\n     * @param values 值 可以是多个\n     * @return 成功个数\n     */\n    public long sSet(String key, Object... values) {\n        try {\n            return redisTemplate.opsForSet().add(key, values);\n        } catch (Exception e) {\n            e.printStackTrace();\n            return 0;\n        }\n    }\n\n\n    /**\n     * 将set数据放入缓存\n     *\n     * @param key    键\n     * @param time   时间(秒)\n     * @param values 值 可以是多个\n     * @return 成功个数\n     */\n    public long sSetAndTime(String key, long time, Object... values) {\n        try {\n            Long count = redisTemplate.opsForSet().add(key, values);\n            if (time > 0) {\n                expire(key, time);\n            }\n            return count;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return 0;\n        }\n    }\n\n\n    /**\n     * 获取set缓存的长度\n     *\n     * @param key 键\n     */\n    public long sGetSetSize(String key) {\n        try {\n            return redisTemplate.opsForSet().size(key);\n        } catch (Exception e) {\n            e.printStackTrace();\n            return 0;\n        }\n    }\n\n\n    /**\n     * 移除值为value的\n     *\n     * @param key    键\n     * @param values 值 可以是多个\n     * @return 移除的个数\n     */\n\n\n    public long setRemove(String key, Object... values) {\n        try {\n            Long count = redisTemplate.opsForSet().remove(key, values);\n            return count;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return 0;\n        }\n    }\n\n\n    // ===============================list=================================\n\n\n    /**\n     * 获取list缓存的内容\n     *\n     * @param key   键\n     * @param start 开始\n     * @param end   结束 0 到 -1代表所有值\n     */\n    public List<Object> lGet(String key, long start, long end) {\n        try {\n            return redisTemplate.opsForList().range(key, start, end);\n        } catch (Exception e) {\n            e.printStackTrace();\n            return null;\n        }\n    }\n\n\n    /**\n     * 获取list缓存的长度\n     *\n     * @param key 键\n     */\n    public long lGetListSize(String key) {\n        try {\n            return redisTemplate.opsForList().size(key);\n        } catch (Exception e) {\n            e.printStackTrace();\n            return 0;\n        }\n    }\n\n\n    /**\n     * 通过索引 获取list中的值\n     *\n     * @param key   键\n     * @param index 索引 index>=0时， 0 表头，1 第二个元素，依次类推；index<0时，-1，表尾，-2倒数第二个元素，依次类推\n     */\n    public Object lGetIndex(String key, long index) {\n        try {\n            return redisTemplate.opsForList().index(key, index);\n        } catch (Exception e) {\n            e.printStackTrace();\n            return null;\n        }\n    }\n\n\n    /**\n     * 将list放入缓存\n     *\n     * @param key   键\n     * @param value 值\n     */\n    public boolean lSet(String key, Object value) {\n        try {\n            redisTemplate.opsForList().rightPush(key, value);\n            return true;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return false;\n        }\n    }\n\n\n    /**\n     * 将list放入缓存\n     *\n     * @param key   键\n     * @param value 值\n     * @param time  时间(秒)\n     */\n    public boolean lSet(String key, Object value, long time) {\n        try {\n            redisTemplate.opsForList().rightPush(key, value);\n            if (time > 0) {\n                expire(key, time);\n            }\n            return true;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return false;\n        }\n    }\n\n\n    /**\n     * 将list放入缓存\n     *\n     * @param key   键\n     * @param value 值\n     * @return\n     */\n    public boolean lSet(String key, List<Object> value) {\n        try {\n            redisTemplate.opsForList().rightPushAll(key, value);\n            return true;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return false;\n        }\n    }\n\n\n    /**\n     * 将list放入缓存\n     *\n     * @param key   键\n     * @param value 值\n     * @param time  时间(秒)\n     * @return\n     */\n    public boolean lSet(String key, List<Object> value, long time) {\n        try {\n            redisTemplate.opsForList().rightPushAll(key, value);\n            if (time > 0) {\n                expire(key, time);\n            }\n            return true;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return false;\n        }\n    }\n\n\n    /**\n     * 根据索引修改list中的某条数据\n     *\n     * @param key   键\n     * @param index 索引\n     * @param value 值\n     * @return\n     */\n    public boolean lUpdateIndex(String key, long index, Object value) {\n        try {\n            redisTemplate.opsForList().set(key, index, value);\n            return true;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return false;\n        }\n    }\n\n\n    /**\n     * 移除N个值为value\n     *\n     * @param key   键\n     * @param count 移除多少个\n     * @param value 值\n     * @return 移除的个数\n     */\n    public long lRemove(String key, long count, Object value) {\n        try {\n            Long remove = redisTemplate.opsForList().remove(key, count, value);\n            return remove;\n        } catch (Exception e) {\n            e.printStackTrace();\n            return 0;\n        }\n    }\n\n\n}\n\n```\n\n## 5、编写 controller 测试\n\n```java\n\tprivate final RedisUtil redisUtil;\n    /**\n     * sy\n     * 验证redis整合\n     * @return ResultBody\n     */\n    @ApiOperation(value = \"验证redis整合\")\n    @GetMapping(value = \"/verifyRedis\")\n    public ResultBody verifyRedis() {\n\n        redisUtil.set(\"test\", \"ceshi\");\n        String value = (String) redisUtil.get(\"test\");\n\n        System.out.println(value);\n\n        return ResultBody.success();\n    }\n```\n\n# 十、Redis 事务和锁机制\n\n**Redis** 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序的执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。\n\n**Redis** 事务的主要作用就是<font color=\"red\">串联多个命令防止别的命令插队。</font>\n\n## 1、基本操作\n\n### 1）、Multi、Exec、Discard\n\n**Multi：**开始事务，进行组队阶段\n\n**Exec：**执行阶段，按照顺序执行\n\n**Discard：**放弃执行\n\n从输入 **Multi** 命令开始，输入的命令都会依次进入命令队列中，但不会执行，直到输入 **Exec** 后，**Redis** 都会将之前的命令队列中的命令依次执行。\n\n组队的过程中可以通过 **Discard** 来放弃组队\n\n![图片加载失败](29.png)\n\n**示例：**\n\n```shell\n# 开启事务\nmulti\nset key1 value1\nset key2 value2\n# 执行\nexec\nkeys *\n\n# 开启事务\nmulti\nset a1 v1\nset a2 v2\n# 放弃事务\ndiscard\nkeys *\n```\n\n### 2）事务的错误处理\n\n事务可能会出现的错误有两种：\n\n1. 组队中某个命令出现了报告错误，执行时整个的所有队列都会被取消\n\n   ![图片加载失败](30.png)\n\n   **示例：**\n\n   ![图片加载失败](31.png)\n\n   \n\n2. 执行阶段某个命令出现了错误，则只有报错的命令不会执行，而其他命令正常执行。\n\n   ![图片加载失败](32.png)\n\n## 2、事务冲突的问题\n\n**场景：**有很多人有你的账户，同事去参加双十一抢购\n\n## 3、例子\n\n- 一个请求想给金额减8000\n- 一个请求想给金额减5000\n- 一个请求想给金额减1000\n\n![图片加载失败](33.png)\n\n### 1）解决方案\n\n#### 1. 悲观锁\n\n**什么是悲观锁：**顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿到数据的时候都会上锁，这样别人想去拿这个数据就会 **block（阻塞）**,知道他用完数据，将锁释放后，被人才可以拿到数据。<font color=\"red\">传统的关系型数据库中就用到了很多这种锁机制</font>，比如<font color=\"red\">行锁</font>，<font color=\"red\">表锁</font>等，<font color=\"red\">读锁</font>，<font color=\"red\">写锁</font>等，都是在做操作之前先上锁<font color=\"red\">锁</font>。\n\n![图片加载失败](34.png)\n\n#### 2.乐观锁\n\n**什么是乐观锁：**顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。<font color=\"red\">乐观锁适用于多读的应用类型，这样可以提高吞吐量。Redis 就是利用这种 check-and-set 机制实现事务的</font>。\n\n![图片加载失败](35.png)\n\n#### 3.watch key [key...] 命令\n\n在执行 **Multi** 之前，先执行 **watch key [keys...]** 命令，可以监视一个（或多个）**key**，如果在事务执行之前这个（这些）**key** 被其他命令所改动，那么事务将会被打断\n\n**测试例子：**\n\n![图片加载失败](41.png)\n\n![图片加载失败](42.png)\n\n## 4、Redis 事务三特性\n\n1. 单独的隔离操作：\n\n   事务中的所有命令都会序列化、按顺序的执行。事务在执行的过程中，不会被其他客户端发送的命令请求打断。\n\n2. 没有隔离级别的概念：\n\n   队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行。\n\n3. 不保证原子性：\n\n   事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚。\n\n## 5、秒杀案例\n\n### 1）基本实现\n\n**页面：**\n\n![图片加载失败](36.png)\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\" xmlns:th=\"http://www.thymeleaf.org\">\n<!--<script th:src=\"@{/webjars/jquery/3.5.1/jquery.min.js}\"></script>-->\n<script src=\"webjars/jquery/3.5.1/jquery.min.js\"></script>\n\n<head>\n    <meta charset=\"UTF-8\">\n    <title>Title</title>\n</head>\n<body>\n<h1>iPhone 13 pro!!! 1元秒杀！！！</h1>\n<form id=\"msform\" action=\"http://localhost:8079/redis/ms/doseckill\">\n    <input type=\"hidden\" id=\"prodid\" name=\"prodid\" value=\"0101\">\n    用户id：<input type=\"text\" id=\"userId\" name=\"userid\">\n    <input type=\"button\" id=\"miaosha_btn\" name=\"seckill_btn\" value=\"秒杀点我\"/>\n</form>\n\n</body>\n<script>\n    $(function () {\n        var form = $(\"#msform\");\n\n        var parems = {};\n\n        $(\"#miaosha_btn\").click(function () {\n            parems.userId = $(\"#userId\").val();\n            parems.prodid = $(\"#prodid\").val();\n            $.ajax({\n                type: \"post\",\n                url: \"http://localhost:8079/redis/ms/doseckill\",\n                data: JSON.stringify(parems),\n                dataType: \"json\",\n                contentType: \"application/json;charset=utf-8\",\n                success: function (data) {\n                    // if (data === \"false\") {\n                    //     alert(\"抢光了\");\n                    //     $(\"#miaosha_btn\").attr(\"disabled\", true);\n                    // }\n                    if (data.code === \"00000\") {\n                        alert(data.message);\n                        $(\"#miaosha_btn\").attr(\"disabled\", true);\n                    } else if (data.code === \"50000\") {\n                        alert(data.message);\n                    }\n                }\n            })\n        })\n\n    })\n</script>\n</html>\n```\n\n**实体类：**\n\n```java\npackage com.sy.jedis_redisdemo.restful.beans;\n\nimport lombok.Data;\n\n/**\n * @ClassName User\n * @Description TODO\n * @Author sy\n * @Date 2021/8/16 19:39\n * @Version 1.0\n **/\n@Data\npublic class User {\n\n    public String userId;\n\n    public String prodid;\n}\n\n```\n\n**Controller：**\n\n```java\npackage com.sy.jedis_redisdemo.restful.controller;\n\nimport com.sy.api.context.ResultBody;\nimport com.sy.jedis_redisdemo.restful.beans.User;\nimport com.sy.jedis_redisdemo.restful.service.MsService;\nimport io.swagger.annotations.Api;\nimport io.swagger.annotations.ApiOperation;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.web.bind.annotation.*;\n\n/**\n * @ClassName MsController\n * @Description TODO\n * @Author sy\n * @Date 2021/8/16 18:14\n * @Version 1.0\n **/\n@Api(value = \"秒杀\", tags = \"秒杀\")\n@RestController\n@RequestMapping(\"/ms\")\npublic class MsController {\n\n    @Autowired\n    private MsService msService;\n\n    @ApiOperation(value = \"秒杀\")\n    @PostMapping(value = \"/doseckill\")\n    public ResultBody doseckill(@RequestBody User user) {\n        return msService.doseckill(user);\n    }\n}\n```\n\n**Service：**\n\n```java\npackage com.sy.jedis_redisdemo.restful.service;\n\nimport com.sy.api.context.ResultBody;\nimport com.sy.jedis_redisdemo.restful.beans.User;\n\n/**\n * @ClassName MsService\n * @Description TODO\n * @Author sy\n * @Date 2021/8/16 19:43\n * @Version 1.0\n **/\npublic interface MsService {\n\n    ResultBody doseckill(User user);\n}\n```\n\n**ServiceImpl：**\n\n```java\npackage com.sy.jedis_redisdemo.restful.service.impl;\n\nimport com.baomidou.mybatisplus.extension.api.R;\nimport com.sy.api.context.ResultBody;\nimport com.sy.jedis_redisdemo.restful.beans.User;\nimport com.sy.jedis_redisdemo.restful.service.MsService;\nimport com.sy.jedis_redisdemo.utils.RedisUtil;\nimport org.apache.commons.lang3.StringUtils;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Service;\nimport redis.clients.jedis.Jedis;\nimport sun.net.RegisteredDomain;\n\n/**\n * @ClassName MsServiceImpl\n * @Description TODO\n * @Author sy\n * @Date 2021/8/16 19:43\n * @Version 1.0\n **/\n@Service\npublic class MsServiceImpl implements MsService {\n\n    @Autowired\n    private RedisUtil redisUtil;\n\n    @Override\n    public ResultBody doseckill(User user) {\n        //1、userId 和 prodid 非空判断\n        if (StringUtils.isEmpty(user.userId) || StringUtils.isEmpty(user.prodid)) {\n            return ResultBody.error(\"用户或商品id不能为空\");\n        }\n\n        //2、连接 redis\n        //Jedis jedis = new Jedis(\"192.168.111.144\", 6379);\n        //RedisUtil redisUtil = new RedisUtil();\n\n        //3、拼接key\n        //3.1 库存key\n        String kcKey = \"sk:\" + user.prodid + \":kc\";\n        //3.2 秒杀成功用户key\n        String userKey = \"sk:\" + user.prodid + \":user\";\n\n        //4、获取库存，如果库存为null，秒杀还未开始\n        Object kc = redisUtil.get(kcKey);\n        if (kc == null) {\n            return ResultBody.error(\"秒杀未开始，请等待！\");\n        }\n        //5、判断用户是否重复秒杀操作\n        if (redisUtil.sHasKey(userKey, user.userId)) {\n            return ResultBody.error(\"已经秒杀成功，不能重复秒杀！\");\n        }\n\n        //6、判断库存数量，如果数量小于1，秒杀结束\n        if ((int)kc <= 0) {\n            return ResultBody.error(\"秒杀已经结束！\");\n        }\n\n        //7、秒杀过程\n        //7.1 库存 -1\n        redisUtil.decr(kcKey, 1);\n        //7.1 把秒杀成功用户添加到清单中\n        redisUtil.sSet(userKey, user.userId);\n        return ResultBody.success(\"秒杀成功！\");\n    }\n}\n\n```\n\n### 2）ab工具模拟并发\n\n#### 2-1）安装 **httpd-tools**\n\n执行 **yum install httpd-tools** 安装\n\n#### 2-2）命令及常用参数\n\n**常用参数：**ab --list 可查看所有参数\n\n```shell\n\t# 请求次数\n    -n requests     Number of requests to perform\n    # 并发次数\n    -c concurrency  Number of multiple requests to make at a time\n    # 提交参数,参数要写到文件中，针对post,使用时要设置 -T\n    -p postfile     File containing data to POST. Remember also to set -T\n    -u putfile      File containing data to PUT. Remember also to set -T\n    # 设置 content-type，和你请求的 content-type 一样\n    -T content-type Content-type header to use for POST/PUT data, eg.\n                    'application/x-www-form-urlencoded'\n                    Default is 'text/plain'  \n```\n\n**命令：**\n\n```shell\n# 1000 次请求，其中并发请求有100个，参数文件是 postfiel\nab -n 1000 -c 100 -p postfile -T 'application/json;charset=utf-8' http://192.168.111.2:8079/redis/ms/doseckill\n```\n\n#### 2-3）测试\n\n1. **创建 postfile 参数文件内容（用于 ab 工具测试并发发送的参数）：**\n\n   ```json\n   {\"prodid\" : \"0101\"}\n   ```\n\n2. **修改 controller：**因为同一个 **userId** 不能重复秒杀，所以我们在这里随机一个。\n\n   ![图片加载失败](37.png)\n\n3. **执行命令进行测试：**\n\n   ```shell\n   ab -n 1000 -c 100 -p postfile -T 'application/json;charset=utf-8' http://192.168.111.2:8079/redis/ms/doseckill\n   ```\n\n4. **查看执行结果：**\n\n   执行命令的结果：\n\n   ![图片加载失败](38.png)\n\n   ![图片加载失败](39.png)\n\n   **redis** 中数据情况：\n\n   ![图片加载失败](40.png)\n\n5. 出现的问题：\n\n   - 在上面测试结果中可以看到库存数量变为了 -35 ，这里出现的就是 **超卖** 的问题\n   - 还可能会出现 **连接超时的问题**\n\n### 3）超卖和连接超时问题解决\n\n#### 3-1）连接超时问题\n\n这个问题在 **[SpringBoot 整合 Redis](https://sunyubk.github.io/2021/08/06/Redis%E5%AD%A6%E4%B9%A0/#%E4%B9%9D%E3%80%81SpringBoot-%E6%95%B4%E5%90%88-Redis)** </a>中，通过 **yml，redisConfig，RedisUtils** 已经解决了\n\n#### 3-2）超卖问题\n\n##### 1.setnx 解决\n\n![图片加载失败](44.png)\n\n##### 2.Redisson 解决\n\n1. 添加依赖\n\n   ```xml\n           <!--redisson-->\n           <dependency>\n               <groupId>org.redisson</groupId>\n               <artifactId>redisson-spring-boot-starter</artifactId>\n               <version>3.13.6</version>\n           </dependency>\n   ```\n\n2. 修改 **serviceImpl**\n\n   ![图片加载失败](45.png)\n   \n   这里不用考虑 锁误删的问题，因为Redisson内部已经拼接了，见下图：\n   \n   这里的 **id** 是 **ConnectionManager** 的一个属性，继续追源码你会发现他也是一个 **UUID** 类型的。\n   \n   ![图片加载失败](91.png)\n\n# 十一、Redis 持久化\n\n## 1、RDB\n\n### 1）什么是 RDB\n\n**RDB** 就是在指定的<font color=\"red\">时间间隔</font>内将内存中的数据集<font color=\"red\">快照</font>写入磁盘。\n\n直白的说就是：在某一时刻记录下数据快照，在时间间隔内将数据存储到磁盘，恢复的时候也是将快照文件直接读到内存中\n\n### 2）备份是如何执行的\n\n**Redis** 会单独创建一个 **(Fork)** 一个子进程来进行持久化，会先将数据写入到一个临时文件中，等持久化过程都结束了，再用这个<font color=\"red\">临时文件替换上次持久化好的文件</font>。整个过程中，主进程不进行任何 **IO** 操作，这就确保了极高的性能。如果需要大规模的数据恢复，而且对于数据恢复的完整性不是非常敏感，那 **RDB** 方式要比 **AOF** 方式更加高效。\n\n**RDB** 的缺点就是：最后一次持久化后的数据可能丢失。\n\n### 3）备份文件位置与备份规则\n\n位置：默认在那个目录下启动 **redis** 服务，文件就生成在哪里。\n\n![图片加载失败](46.png)\n\n规则：\n\n![图片加载失败](47.png)\n\n### 4）命令 save VS bgsave\n\n**Redis** 默认情况下是自动进行备份的。也可以使用下面两个命令进行手动备份。\n\n**save：**save 时只管保存，其他不管，全部阻塞。不建议\n\n<font color=\"red\">**bgsave：** Redis 会在后台异步进行快照操作，快照同时还可以响应客户端请求。</font>\n\n## 2、AOF\n\n### 1）什么是 AOF\n\n<font color=\"red\">以 **日志** 的形式类记录每个写操作（增量保存）</font>，将 **Redis** 执行过的所有写指令记录下来（<font color=\"red\">读操作不记录</font>），<font color=\"red\">只许追加文件但不可以改写文件</font>，**Redis** 启动之初会读取该文件重新构建数据。简单的来说就是根据日志文件的内容将所有指令从前到后执行一次来完成数据的恢复工作。\n\n### 2）AOF 持久化流程\n\n1. 客户端的请求写命令会被 **append** 追加到 **AOF** 缓冲区内；\n2. **AOF** 缓冲区根据 **AOF** 持久化策略 **[always，everysec，no]**，将操作 **sync** 同步到磁盘的 **AOF** 文件中；\n3. **AOF** 文件大小超过重写策略或手动重写时，会对 **AOF** 文件 **rewrite** 重写，压缩 **AOF** 文件的容量；\n4. **Redis** 服务重启是，会重新 **load** 加载 **AOF** 文件中的写操作达到数据恢复的目的；\n\n### 3）AOF 默认不开启\n\n可以再 **redis.conf** 中配置文件名称，默认为：**appendonly.aof**\n\n**AOF** 文件的保存路径与 **RDB** 的路径一致\n\n### 4）AOF 和 RDB 同时开启，Redis 听谁的？\n\n**AOF** 和 **RDB** 同时开启，系统默认取 **AOF** 的数据（数据不会存在丢失情况）\n\n### 5）AOF 文件损坏xiuf\n\n- 如果遇到 **AOF** 文件损坏，可以通过：/bin/<font color=\"red\">redis-check-for-aof--fix appendonly.aof</font> 进行恢复\n- 备份被写坏的 **AOF** 文件\n- 恢复：重启 **Redis**，然后会自动加载 **AOF** 文件\n\n### 6）AOF 同步频率设置\n\n1. **appendfsync always**\n\n   始终同步，每次 **Redis** 的写操作都会like记入日志；性能比较差，但是数据的完整性比较好。\n\n2. **appendfsync everysec**\n\n   每秒同步，每秒记入日志一次，如果宕机，本秒的数据可能会丢失\n\n3. **appendfsync no**\n\n   **Redis** 不主动进行同步，把同步时机交给操作系统。\n\n### 7）Rewrite 压缩\n\n当 **AOF** 文件 >= 设置定文件大小后，会对 **AOF** 文件进行<font color=\"red\">压缩重写</font>\n\n例：\n\n```shel\n# 我们实际执行的指令\nset k1 v1\nset k2 v2\n\n压缩后的\nset k1 v1 k2 v2\n```\n\n<font color=\"red\">其实 AOF 的压缩重写，就是把一些命令重写为一条命令，不去关注过程，只关注最后的结果。</font>\n\n# 十二、Redis 主从复制\n\n## 1、什么是主从复制\n\n主机数据更新后根据配置和策略，自动同步到备机的 <font color=\"red\">master/slaver 机制</font>，  <font color=\"red\">**Master** 以写为主，**Slaver** 以读为主</font>。\n\n## 2、能干嘛\n\n- 读写分离，性能扩展。\n\n- 容灾快速恢复\n\n  如果某一台从机出现问题，可以切换另一台从机。如果是主机出现问题，则可以通过集群来解决。\n\n  ![图片加载失败](48.png)\n\n## 3、主从配置\n\n这里是在一台虚拟机中，通过不同端口来模拟多台服务器\n\n1. 新建一个目录，名字自己定义就好了。\n\n2. 将我们原本的 **redis.conf** 复制到新创建的目录中。\n\n   ![图片加载失败](49.png)\n\n3. 创建三个配置文件，分别以端口进行区别，内容配置也要进行相应的修改\n\n   ![图片加载失败](50.png)\n\n   ```shell\n   # 引入基本的配置文件\n   include /usr/local/myredis/redis.conf\n   # 重新配置的内容，可以覆盖基本配置中配置的\n   pidfile /var/run/redis_6379.pid\n   port 6379\n   dbfilename dump6379.rdb\n   ```\n\n4. 可以看到这里我们已经起来了这三个 **Redis**\n\n   ![图片加载失败](51.png)\n\n5. 连接三台 **Redis** 并查看信息，可以看到三台 **Redis** 都是 **master(主)**\n\n   ![图片加载失败](52.png)\n\n   ![图片加载失败](53.png)\n\n   ![图片加载失败](54.png)\n\n6. 配置主从关系：**配从（库）不配主（库）**\n\n   ```shell\n   # 在从机中使用命令配置，ip：主机ip，port：主机端口\n   slaveof ip port\n   \n   # 取消从服务器配置，会重新变成主服务器\n   slaveof no one\n   ```\n\n7. 查看信息已经可以看到，角色（role）已经为从机（slave）\n\n   ![图片加载失败](55.png)\n\n8. 测试\n\n   - 在主机中新增一个 **key**\n\n     ![图片加载失败](56.png)\n\n   - 在从机中查看\n\n     ![图片加载失败](57.png)\n\n   <font color=\"red\">注意：写操作只能在主机中进行，从机中只能进行读操作</font>\n\n   ![图片加载失败](58.png)\n\n## 4、主从复制的原理\n\n1. 当从服务器（**slave**）连接上主服务器（**master**）之后，从服务器（**slave**）会向主服务器（**master**）发送进行数据同步的消息\n2. **master** 接到 **slave** 发送过来的同步消息后，把 **master** 的数据会持久化到 **RDB** 文件，把 **RDB** 文件发送给 **slave**，**slave** 拿到 **RDB** 文件进行读取\n3. **master** 每次进行写操作后，会和 **slave** 进行同步数据。\n\n<font color=\"red\">注意：</font>\n\n上面第 2 步是 **slave** 主动同步数据（全量复制），第 3 步是 **master** 主动同步数据（增量复制）\n\n- **全量复制：**从服务器（**slave**）主动发送消息同步数据\n- **增量复制：**主服务器（**master**）将写操作命令传给从服务器（**slave**）进行数据同步\n\n## 5、一主二仆\n\n**特点：**\n\n1. 当某一台从服务器挂掉之后再重启，他重新变成一个主机，并不会恢复成原来的从服务器\n2. 当某一台冲服务器挂掉之后，主服务数据发生了变动，从服务器重启之后，重新设置成主服务的从服务器，那么他会将主服务器的数据复制过来\n3. 当主服务挂掉之后，从服务器还是从服务器，并且可以看到主服务器已经挂掉了（down），并不会上位变成主服务器。当主服务器重新启动之后，依旧是主服务器，两台从服务器还是他小弟，并且可以再信息中看到大哥的状态是启动的（up）\n\n**测试：**\n\n1. **shutdown** 掉 6381，查看主服务器（6379） 的信息，我们可以看到主服务器信息中只有一台从服务器了\n\n   ![图片加载失败](59.png)\n\n2. 我们在 主服务器（6379）中随意添加几条数据。\n\n   ![图片加载失败](62.png)\n\n3. 重新启动 6381，并查看信息，我们可以看到他重新变成了主服务器\n\n   ![图片加载失败](60.png)\n\n4. 我们将 6381 重新设置成从服务器，并分别查看他和主服务器的信息，可以看到他已经变成了从服务器，而且主服务器的信息中显示有两台从服务器。\n\n   ![图片加载失败](61.png)\n\n5. 查看从服务器中的数据，可以看到和主服务器是一样的\n\n   ![图片加载失败](63.png)\n\n## 6、薪火相传\n\n**薪火相传** 我们可以理解为 **组织架构树** 或者我们实际工作中**项目经理、组长、组员**这种结构。\n\n就是说：\n\n- 6379 为主服务器\n- 6380 是 6379 的从服务器\n- 6381 是 6380 的服务器\n\n这样，6379 数据会同步给 6380 ，6380 再同步给 6381。\n\n**缺点：**\n\n当 6380 挂掉了，那么 6379 的数据也无法同步给 6381了。\n\n这里可以自己进行测试一下，我这里就不实际进行操作了。\n\n## 7、反客为主\n\n其实这个就是我们上面提到的 **slaveof no one** 命令，可已将从机变为主机。\n\n**缺点：** 需要手动完成。\n\n## 8、哨兵模式\n\n### 1）什么是哨兵模式\n\n<font color=\"red\">反客为主的自动版</font>，能够后台监控主机是否故障，如果故障了，根据投票数自动将从库转换为主库。\n\n其实就像是 **zookeeper** 集群的选举。<font color=\"#FFFFFF\">农奴翻身把歌唱，噢耶！</font>\n\n### 2）如何使用\n\n1. 设置为一主二仆/多仆模式\n\n2. 创建 **sentinel.conf** 文件，目录自定义，我们这里就放在和 **redis6379.conf** 同级的目录下了\n\n3. 配置哨兵，编写 **sentinel.conf** 配置文件内容\n\n   ```shell\n   # sentinel 哨兵\n   # monitor 监控\n   # mymaster 为监控对象起的服务器名称，其实就是为 master 主机起个别名\n   # 192.168.111.144 6379 主机 ip 和端口\n   # 1 至少有多少个哨兵同意迁移的数量，通俗的说就是：需要有多少个从机同意才能切换为主机，这里个人建议设置为从机数量的一半以上。类似于 zookeeper 的选举\n   sentinel monitor mymaster 192.168.111.144 6379 1\n   ```\n\n4. 启动哨兵，使用 **redis-sentinel** 启动\n\n   ![图片加载失败](64.png)\n\n   ![图片加载失败](65.png)\n\n   注意，哨兵服务的默认端口为：26379\n\n5. 测试，关掉 6379，查看哨兵窗口变化\n\n   ![图片加载失败](66.png)\n\n   这里通过控制台信息我们可以看到 6381 被选为了主服务器，6380 变成了 6381 的从机。\n\n   还有一个信息就是，6379 还在。那么当 6379 重新启动后会变成什么样呢？这里我们将 6379 重启，并查看信息。\n\n   ![图片加载失败](67.png)\n\n   ![图片加载失败](68.png)\n\n   通过上面的信息我们可以看到，6379 变成了 6381 的从机。\n\n6. 复制延时\n\n   哨兵模式的缺点，由于所有的写操作都是在 **Master** 上进行的，然后同步更新到 **Slave** 上，所以从 **Master** 同步到 **Slave** 会有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，**Slave** 机器数量的增加也会使这个问题更加严重。\n\n### 3）故障恢复\n\n![图片加载失败](69.png)\n\n- 优先级在 **redis.conf** 中默认：**replica-priority 100** ，值越小优先级越高\n\n  ![图片加载失败](70.png)\n\n- 偏移量是指获得原主机数据最全的\n\n- 每个 **Redis** 实例启动后都会随机生成一个 40 位的 **runid**。\n\n### 4）springboot 主从复制\n\n只需要在 **yml** 配置文件中进行相应配置即可：\n\n![图片加载失败](71.png)\n\n服务启动出现了报错：\n\n```java\n// 哨兵哨兵命令返回少于2个节点!在Redis配置中至少应该定义两个哨兵。设置checkSentinelsList = false以避免此检查。\nSENTINEL SENTINELS command returns less than 2 nodes! At least two sentinels should be defined in Redis configuration. Set checkSentinelsList = false to avoid this check.\n```\n\n经过一番搜索并没有找到什么有用的，所以我又增加了两个哨兵@~@\n\n1. 修改原有的 **sentinel.conf** 配置文件，并重命名为 **sentinel6379.conf**\n\n   ```shell\n   sentinel monitor mymaster 192.168.111.144 6379 1\n   protected-mode no\n   port 26379\n   ```\n\n2. 新增两个配置文件，分别是：**sentinel6380.conf**，**sentinel6381.conf**，只需要修改一下 **port** ，分别是：26380，26381\n\n启动服务/测试类测试：\n\n![图片加载失败](72.png)\n\n执行后可以到 **Redis** 中看一下数据是不是已经存进去了。\n\n参考：[springboot+redis的sentinel实现哨兵模式(超详细)](https://zhuanlan.zhihu.com/p/152462924)\n\n# 十三、Redis 集群\n\n## 1、问题\n\n1. 容量不够，**redis** 如何进行扩容？\n2. 并发写操作，**redis** 如何分摊？\n\n另外，主从模式，薪火相传模式，主机宕机，导致 **ip** 地址发生变化，应用程序中配置需要修改对应的主机地址、端口等信息。\n\n之前通过代理主机来解决，但是 **redis3.0** 中提供了解决方案。就是 <font color=\"red\">无中心化集群</font> 配置。\n\n## 2、什么是集群？\n\n- **Redis** 集群实现了对 **Redis** 的水平扩容，即启动 **N** 个 **Redis** 节点，将这个数据库分布存储在这 **N** 个节点中，每个节点存储总数据的 **1/N**。\n- **Redis** 集群通过分区**（partition）**来提供一定程度的可用性**（availability）**：即使集群中有一部分节点失效或者无法进行通讯，集群也可以继续处理命令请求。\n\n## 3、Redis 集群的搭建\n\n这里我们还是在同一台虚拟机中以不同的端口的方式来模拟搭建，依旧是 **主从复制** 中用到的目录就可以。\n\n创建六个实例分别是：**6379、6380、6381、6389、6390、6391**（三主三从）。\n\n1. 删除掉之前测试产生的 **dump、aof** 文件。\n\n2. 我们在 **redis_6379.conf** 的基础上配置基本信息\n\n   ![图片加载失败](73.png)\n\n   ![图片加载失败](74.png)\n\n3. 在配置文件中增加集群相关配置\n\n   ![图片加载失败](75.png)\n\n   ```shell\n   include /usr/local/myredis/redis.conf\n   pidfile \"/var/run/redis_6379.pid\"\n   port 6379\n   dbfilename \"dump6379.rdb\"\n   logfile \"/usr/local/myredis/redis_err_6379.log\"\n   daemonize yes\n   dir \"/usr/local/myredis\"\n   # 开启集群\n   cluster-enabled yes\n   # 指定集群节点配置文件\n   cluster-config-file nodes_6379.conf\n   # 设定节点失联时间（毫秒），超时后集群自动进入主从切换\n   cluster-node-timeout 15000\n   ```\n\n4. 删除6380 6381 两个配置文件，并将我们刚才修改好的配置文件在复制出5份。\n\n   ![图片加载失败](76.png)\n\n5. 修改复制出来的那几份文件，修改相应的端口\n\n   ```shell\n   # 可以使用替换进行操作\n   vim redis6380.conf\n   :%s/6379/6380\n   ```\n\n   ![图片加载失败](77.png)\n\n6. 启动 6 个 **Redis** 服务，并查看节点配置文件是否正确生成了\n\n   ![图片加载失败](78.png)\n\n7. 将 6 个节点合成一个集群\n\n   - 进入到 **Redis** 安装目录的 **src** 中，或者是解压的目录中的 **src** 中。\n\n   - 使用命令进行合体\n\n     ```shell\n     # 注意下面的命令只能在安装目录的 src 下才可以使用，使用 ip，不要使用 127.0.0.1\n     # --cluster create 集群创建\n     # --cluster-replicas 1 采用最简单的方式配置集群，一主一从，正好三组。前 3 为主机，后 3 为从机\n     redis-cli --cluster create --cluster-replicas 1 192.168.111.144:6379 192.168.111.144:6380 192.168.111.144:6381 192.168.111.144:6389 192.168.111.144:6390 192.168.111.144:6391\n     ```\n\n   - 执行命令\n\n     ![图片加载失败](79.png)\n\n     执行命令后会展示分配的一些信息，并会询问我们是否接受这种分配方式，我们输入 **yes**\n\n     ![图片加载失败](80.png)\n\n8. 连接\n\n   ~~~shell\n   # -c 采用集群策略连接，设置数据会自动切换到相应的写主机\n   # 连接任何一个都可以，例如6379/6380/6381，会自动切换到写主机\n   redis-cli -c -p 6379\n   ~~~\n\n9. 查看集群节点信息：**cluster nodes**\n\n   我们可以在信息中看到哪一台是主机，哪一台是从机，和对应的主从。\n\n   ![图片加载失败](81.png)\n\n## 4、Redis cluster 如何分配这六个节点？\n\n- 一个集群至少要有三个主节点\n- 选项 **--cluster-replicas 1** 表示我们希望为集群中的每个主节点创建一个从节点。\n- 分配原则尽量保证每个主数据库运行在不同的 **IP** 地址，每个从库和主库不在一个 **IP** 地址上。\n\n## 5、什么是 slots(插槽)?\n\n通俗的来说就像是 洞 ，每个洞都可以放入东西。\n\n- 一个 **Redis** 集群包含 16384 个插槽（hash slot），数据库中的每个键都属于这 16384 个插槽中的其中一个。\n\n- 每个主节点都有他负责的一定范围的插槽，可以再节点信息中看到。\n\n  ![图片加载失败](82.png)\n\n- 集群会使用 **CRC16(key)%16384** 来计算 **key** 属于哪个插槽，其中的 **CRC16(key)** 语句用于计算键 **key** 的 **CRC16** 校验和。\n\n## 6、集群数据的新增与查询\n\n1. 新增（单个key/value、多个key/value）\n\n   - 下图可见，根据key计算除了插槽，并存储到了相应的主机中，并切换到了相应的主机\n\n     ![图片加载失败](83.png)\n\n   - 多个 key/value 新增\n\n     ```shell\n     # 错误方式,多个 key 不能同时插入一个插槽\n     mset name lucy age 20 addr china\n     #err:CROSSSLOT Keys in request don't hash to the same slot\n     \n     #正确方式，使用 {组名} 的方式新增数据\n     #这样就会根据{}中的组名去计算插槽\n     mset name{user} lucy age{user} 20 addr{user} china\n     ```\n\n2. 查询集群中的值\n\n   ```shell\n   # 获取 key 在集群中的插槽位置：cluster keyslot key\n   cluster keyslot k1\n   result: 12706\n   \n   # 获取插槽位置中有几个值，只能插槽所在的主机中用，否则返回 0\n   cluster countkeysinslot 12706\n   \n   # 获取指定插槽中count个 key，cluster get keysinslot slot count\n   # 获取 12706 这个插槽中的 key，获取 10 个\n   cluster getkeysinslot 12706 10\n   ```\n\n## 7、故障恢复\n\n1. 如果主节点下线，从节点能否自动提升为主节点？注意：<font color=\"red\">15 秒超时</font>\n\n   ![图片加载失败](84.png)\n\n   从上图可以看到，6379 下线之后，6380 在 15 秒之后提升为主节点了。\n\n2. 下线的主节点恢复之后，主从关系如何？\n\n   ![图片加载失败](85.png)\n\n   从上图可以看到，下线的主节点恢复后变成了从机。\n\n3. 如果某一段插槽的主从都挂掉了（集群中的某一组主从挂掉），那么这个集群是否还能继续使用？\n\n   根据 **redis.conf** 中 **cluster-require-full-coverage** 配置而变化的：\n\n   - 如果 **cluster-require-full-coverage** 为 **yes** ，那么，整个集群都挂掉。\n   - 如果 **cluster-require-full-coverage** 为 **no** ，那么就只有该主从不能用，也无法存储。\n\n## 8、springboot 集群的配置\n\n1. 修改 **yml** 配置文件\n\n   ![图片加载失败](86.png)\n\n2. 测试类测试\n\n   ![图片加载失败](87.png)\n\n这样简单的配置就好了，我这里没有报错一切顺利，因为我也没用过，所以这些应该是很基础的配置。\n\n## 9、Redis 集群的好处与不足\n\n1. 好处：\n   - 实现扩容\n   - 分摊压力\n   - 无中心配置，相对简单\n2. 不足\n   - 多键操作是不被支持的\n   - 多键的 **Redis** 事务是不被支持的。**lua** 脚本不被支持。\n   - 由于集群方案出现的较晚，很多公司已经采用了其他的集群方案，而代理或者客户端分片的方案想要 **迁移** 至 **redis cluster**，需要整体迁移，而不是逐步过渡，复杂难度大\n\n# 十四、Redis 应用问题解决\n\n## 1、缓存穿透\n\n1. 什么是 **缓存穿透**\n\n   **缓存穿透：** 就是大量的请求 <font color=\"red\">访问缓存，获取不存在的数据</font>，这个时候就会去请求数据库（<font color=\"red\">数据库中也不存在</font>），导致数据库瘫痪或错误、宕掉等。\n\n   ![图片加载失败](88.png)\n\n2. 出现场景\n\n   一般出现在一下两种场景中：\n\n   - **redis** 中查询不到数据\n   - 出现很多非正常 **url** 访问\n\n3. 解决方案\n\n   - <font color=\"red\">对空值缓存</font>\n\n     如果查询返回的数据为空（不管数据是不是存在），我们仍然把这个空结果（null）进行缓存，设置空结果的过期时间会很短，最长不会超过五分钟。\n\n   - <font color=\"red\">设置可以访问的名单（白名单）</font>\n\n     使用 **bitmaps** 类型定义一个可以访问的名单，名单 **id** 作为 **bitmaps** 的偏移量，每次访问和 **bitmaps** 里面的 **id** 进行比较，如果访问的 **id** 不在 **bitmaps** 中，进行拦截，不允许访问。\n\n   - <font color=\"red\">采用布隆过滤器</font>\n\n     这个底层其实就是一个 **bitmaps** ，只不过做了相应的封装等。\n\n     其实就是检索一个元素是否在一个集合中。\n\n     优点：空间效率和查询时间都远超一般的算法\n\n     缺点：有一定的误识别率和删除困难\n\n   - <font color=\"red\">进行实时监控</font>\n\n     当发现 **Redis** 的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，可以设置黑名单限制服务。\n\n## 2、缓存击穿\n\n1. 什么是 **缓存击穿**\n\n   **缓存击穿：** key 对应的数据在数据库中存在，但是在 **redis** 中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端 **DB** 加载数据并回设到缓存，这个时候并发的请求可能会瞬间把后端 **DB** 压垮\n\n   <font color=\"red\">注意：这里指的是某个 **key** 过期了，大量访问使用这个 **key**。并不是出现大量的 **key** 过期</font>\n\n   ![图片加载失败](89.png)\n\n2. 解决方案\n\n   - <font color=\"red\">预先设置热门数据</font>\n\n     在 **redis** 高峰访问之前，把一些热门数据提前存入到 **Redis** 中，并加大这些热门数据 **key** 的时长\n\n   - <font color=\"red\">实时调整</font>\n\n     现场监控那些数据热门，实时调整 **key** 的过期时长 \n\n   - <font color=\"red\">使用锁</font>\n\n     ![图片加载失败](90.png)\n\n## 3、缓存雪崩\n\n1. 什么是 **缓存雪崩**\n\n   **缓存雪崩：** 在极少时间段内，查询大量 **key** 的集中过期情况。\n\n2. 解决方案\n\n   - <font color=\"red\">构建多级缓存架构</font>\n\n     **nginx** 缓存 + **Redis** 缓存  + 其他缓存（**ehcache** 等）\n\n   - <font color=\"red\">使用锁或队列</font>\n\n     用加锁或者队列的方式来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。不适合高并发情况。\n\n   - <font color=\"red\">设置过期标志更新缓存</font>\n\n     记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程在后台去更新实际 **key** 的缓存\n\n   - <font color=\"red\">将缓存失效时间分散开</font>\n\n     比如我们可以再原有的失效时间基础上增加一个随机值，比如 1-5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。\n\n## 4、分布式锁\n\n###  1）什么是 **分布式锁**\n\n个人理解 **分布式锁** 就是应用在集群、分布式服务中。因为原单体单机部署的系统演化成分布式集群系统，由于分布式系统多线程、多进程且分布在不同的机器上，这样原来的单机部署情况下的并发锁策略就失效了，我们就需要一种跨 **JVM** 的互斥机制（锁）来控制共享资源的访问\n\n### 2）实现方式\n\n- 基于数据库实现\n\n- 基于缓存（**Redis** 等）\n\n  性能好\n\n- 基于 **zookeeper**\n\n  可靠性高\n\n### 3）使用 redis实现分布式锁\n\n其实就是 **setnx key value** 来设置一个 **key** 作为锁，释放锁就是删除掉这个 **key**。\n\n- 问题一：假如现在出现了别的情况，例如：加锁之后程序报错或由于别的原因没有释放该怎么办呢？\n\n  解决方式就是设置一个过期时间\n\n  ```shell\n  set key_lock 1\n  exprie key_lock 10\n  ```\n\n- 问题二：如果在设置过期时间的时候服务器突然死掉了或者由于一些其他原因设置失败了怎么办？\n\n  解决方式就是加锁的同时设置过期时间\n\n  ```shell\n  # 这个命令在上面说过，他的意思就是：新增一个 key 并设置他的时间，只有在这个 key 不存在的时候才能设置成功\n  set kye_lock 1 EX 10 NX\n  ```\n\n- 问题三：误删问题\n\n  这个可以通过添加 **UUID** 等方式解决，在上面的 [秒发案例的超卖问题中](https://sunyubk.github.io/2021/08/06/Redis%E5%AD%A6%E4%B9%A0/#3%EF%BC%89%E8%B6%85%E5%8D%96%E5%92%8C%E8%BF%9E%E6%8E%A5%E8%B6%85%E6%97%B6%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3) 中已经解决过了。\n\n# 案例\n\n## 案例一、\n\n场景：\n\n1. 一亿个用户，用户有频繁登录的，也有不经常登录的\n2. 如何记录用户的登录信息\n3. 如何查询活跃用户，[如： 连续登录的]\n\n```shell\n# 以位图的方式来解决\n# 用户的登录状态以 0/1来表示\n# 初始值 一亿个用户都没有登陆过，设置第3,5,7位用户在周一登录过\nsetbit mon 100000000 0\nsetbit mon 3 1\nsetbit mon 5 1\nsetbit mon 7 1\n\n# 设置第3,4,8位用户在周二登录过\nsetbit tue 100000000 0\nsetbit tue 3 1\nsetbit tue 4 1\nsetbit tue 8 1\n\n# 设置第3,6,9位用户在周三登录过\nsetbit wed 100000000 0\nsetbit wed 3 1\nsetbit wed 6 1\nsetbit wed 9 1\n\n# 按位与运算\n# res 为比较后返回的结果集\n# 例子：0100\n#      0101 \n#      0110\n# and 返回结果集是0100，位图的同一个位置都一样，则返回的是1，否则返回0\n# or  返回结果集是0111，位图的同一个位置有一个是1，则返回1\n# \n#使用一下命令则可以得到res,三天都登录了的用户\nbitop and res mon tue wed\n```\n\n \n","tags":["Redis"],"categories":["技术学习","Redis"]},{"title":"SpringCloud 学习","url":"/2020/09/07/SpringCloud-学习/","content":"\n# 1.什么是微服务架构\n\n　　微服务架构是一种架构模式或者架构风格，<font color=\"red\">它提倡将单一应用程序分成一组小的服务</font>，每个服务运行在其独立的自己的进程中，服务之间互相协调，配合，为用户提供最终价值。\n\n<!-- more -->\n\n# 2.什么是SpringCloud\n\n　　**SpringCloud** 就是分布式微服务架构下的一站式解决方案，是各个微服务架构落地技术的集合体，俗称为服务全家桶\n\n# 3.SpringCloud 和 SpringBoot 是什么关系\n\n1. **SpringBoot：**专注于快速方便的开发单个个体微服务\n\n   **SpringCloud：**是关注全局的微服务协调整理治理框架，它将 **SpringBoot** 开发的一个个单体微服务整合并管理起来，为各个微服务之间提供，管理配置、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等等集成服务\n\n2. **SpringBoot** 可以离开 **SpringCloud** 独立使用开发项目，但是 **SpringCloud** 离不开 **SpringBoot**，属于依赖关系。\n\n总的来说，**SpringBoot** 专注于快速、方便的开发单个微服务个体，**SpringCloud** 关注全局的服务治理框架\n\n# 4.SpringCloud 和 Dubbo 有什么区别？\n\n1. 在通讯机制方面：\n\n   **Dubbo** 是通过 **RPC** 远程过程调用\n\n   **SpringCloud** 是通过基于 **HTTP** 的 **RESTful api**\n\n2. 在自身技术方面：\n\n   **Dubbo** 就是像组装机，使用的基本都是第三方。选择的自由度很高，但是出问题的可能性也会随之提高。\n\n   **SpringCloud** 就像是买的一体机，一整套都是自己的。在 **Spring Source** 的整合下，做了大量的稳定性测试，使其拥有更高的稳定性。\n\n   具体见表：\n\n   |              | Dubbo         | Spring Cloud                 |\n   | :----------- | :------------ | :--------------------------- |\n   | 服务注册中心 | Zookeeper     | Spring Cloud Netflix Eureka  |\n   | 服务调用方式 | RPC           | REST API                     |\n   | 服务监控     | Duboo-monitor | Spring Boot Admin            |\n   | 断路器       | 不完善        | Spring Cloud Netflix Hystrix |\n   | 服务网关     | 无            | Spring Cloud Netflix Zuul    |\n   | 分布式配置   | 无            | Spring Cloud Config          |\n   | 服务跟踪     | 无            | Spring Cloud Sleuth          |\n   | 消息总线     | 无            | Spring Cloud Bus             |\n   | 数据流       | 无            | Spring Cloud Stream          |\n   | 批量任务     | 无            | Spring Cloud Task            |\n   | ......       | ......        | ......                       |\n\n\n**开发参考文档地址：**\n\n　　中文版API：[https://www.springcloud.cc/spring-cloud-dalston.html](https://www.springcloud.cc/spring-cloud-dalston.html)\n\n　　springcloud中国社区：[http://springcloud.cn/](http://springcloud.cn/)\n\n　　springcloud中文网：[https://www.springcloud.cc/](https://www.springcloud.cc/)\n\n至此，理论概念部分完成，接下来就是代码案例的编写了。\n\n# 5.代码案例\n\n## 1)Rest微服务案例-父工程构建\n\n首先，在working set 中新建一个maven porject。\n\nArtifact Id：父工程的名字\n\nPackaging：pom\n\n![图片加载失败](springcloud_1.png)\n\n## 2)pom文件编写\n\n```xml\n\n```\n\n\n\n# <font color=\"red\">*</font>框架搭建过程中发生的问题与解决方式\n\n## 1) 启动报错\n\n1. <font color=\"red\"><strong>java.lang.ClassNotFoundException: org.springframework.boot.bind.RelaxedPropertyResolver </strong></font>\n\n    　　关于这个报错信息我也百度了好久，说什么的都有，基本说的都是依赖版本问题，我也是一顿调整问题，后来将光标移动到了启动类的 **@SpringBootApplication** 注解上发现 **spring-boot-autoconfigure** 的版本为 1.5.X。因为我的父级 **pom** 中定义了 **springboot starter** 的版本为 **2.4.5** 所以意识到不对了。后来手动引入 **spring-boot-autoconfigure** 解决这个问题\n\n   ```xml\n   <dependency>\n   \t<groupId>org.springframework.boot</groupId>\n       <artifactId>spring-boot-autoconfigure</artifactId>\n       <version>${springboot.stater.version}</version>\n   </dependency>\n   ```\n\n\n## 2）扫描不到mapper接口\n\n1. <font color=\"red\"><strong>org.apache.ibatis.binding.BindingException: Invalid bound statement (not found)</strong></font>\n\n   这个报错产生的原因很多，列出我知道的几种\n\n   - mybatisPlusConfig 配置文件类上是否加入了 @MapperScan(”mapper路径“) 注解\n   - yml.xml 配置文件中 的 mapper.xml 文件扫描路径配置是否正确\n   - mapper.xml 文件存放路径是否正确，spring boot 默认是不会将 java 文件夹下的非java文件打包。所以如果mapper.xml文件应该放在 resource 静态资源路径下，如果放在 java文件夹下，则需要在 pom 中配置 resources 将xml打包\n   - idea 开发工具项目文件路径问题，idea是会隐藏空文件夹的，例如有的时候我们在resource 下创建了 mybatis.mapper 用来存放 mapper.xml 文件。这个时候的 mybatis.mapper 文件夹在 idea 中你可能认为他是两个文件夹，但是如果你在系统中找到这个文件夹，这个文件夹可能并不是在 mybatis 文件中还有一个 mapper 文件夹，而是有一个叫 mybatis.mapper 的文件夹。这个真的要注意。\n\n   <font color=\"red\"><strong>*</strong></font>**我这里就是犯了最后一个错误，我怎么也没想到 idea 的这个问题，他创建多级空目录会有这个问题，我知道，但是就没有往这边想，为此我付出了 <font color=\"red\" size=\"5\">5</font> 个小时的代价。特此记录，引以为戒**\n\n## 3）swagger 3.0版本注意事项\n\n1. 本来小编用的是 **swagger2** 的版本，结果因为搭建项目框架，有的依赖有问题，切换了 **swagger** 的版本为：3.0.0.。切换之后服务可以正常启动，但是访问不了 **swagger** 的页面了。*(访问地址：swagger-ui.html)* \n\n   **解决：**\n\n   1. swagger3.0 需要在 pom 中添加以下依赖：\n\n      ```xml\n      <dependency>\n      \t<groupId>io.springfox</groupId>\n          <artifactId>springfox-boot-starter</artifactId>\n          <version>3.0.0</version>\n      </dependency>\n      ```\n\n   2. 需要在启动类增加 **@EnableOpenApi** 注解\n\n   3. 访问地址变为：xxx/swagger-ui/index.html\n\n## 4）Erueka 报错\n\n1. <font color=\"red\">启动报错：spring cloud erueka  com.google.gson.GsonBuilder:</font>\n\n   升级 gson 的版本即可\n\n2. 访问eureka 中服务的info--》/actuator/info 404 问题\n\n   - 修改父工程pom\n\n     ```xml\n         <build>\n             <finalName>springCloud</finalName>\n             <resources>\n                 <resource>\n                     <directory>src/main/resources</directory>\n                     <filtering>true</filtering>\n                 </resource>\n             </resources>\n             <plugins>\n                 <plugin>\n                     <groupId>org.apache.maven.plugins</groupId>\n                     <artifactId>maven-resources-plugin</artifactId>\n                     <version>${maven.resources.version}</version>\n                     <configuration>\n                         <delimiters>\n                             <!--这里使用与匹配yml中的配置，需要注意有的版本这里用的是<delimit>标签-->\n                             <delimiter>$</delimiter>\n                         </delimiters>\n                     </configuration>\n                 </plugin>\n             </plugins>\n         </build>\n     ```\n\n   - 修改子工程yml配置文件\n\n     ```yaml\n     eureka:\n       # 客户端注册进eureka服务列表内\n       client:\n         service-url:\n           # 对应eureka服务端的defaultZone\n           defaultZone: http://localhost:7001/eureka\n       # 实例配置\n       instance:\n         # 实例id，eureka 中实例名称，status显示的名称\n         instance-id: ProViderDept8001\n         # 配置访问路径可以显示ip地址\n         prefer-ip-address: true\n     info:\n       app.name: springCloud\n       company.name: www.sy.com\n       build.artifactId: $project.artifactId$\n       build.version: $project.version$\n     \n     #此处配置用于开发eureka 的actuator/info 信息使用\n     management:\n       endpoints:\n         web:\n           exposure:\n     #       开放所有\n             include: \"*\"\n     ```\n\n     ","tags":["Spring Cloud 学习"],"categories":["技术学习","Spring Cloud 学习"]},{"title":"Ubuntu破解Jetbrains工具","url":"/2020/08/04/Ubuntu破解Jetbrains工具/","content":"\n\n\n破解包下载：[jetbrains-agent-2020.1.2](jetbrains-agent-2020.1.2.zip)\n\n<font color=\"red\">注：本篇文章以及提供的破解包用于 idea2020.1.2版本（经本人测试datagrip2020.1.4也可以，应该是临近idea2020.1.2版本的即可）。</font>\n\n<!-- more -->\n\n## 1）下载安装idea\n\n下载地址：[https://www.jetbrains.com/idea/download/other.html](https://www.jetbrains.com/idea/download/other.html)\n\n选择2020.1.2版本进行下载\n\n![图片加载失败](Jetbrains_1.png)\n\n## 2）进行安装破解包\n\n1. 下载破解包并解压\n\n2. 安装完成之后以“**试用**”进入idea。\n\n3. 将破解包内的文件拉入 **idea** 中（直接拉入破解包的压缩包也行，最好是拉入破解包内的文件:lib内的jetbrains-agent.jar）\n\n   ![图片加载失败](Jetbrains_2.png)\n\n4. idea 会重新启动，启动后会弹出配置助手，激活方式选择 code 或者 server 都可以，本人用的是 server。选择好之后点击 “为IDEA安装”。\n\n   ![图片加载失败](Jetbrains_3.png)\n\n5. idea 会提示安装成功，重启后生效，点击 “**是**”\n\n6. idea 重启后，点击help - about 查看是否成功\n\n   ![图片加载失败](Jetbrains_4.png)\n\n---\n\n至此，破解完成。（经本人亲自测试过是成功的。）","tags":["工具破解"],"categories":["Linux","工具破解"]},{"title":"Ubuntu安装Myslq5.7","url":"/2020/08/03/Ubuntu安装Mysql5.7/","content":"\n\n\n## 1.下载 Myslq5.7\n\n下载地址：[https://downloads.mysql.com/archives/community/](https://downloads.mysql.com/archives/community/)\n\n<!-- more -->\n\n![图片加载失败](Mysql_install_1.png)\n\n## 2.移动压缩包并解压\n\n图片中的目录是本人创建的用于安装各种环境的目录，根据个人习惯不同目录可自行创建。\n\n![图片加载失败](Mysql_install_2.png)\n\n## 3.重命名解压后的文件夹\n\n将解压后的文件夹重命名为 **mysql-5.7.30**\n\n```shell\nmv mysql-5.7.30-linux-glibc2.12-x86_64 mysql-5.7.30\n```\n\n## 4.添加用户组\n\n```shell\ngroupadd mysql\n```\n\n## 5.添加用户\n\n```shell\nuseradd -r -g mysql mysql\n```\n\n## 6.更新系统依赖环境\n\n```shell\napt-get update\n```\n\n## 7.下载libaio依赖\n\n```shell\napt-get install libaio*\n```\n\n## 8.下载libncurses依赖\n\n```shell\napt-get install libncurses*\n#执行玩以上命令会问你是否继续执行。输入 Y 继续执行\n```\n\n## 9.创建data目录\n\n```shell\ncd mysql-5.7.30\nmkdir data\n```\n\n## 10.将mysql-5.7.30的所有者以及所属组改为mysql\n\n```\nchown -R mysql:mysql /usr/Environment/Mysql/mysql-5.7.30\n```\n\n## 11.在/usr/Environment/Mysql/mysql-5.7.30/support-files目录下创建my_default.cnf\n\n```shell\n[mysql]\ndefault-character-set=utf8\nsocket=/tmp/mysql.sock\n[mysqld]\nport=3306\nsocket=/tmp/mysql.sock\n#根据个人目录不同basedir、datadir需要选择你自己的目录\nbasedir=/usr/Environment/Mysql/mysql-5.7.30\ndatadir=/usr/Environment/Mysql/mysql-5.7.30/data\nmax_connections=250\ncharacter-set-server=utf8\ndefault-storage-engine=INNODB\nmax_allowed_packet=16M\nlog-error=/usr/Environment/Mysql/mysql-5.7.30/data/mysqld.log\npid-file=/usr/Environment/Mysql/mysql-5.7.30/data/mysqld.pid\n```\n\n## 12.将my_default.cnf拷贝至/etc/mysql下\n\n```shell\ncp my_default.cnf /etc/mysql/my.cnf\n```\n\n## 13.初始化mysqld\n\n```shell\ncd /usr/Environment/Mysql/mysql-5.7.30\n./bin/mysqld --initialize --user=mysql --basedir=/usr/Environment/Mysql/mysql-5.7.30/ --datadir=/usr/Environment/Mysql/mysql-5.7.30/data/ \n```\n\n## 14.初始化完成后查看日志中的临时密码\n\n```shell\ncd data/\ncat mysqld.log\n```\n\n临时密码为：i>;+lyB5Ojon\n\n```shell\n2020-08-07T07:37:17.198965Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).\n2020-08-07T07:37:17.594529Z 0 [Warning] InnoDB: New log files created, LSN=45790\n2020-08-07T07:37:17.700675Z 0 [Warning] InnoDB: Creating foreign key constraint system tables.\n2020-08-07T07:37:17.769067Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: d1ee4afd-d880-11ea-8942-a0c589328791.\n2020-08-07T07:37:17.772722Z 0 [Warning] Gtid table is not ready to be used. Table 'mysql.gtid_executed' cannot be opened.\n2020-08-07T07:37:19.446295Z 0 [Warning] CA certificate ca.pem is self signed.\n2020-08-07T07:37:19.783441Z 1 [Note] A temporary password is generated for root@localhost: i>;+lyB5Ojon\n```\n\n## 15.把启动脚本放到开机初始化目录\n\n```shell\ncd /usr/Environment/Mysql/mysql-5.7.30/support-files/\ncp mysql.server /etc/init.d/mysql\n```\n\n## 16.编辑 /etc/init.d/mysql 文件\n\n```shell\nvim /etc/init.d/mysql\n```\n\n将文件中的basedir、datadir赋值为上面配置的目录即可\n\n![图片加载失败](Mysql_install_3.png)\n\n## 17.配置环境变量\n\n```shell\nvim /etc/profile\n\n#环境变量下面增加以下两行，目录根据个人不同进行修改\n#目的是可以在任意目录下启动 mysql 服务与登录 mysql\nexport MYSQLBIN_HOME=/usr/Environment/Mysql/mysql-5.7.30\nexport PATH=$MYSQLBIN_HOME/bin:$PATH\n```\n\n## 18.使配置文件生效\n\n```shell\nsource /etc/profile\n```\n\n如果切换回普通用户，或者重启之后环境变量失效，配置 ~/.bashrc 文件 在最下面添加 **source /etc/profile** 即可\n\n## 19.启动MySQL服务\n\n```shell\nservice mysql start\n```\n\n## 20.查看MySQL服务是否正常启动\n\n```shell\nservice mysql status\n```\n\n如下图，已经启动成功\n\n![图片加载失败](Mysql_install_4.png)\n\n## 21.登录mysql\n\n```shell\nmysql -r root -p #执行完此命令会让你输入密码，密码为上文日志中的初始密码，输入的时候密码是不可见的，直接复制过去也可以\n```\n\n![图片加载失败](Mysql_install_5.png)\n\n## 22.修改密码并授权远程连接\n\n```sql\nset password=password('123456');\ngrant all privileges on *.* to root@'%' identified by '123456';\nflush privileges;\n```\n\n## 23.退出MySQL\n\n```sql\nexit\n```\n\n## 24.重启MySQL生效\n\n```shell\nservice mysql stop\nservice mysql start\n#或\nservice mysql restart\n```\n\n---\n\n至此 **MySQL** 安装配置完成 ，可以用连接工具进行连接了。","tags":["环境安装"],"categories":["Linux","环境安装"]},{"title":"Hexo&github博客迁移（Windows迁移至Ubuntu）","url":"/2020/08/01/Hexo-github博客迁移（Windows迁移至Ubuntu）/","content":"\n\n\n　　这篇博客主要讲的是如何进行 **Hexo&github** 博客迁移，此处应用场景为换电脑后进行迁移\n\n<!-- more -->\n\n　　由于本人电脑有两块固态，所有在空间比较小的固态上装了一个 **Ubuntu** 系统，安装之后，进行一些开发应用，在安装之后有一些使用的问题想要记录一下，所以决定迁移个人博客到这个系统上。\n\n　　好了，废话不多说，接下来就是本人实际的迁移过程：\n\n## 1.迁移前环境准备\n\n在新系统上安装如下环境：\n\n1. **安装git：**此处参考[Ubuntu下git的安装及使用](https://www.cnblogs.com/lxm20145215----/p/5905765.html)即可\n\n2. **安装Nodejs：**此处参考本人博客中的[Ubuntu安装Nodejs](https://sunyubk.github.io/2020/07/16/Ubuntu%E5%AE%89%E8%A3%85NodeJS/)\n\n3. **安装Hexo：**此处参考本人博客中的[Ubuntu安装Hexo](https://sunyubk.github.io/2020/08/01/Ubuntu%E5%AE%89%E8%A3%85Hexo/)\n\n## 2.将博客文件存至github\n\n### 1）在github上创建仓库用于存放博客文件\n\n如下图，点击 New repository 创建仓库，blog_all就是本人存放迁移博客的的仓库，当然，这个仓库是私人的。\n\n![图片加载失败](move_blog_1.png)\n\n\n\n### 2）上传博客文件至github仓库\n\n将原系统中博客目录下的文件都上传至 **github** 仓库中，因为有一些文件会使上传失败，所以本人的处理方式是：\n\n在本地存放博客文件的文件夹同级创建用于存放可能会干扰上传的文件，本人移动的文件都有：\n\n1. 博客根目录下的：.gitignore 文件\n2. .deploy_git文件夹下的 .git 文件夹\n3. 主题文件夹下的 .git 文件夹\n\n![图片加载失败](move_blog_3.png)　　\n\n下图为本人上传的后的仓库：\n\n![图片加载失败](move_blog_2.png)\n\n## 3.将github仓库中的文件clone至新系统中\n\n### 1）在本地创建用于存放博客文件的目录\n\n下图中的 **blog_all** 就是博客的目录，**git_config** 是存放一些可能会烦扰上传的文件\n\n![图片加载失败](move_blog_4.png)\n\n### 2）至此博客迁移就已经完成了\n\n![图片加载失败](move_blog_5.png)\n\n### 3）检验博客是否可以成功访问\n\n在 **blog_all** 文件夹下执行一下命令后访问，localhost:4000：\n\n```shell\nhexo s -g\n```\n\n![图片加载失败](move_blog_6.png)\n\n## 4.编写shell脚本用于更新博客迁移的仓库，为以后博客迁移做准备\n\n<font color=\"red\">注：以下命令中的目录根据个人不同，请注意修改。</font>\n\n### 1）创建存放脚本的目录\n\n下图为目录结构（根据个人喜好自己配置即可）：\n\n**shell** 目录下的update_blog.sh才是最终的执行文件，**libs** 下的文件执行供其他脚本调用的脚本\n\n![图片加载失败](move_blog_7.png)\n\n### 2）编写 shell 脚本\n\n此处分为四步进行：\n\n1. 将可能会干扰上传的文件移动到暂存文件夹中\n2. 使用 **git** 命令将文件上传\n3. 上传过后，再将暂存文件夹中的文件移动回原目录\n4. 创建日志文件，用于记录什么时间更新过\n\n```shell\n#!/bin/bash\n\n#获取当前时间用于提交描述使用\ntime=$(date \"+%Y-%m-%d %H:%M:%S\")\n\n#已下命令为移动一些配置文件\necho \"1.移动 .deploy_git 下的 .git 文件夹到相应的博客配置文件暂存文件夹中\"\nsudo mv /usr/Environment/Hexo/blog_all/.deploy_git/.git /usr/Environment/Hexo/git_config/.deploy_git/\n\necho \"2.移动博客文件根目录下的 .gitignore 到相应的博客配置文件暂存文件夹中\"\nsudo mv /usr/Environment/Hexo/blog_all/.gitignore /usr/Environment/Hexo/git_config/blog_git/\n\necho \"3.移动博客主题文件夹下的 .git 文件夹到相应的博客配置文件暂存文件夹中\"\nsudo mv /usr/Environment/Hexo/blog_all/themes/stun/.git /usr/Environment/Hexo/git_config/themes_git/stun/\n\n#以下命令为将本地改动提交至远程库\necho \"4.执行 git add 跟踪命令\"\ngit add .\n\necho \"5.执行 git commit 命令将暂存区的改动提交至本地的版本库\"\ngit commit -m \"更新于：${time}\"\n\necho \"6.执行 git push 命令将本地库推送至远程库\"\ngit push\n\n#以下命令为将第一步中移动的配置文件移动回原位\necho \"7.移动 .deploy_git 下的 .git 文件夹到相应的博客配置文件暂存文件夹中\"\nsudo mv /usr/Environment/Hexo/git_config/.deploy_git/.git /usr/Environment/Hexo/blog_all/.deploy_git/\n\necho \"8.移动博客文件根目录下的 .gitignore 到相应的博客配置文件暂存文件夹中\"\nsudo mv /usr/Environment/Hexo/git_config/blog_git/.gitignore /usr/Environment/Hexo/blog_all/\n\necho \"9.移动博客主题文件夹下的 .git 文件夹到相应的博客配置文件暂存文件夹中\"\nsudo mv /usr/Environment/Hexo/git_config/themes_git/stun/.git  /usr/Environment/Hexo/blog_all/themes/stun/\n\n#写入更新日志\n# 判断文件是否存在不存在、创建文件并输入内容\nfile=\"/usr/Environment/Hexo/update_blog.log\"\n\nif [ ! -f  $file ];then \n\techo \"更新于：${time}\" >> $file\nelse\n\t# cat $file\n\techo \"更新于：${time}\" >> $file\nfi\n\necho \"新完成，日志写入完成\"\n```\n\n以上脚本已经可以使用，但是需要在root用户下。\n\n### 3）创建 Expect 脚本用于切换登录用户\n\n1. 安装 **Expect、Tcl**。此处参考本人博客中的[Ubuntuan安装Expect&Tcl]()\n\n2. 编写 **Expect** 脚本\n\n   ```shell\n   spawn sudo su root\n   expect \"密码：\" {send \".\\r\" }\n   expect \"*#\" {send \"cd /usr/Environment/Hexo/blog_all\\r\"}\n   expect \"blog_all*\" {send \"sh /usr/Environment/Scripts/Shell/libs/shell_update_blog.sh\\r\"}\n   interact\n   ```\n\n3. 由于本人太懒，不想没有都输入 expect XXX，所以又写了一个调用 **Expect** 脚本的 **shell** 脚本\n\n   ```shell\n   expect /usr/Environment/Scripts/Expect/expect_update_blog.sh\n   ```\n\n至此，更新脚本编写完成。\n\n## 5.配置 /etc/profile 文件 使脚本在任意目录都可以执行\n\n1. 在/etc/profile 文件末尾添加如下配置：\n\n   ```shell\n   export SHELL_HOME=/usr/Environment/Scripts/Shell\t#目录根据个人不同进行修改\n   export PATH=$SHELL_HOME:$PATH\n   ```\n\n2. 执行以下命令使配置文件生效：\n\n   ```shell\n   source /etc/profile\n   ```\n\n   现在其实就已经可以在任意目录执行指定目录中的脚本文件了，但是重启终端之后就不行了，也许是个人电脑问题，但是还是建议进行下一步配置。\n\n3. 配置 ~/.bashrc 文件，在文件末尾添加第二步执行的命令。\n\n至此，脚本就配置好了。\n\n---\n\n　　好了，到这里本篇文章就结束，更新完博客之后可以顺便执行一下脚本，将博客文件上传至 **github** 仓库中，用于以后迁移，或者当个以防万一的备份。","tags":["个人博客"],"categories":["个人博客","博客迁移"]},{"title":"Ubuntuan安装Expect&Tcl","url":"/2020/08/01/Ubuntuan安装Expect-Tcl/","content":"\n\n\n<font color=\"red\">注：以下命令都是在 root 用户下执行</font>\n\n<!-- more -->\n\n## 1.检查 Tcl 的安装情况\n\n执行如下命令：\n\n```shell\nwhereis tcl\n```\n\n如果没有显示，就是没有安装 **Tcl**\n\n## 2.下载安装文件\n\n```shell\nwget https://nchc.dl.sourceforge.net/project/tcl/Tcl/8.6.10/tcl8.6.10-src.tar.gz\n```\n\n## 3.创建文件夹\n\n```shell\nmkdir /usr/Environment/Tcl #Environment是本人创建用存放安装环境的目录\n```\n\n## 4.移动安装文件至 Tcl 目录下\n\n```shell\nmv tcl8.6.10-src.tar.gz /usr/Environment/Tcl/\n```\n\n## 5.解压\n\n```shell\ntar -zxvf tcl8.6.10-src.tar.gz\n```\n\n## 6.进入安装目录\n\n```shell\n#在上一步解压后会得到tcl8.6.10\ncd tcl8.6.10/unix/\n```\n\n## 7.生成Makefile\n\n```shell\n./configure\n```\n\n## 8.编译、安装\n\n```shell\nmake\nmake install\n```\n\n","tags":["环境安装"],"categories":["Linux","环境安装"]},{"title":"Ubuntu安装Hexo","url":"/2020/08/01/Ubuntu安装Hexo/","content":"\n\n\n## 1.使用[使用淘宝NPM镜像](https://developer.aliyun.com/mirror/NPM?from=tnpm)，使用一下命令等待安装完成\n\n```shell\nnpm install -g cnpm --registry=https://registry.npm.taobao.org\n```\n\n<!-- more -->\n\n## 2.使用淘宝NPM安装Hexo\n\n```shell\ncnpm install -g hexo-cli\n```\n\n\n\n## 3.出现错误不用理会，继续执行以下命令\n\n```shell\ncnpm install hexo --save\n```\n\n\n\n## 4.安装完成后，输入以下命令，验证安装是否成功\n\n```shell\nhexo -v\n```\n\n\n\n## 5.初始化\n\n```shell\nhexo init\n```\n\n","tags":["环境安装"],"categories":["Linux","环境安装"]},{"title":"Ubuntu安装NodeJS","url":"/2020/07/16/Ubuntu安装NodeJS/","content":"\n\n\n## 1.下载nodeJS\n\n下载地址：[https://nodejs.org/en/](https://nodejs.org/en/)\n\n<!-- more -->\n\n<font color=\"red\">LTS：稳定版　　Current：最新版</font>\n\n![图片加载失败](nodeJS_install_1.png)\n\n## 2.解压\n\n```shell\n#下载的压缩包为 tar.xz 格式，所以先用以下命令解压一次\nxz -d node-v12.18.2-linux-x64.tar.xz\n#解压过后在用 tar 方式解压\ntar -xvf node-v12.18.2-linux-x64.tar\n```\n\n![图片加载失败](nodeJS_install_2.png)\n\n![图片加载失败](nodeJS_install_3.png)\n\n\n\n## 3.配置环境变量\n\n```shell\nvim /etc/profile\t#编辑全局变量配置文件\n\n#在配置文件中追加如下内容\nexport NODE_HOME=/usr/Environment/nodeJS/node-v12.18.2-linux-x64\nexport PATH=$NODE_HOME/bin:$PATH\n```\n\n![图片加载失败](nodeJS_install_4.png)\n\n\n\n## 4.使配置生效\n\n```shell\nsource /etc/profile\t#使配置文件生效\n```\n\n\n\n## 5.检验是否安装成功\n\n```shell\nnode -v\n```\n\n![图片加载失败](nodeJS_install_5.png)\n\n\n\n如图所示出现版本号即成功了。","tags":["环境安装"],"categories":["Linux","环境安装"]},{"title":"Ubuntu安装Maven3.6.3","url":"/2020/07/16/Ubuntu安装Maven3.6.3/","content":"\n\n\n## 1.下载Maven\n\n下载地址：[http://maven.apache.org/index.html](http://maven.apache.org/index.html)\n\n<!-- more -->\n\n![图片加载失败](maven_install_1.png)\n\n\n\n## 2.解压\n\n```shell \ntar -zxvf apache-maven-3.6.3-bin.tar.gz\nmkdir repository\t#创建本地仓库文件夹，下面配置到 setting.xml 配置文件中\n```\n\n![图片加载失败](maven_install_3.png)\n\n## 3.配置 Maven 配置文件，配置 本地仓库(repository) 与 远程仓库源\n\n```shell\ncd apache-maven-3.6.3/conf/\t#进入 setting.xml 配置文件目录\ncp setting.xml setting.xml.bak\t#备份配置文件\nvim setting.xml\t#编辑配置文件\n```\n\n![图片加载失败](maven_install_4.png)\n\n```xml\n#找到 localRepository 标签 在注释外增加下列内容 ，用于指定本地仓库\n<localRepository>/usr/Environment/maven/repository</localRepository>\n\n#找到 mirrors 标签，在标签中增加下列内容，用于配置阿里云的仓库 \n    <mirror>\n\t\t<id>nexus-aliyun</id>\n\t\t<mirrorOf>central</mirrorOf>\n\t\t<name>Nexus aliyun</name>\n\t\t<url>https://maven.aliyun.com/repository/central</url>\n    </mirror>\n\n```\n\n![图片加载失败](maven_install_5.png)\n\n![图片加载失败](maven_install_6.png)\n\n\n\n## 4.配置环境变量\n\n```shell\nvim /etc/profile\t#编辑全局变量配置文件\n\n#在配置文件中追加如下内容\nexport MAVEN_HOME=/usr/Environment/maven/apache-maven-3.6.3\nexport PATH=${MAVEN_HOME}/bin:${PATH}\n```\n\n![图片加载失败](maven_install_7.png)\n\n\n\n## 5.使配置生效\n\n```shell\nsource /etc/profile\t#使配置文件生效\n```\n\n\n\n## 6.检验是否安装成功\n\n```shell\nmvn -v\n```\n\n![图片加载失败](maven_install_8.png)\n\n\n\n## 7.初始化本地仓库\n\n```shell\nmvn help:system\n```\n\n![图片加载失败](maven_install_9.png)\n\n\n\n到这里 Maven 已经安装成功，本地仓库中也已经有了基础的 jar 包了","tags":["环境安装"],"categories":["Linux","环境安装"]},{"title":"Ubuntu安装tomcat8.5","url":"/2020/07/16/Ubuntu安装tomcat8.5/","content":"\n\n\n## 1.下载 tomcat\n\n下载地址：[https://tomcat.apache.org/download-80.cgi](https://tomcat.apache.org/download-80.cgi)\n\n<!-- more -->\n\n![图片加载失败](tomcat_install_1.png)\n\n\n\n## 2.解压\n\n```shell\ntar -zxvf apache-tomcat-8.5.34.tar.gz\n```\n\n![图片加载失败](tomcat_install_2.png)\n\n\n\n## 3.配置环境变量\n\n**环境变量也可以不配置，配置的目的是为了可以在任意目录下启动 tomcat**\n\n```shell\nvim /etc/profile\t#编辑全局变量配置文件\n\n#在配置文件中追加如下内容\nexport PATH=$PATH:/usr/Environment/tomcat/apache-tomcat-8.5.34/bin\n#编辑好之后按 ESC 输入 :wq 退出并保存配置文件\n```\n\n![图片加载失败](tomcat_install_3.png)\n\n\n\n## 4.使配置生效\n\n```shell\nsource /etc/profile\t#使配置文件生效\n```\n\n\n\n## 5.检验是否安装成功\n\n```shell\nstartup.sh\t#启动 \nshutdown.sh\t#关闭 \n\n#启动后可访问 localhost:8080 ，tomcat端口默认8080，显示如下页面表示启动成功\n```\n\n![图片加载失败](tomcat_install_4.png)","tags":["环境安装"],"categories":["Linux","环境安装"]},{"title":"Ubuntu安装jdk1.8","url":"/2020/07/16/Ubuntu安装jdk1.8/","content":"\n\n\n## 1.下载 JDK\n\njdk8 下载地址：[https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html](https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html)\n\n<!-- more -->\n\n![图片加载失败](jdk_install_1.png)\n\n\n\n## 2.解压\n\n```shell\ntar -zxvf jdk-8u191-linux-x64.tar.gz\t#将压缩包解压\n```\n\n![图片加载失败](jdk_install_2.png)\n\n*图中的目录可以自己设置，小编是在 **/user** 下创建了环境专用的目录\n\n\n\n## 3.配置环境变量\n\n```shell\nvim /etc/profile\t#编辑全局变量配置文件\n\n#在配置文件中追加以下内容\nexport JAVA_HOME=/usr/Environment/jdk/jdk1.8.0_191\nexport JRE_HOME=${JAVA_HOME}/jre\nexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib\nexport PATH=${JAVA_HOME}/bin:$PATH\n#编辑好之后按 ESC 输入 :wq 退出并保存配置文件\n```\n\n![图片加载失败](jdk_install_3.png)\n\n\n\n## 4.使配置生效\n\n```shell\nsource /etc/profile\t#使配置文件生效\n```\n\n\n\n## 5.检验是否安装成功\n\n```shell\njava -version\n或\njavac -version\n```\n\n![图片加载失败](jdk_install_4.png)\n\n\n\n**出现如上图所示版本号即安装成功**","tags":["环境安装"],"categories":["Linux","环境安装"]},{"title":"Java 面试题","url":"/2020/07/16/面试题/","content":"\n# 一、Java基础\n\n## 1.JDK 和 JRE 有什么区别？\n\n- JDK：java开发工具包，提供了java的开发环境和运行环境。\n- JRE：java的运行环境，为java的运行提供了所需环境。\n\n<!-- more -->\n\n## 2.== 和 equals 的区别是什么？\n\n**== 解读**\n\n对于基本类型和引用类型 == 的作用效果是不同的：\n\n- 基本类型：比较的是值是否相同。\n- 引用类型：比较的是引用是否相同。\n\n代码示例：\n\n```java\nString x = \"string\";\nString y = \"string\";\nString z = new String(\"string\");\nSystem.out.println(x==y); // true\nSystem.out.println(e==z); // false\nSystem.out.println(x.equals(y)); // true\nSystem.out.println(x.equals(z)); //true\n```\n\n代码解读：\n\n1. 因为 x 和 y 指向的是一个引用（指向的都是常量池中的string），所以 == 也是true。\n2. 因为 new String()方法是重新开辟了内存空间所有 == 的结果为false。\n3. equals比较的一直都是值所以一直都是true。\n\n**equals解读**\n\nequals 本质上就是 ==，只不过 String 和 Integer 等重写了 equals 方法，把它变成了值比较。\n\n**总结**：== 对于基本类型是值比较，对于引用类型是引用比较；而 equals 默认情况下是引用比较。只是很多类重写了 equals 方法。比如 String、Integer 等把它重写成了值比较。\n\n## 3.两个对象的 hashCode()相同，则 equals()也一定为 true，对吗？\n\n不对，两个对象的 hashCode()相同，equals()不一定true。\n\n**原因**：在散列表中，hashCode()相等，即两个键值对的哈希值相等，然而哈希值相等，并不一定能得出键值对相等。\n\n## 4.final 在 java 中有什么作用？\n\n- final 修饰的类叫最终类，不能被继承。\n- final 修饰的方法不能被重写。\n- final 修饰的变量叫常量，常量必须初始化，初始化之后值就不能被修改。\n\n## 5.java 中的 Math.round(-1.5) 等于多少？\n\n等于 -1，Math.round() 就是加 0.5 并向下取整。\n\n## 6.String 属于基础的数据类型吗？\n\nString 不属于基础类型，而属于对象。\n\n基础类型有 8 中：byte、short、int、long、float、double、boolean、char。\n\n## 7.java 中操作字符串都有哪些类？它们之间有什么区别？\n\n操作字符串的类有：String、StringBuffer、StringBuilder\n\n**区别**：\n\n1. String 声明的是不可变对象，每次操作都会生成新的 String 对象，然后将指针指向新的 String 对象，而 StringBuffer、StringBuilder 可以再原有对象的基础上进行操作。\n2. StringBuffer 是线程安全的，StringBuilder 相反。\n\n## 8.String str = \"i\" 与 String str = new String(\"i\") 一样吗？\n\n不一样。\n\n**原因**：String str = \"i\" 是被 java 虚拟机分配到常量池中，而 String str = new String(\"i\") 是被分配到堆内存中。\n\n## 9.如何将字符串反转\n\n1. 使用 StringBuffer 或者StringBuilder 的 reverse() 方法。\n\n**示例代码**：\n\n```java\nString str = \"abc\";\nStringBuffer sb = new StringBuffer(str);\nStringBuffer res = sb.reverse();\nstr = res.toString();\n```\n\n2. 使用 String 的 charAt() 方法，将字符串从后向前取出，存入到 StringBuffer 或者 StringBuilder 中，再转为 String。\n\n**示例代码**：\n\n```java\nString str = \"abc\";\nStringBuffer sb = new StringBuffer();\nfor(int x = str.length()-1;x >= 0;x--){\n    sb.append(str.charAt(x));\n}\nstr = sb.toString();\n```\n\n## 10.String类的常用方法都有哪些？\n\n- indeOf()\t返回指定字符的索\n- charAt()\t返回指定索引的字符\n- replace()\t字符串替换\n- trim()\t去除两端的空白\n- split()\t分割字符串，返回一个分割后的字符串数组\n- getBytes()\t返回字符串的byte类型数组\n- substring()\t截取字符串\n- length()\t返回字符串长度\n- equals()\t比较字符串\n- toLowerCase()\t将字符串转为小写字母\n- toUpperCase()\t将字符串转为大写字母\n\n## 11.什么是抽象？什么是多态？\n\n**抽象**：抽象是对具体对象进行提炼，提取对象的同类型的 共性特征 的过程\n\n**多态**：多态就是多个对象对一个行为的不同响应/多态  是 对象本身具备的不同状态\n\n**自我感觉 “抽象” 和 “多态” 很像**\n\n## 12.抽象类必须有抽象方法吗？\n\n不是的，抽象类可以没有抽象方法\n\n## 13.普通类和抽象类有什么区别？\n\n1. 普通类不能有抽象方法，抽象类可以有抽象方法。\n2. 普通类可以直接实例化，抽象类不能直接实例化。\n\n## 14.抽象类能使用 final 修饰吗？\n\n不能，final 修饰的类不可被继承，而抽象类就是用来继承的。\n\n## 15.接口和抽象类有什么区别？\n\n- 实现：接口是由 implements 来实现的，抽象类是由 extends 继承的。\n- 构造方法：接口没有构造方法，抽象类有构造方法。\n- 实现数量：类可以实现多个接口，但是只能继承一个抽象类\n\n**个人理解**：抽象类就是实现多态的一种方式\n\n## 16.Java中的 IO 流分为哪几种？\n\n**按功能**：输入流（input），输出流（output）\n\n**按类型**：字节流，字符流\n\n**字节流：inputStream、outputStream；**\n\n**字符流：reader、writer；**\n\n## 17.BIO、NIO、AIO有什么区别？\n\n- **BIO**：Block IO 同步阻塞式 IO，就是我们平常使用的传统 IO，它的特点是模式简单使用方便，并发处理能力低。\n- **NIO**：New IO 同步非阻塞 IO，是传统 IO 的升级，客户端和服务器端通过 Channel（通道）通讯，实现了多路复用。\n- **AIO**:Asynchronous IO 是 NIO 的升级，也叫 NIO2，实现了异步非堵塞 IO ，异步 IO 的操作基于事件和回调机制。\n\n## 18.files 的常用方法都有哪些？\n\n- File.exists()：检查文件路径是否存在？\n- File.createFile()：创建文件\n- File.createDirectory()：创建文件夹\n- File.delete()：删除一个文件或目录\n- File.move()：移动文件\n- File.copy()：复制文件\n- File.size()：查看文件个数\n- File.read()：读取文件\n- File.write()：写入文件\n\n## 19.简述 java 集合中有关有序、无序的区别，并分别列出其中的典型\n\n1. 集合的有序、无序是指插入元素时，插入的顺序性，也就是先插入的元素优先放在集合的前面部分。\n2. ArrayList 有序的、HashMap 无序的\n\n## 20.简述 spring 的两大特性\n\n1. Ioc：控制反转，就是将控制权从程序员交由 spring 容器控制\n\n   例：class A 中要用到 class B 中的对象，一般情况的情况下是在 A 的代码中 new 一个 B 的对象。而使用到DI注入后，只需要在 A 中声明一个私有化的 B 对象就可以了\n\n2. aop：面向切面编程，横向扩展，可以通过动态代理的方式来完成一些重复性高的操作。\n\n   例：日志，事务，权限等\n\n## 21.什么是接口？\n\n​\t接口就是定义了一系列方法，主要是告诉我们这个方法是做什么的，但是具体怎么做是由他的实现类完成的。\n\n## 22.什么是死锁，产生死锁的四个必要条件是什么？\n\n1. 死锁可以理解为：互相不让步，不放弃，同时需要对方的资源。\n\n   例：两个以上线程都在等待对方执行完毕才能继续往下执行，这样就造成了无限等待，也就成了死锁\n\n2. 四个必要条件分别是：\n\n   - 互斥：一个资源每次只能被一个进程使用\n   - 保持锁并请求锁：一个进程因请求资源而阻塞时，对已经获取到的资源保持不放\n   - 不可抢夺：进程已经获得的资源，在未使用完之前，是不能被强行剥夺的\n   - 循环等待：若干线程形成了一种头尾相接的循环等待资源关系\n\n\n\n\n\n\n\n\n\n# 二、容器\n\n## 1.java 的常用容器都有哪些？\n\n常用容器的图录：\n\n![图片加载失败](1.jpg)\n\n## 2.Collection 和 Collections 有什么区别？\n\n- java.util.Collection 是一个集合接口。直接继承他的接口有 List 和 Set\n- Collections 是一个工具类，提供了一系列静态方法，用于集合中的元素排序，搜索以及线程安全等操作。\n\n## 3.List、Set、Map之间的区别是什么？\n\n|    比较    |                            List                            |                             Set                             |                             Map                              |\n| :--------: | :--------------------------------------------------------: | :---------------------------------------------------------: | :----------------------------------------------------------: |\n|  继承接口  |                         Collection                         |                         Collection                          |                                                              |\n| 常见实现类 | AbstractList（其常用子类有 ArrayList、LinkedList、Vector） | AbstractMap（其常用子类有 HashSet、LinkedHashSet、TreeSet） |                      HashMap、HashTable                      |\n|  常见方法  |     add()、remove()、clear() get()、contains()、size()     |         add()、remove()、clear() contains()、size()         | put()、get()、remove() clear()、containsKey() containsValue()、KeySet() values()、size（） |\n|    元素    |                           可重复                           |                不可重复（用 equals() 判断）                 |                           不可重复                           |\n|    顺序    |                            有序                            |              无序（实际上是由 HashCode 决定）               |                                                              |\n|  线程安全  |                      Vector 线程安全                       |                                                             |                      HashTable 线程安全                      |\n\n## 4.HashMap 和 HashTable 有什么区别？\n\n- HashMap 去掉了 HashTable 中的 Contains() 方法，但是加上了 ContainsKey()、ContainsValue() 方法。\n- HashMap 是同步的（线程安全的），HashTable 是非同步的（线程不安全），所以效率上 HashTable 要高于 HashMap。\n- HashMap 允许空键值，而 HashTable 不允许。\n\n\n\n\n\n\n\n\n\n# 三、数据库（sql）\n\n**<font color='red'>注：本部分sql都已经进行实际测试，所用数据库为 MySQL，如果有用到别的数据库会有红色标注出来。</font>**\n\n## 1.下面有两张表：用户表（Table_User）、考勤表（Table_ATtendance）\n\n<center>用户表（Table_User）</center>\n\n|  ID  | Account | USERNAME |\n| :--: | :-----: | :------: |\n|  1   |   liy   |   李阳   |\n|  2   | zhangxw |  张晓伟  |\n|  3   |  liuh   |   刘华   |\n|  4   |  yangl  |   杨柳   |\n|  5   | zhangl  |   张丽   |\n\n<center>考勤表（Table_ATtendance）</center>\n\n|  ID  | User_ID |        TIME         |\n| :--: | :-----: | :-----------------: |\n|  1   |    2    | 2019-05-04 08:53:24 |\n|  2   |    1    | 2019-05-04 08:55:32 |\n|  3   |    3    | 2019-05-05 08:20:13 |\n|  4   |    2    | 2019-05-05 08:55:33 |\n|  5   |    1    | 2019-05-06 08:57:03 |\n|  6   |    5    | 2019-05-06 08:52:10 |\n|  7   |    4    | 2019-06-01 08:20:14 |\n|  8   |    2    | 2019-05-07 08:45:11 |\n\n**问题一：请用SQL列出每个用户每个月的出勤率**\n\n```sql\nselect a.*,u.USERNAME,CONCAT(ROUND(count(*)/30*100,2),'%') percent from `1-Attendance` a\nleft JOIN `1-User` u on a.User_ID = u.ID\nGROUP BY a.User_ID,DATE_FORMAT(a.TIME,'%M')\n```\n\n\n\n<center>运行结果</center>\n\n![图片加载失败](database_sql_1-1.png)\n\n\n\n本问题没有什么难点，就是基础的 count() 函数与 group by 分组的应用。\n\n本题运用到的函数：\n\n- **CONCAT()**：用于字符串拼接 CONCAT(str1,str2,str3,...)，返回的结果是拼接后的字符串，如果有一个参数是null 则返回\n- **ROUND()**：用于处理小数位保留的问题 ROUND(column_name,decimals)，第一个参数为要进行处理的字段或者数值，第二个参数为保留的位数。\n\n**问题二：请用SQL列出每月出勤的前两名和后两名**\n\n```sql\nselect * from (\n\tselect a.User_ID,DATE_FORMAT(a.TIME,'%m')time,u.USERNAME,ROUND(count(*)/30*100,2) percent from `1-Attendance` a\n\tleft JOIN `1-User` u on a.User_ID = u.ID\n\tGROUP BY a.User_ID,DATE_FORMAT(a.TIME,'%m')\n\tORDER BY TIME\n) aa \nwhere (\n\tselect count(*) from (\n\t\tselect a.User_ID,DATE_FORMAT(a.TIME,'%m') time,u.USERNAME,ROUND(count(*)/30*100,2) percent from `1-Attendance` a\n\t\tleft JOIN `1-User` u on a.User_ID = u.ID\n\t\tGROUP BY a.User_ID,DATE_FORMAT(a.TIME,'%m')\n\t\tORDER BY TIME\n\t)bb\n\twhere bb.time = aa.time and bb.percent >= aa.percent #获取前两位\n)<=2\nOR (\n\tselect count(*) from (\n\t\tselect a.User_ID,DATE_FORMAT(a.TIME,'%m') time,u.USERNAME,ROUND(count(*)/30*100,2) percent from `1-Attendance` a\n\t\tleft JOIN `1-User` u on a.User_ID = u.ID\n\t\tGROUP BY a.User_ID,DATE_FORMAT(a.TIME,'%m')\n\t\tORDER BY TIME\n\t)bb\n\twhere bb.time = aa.time and bb.percent <= aa.percent #获取后两位\n)<=2\nORDER BY aa.time asc,percent desc\n```\n\n\n\n<center>运行结果</center>\n\n![图片加载失败](database_sql_1-2.png)\n\n\n\n本人认为这个问题还是有点绕的，估计是本人基础太差的问题。而且应该还有更简单的方式解决这个问题，但是我还不知道@~@。请包涵。。。。\n\n这条 **SQL** 编写的思路为：\n\n使用自连接进行比较，就是分为A、B两个表。加了where后的子查询条件后，就想象成在 A 表后面多了一列count(\\*) ，bb.percent >= aa.percent，这种比较就是在 A 表中排名越靠前的 count(\\*) 的值就越小。同理取后两名就是与取前两名相反。 \n\n\n\n## 2.下面有两张表：用户表（Table_User）、部门表（Table_Department）\n\n<center>用户表（Table_User）</center>\n\n|  ID  | ACCOUNT | USERNAME | DEPTID |\n| :--: | :-----: | :------: | :----: |\n|  1   |   liy   |   李阳   |   1    |\n|  2   | zhangxw |  张晓伟  |   2    |\n|  3   |  liuh   |   刘华   |   2    |\n|  4   |  yangl  |   杨柳   |   3    |\n|  5   | zhangl  |   张丽   |   4    |\n\n<center>部门表（Table_Department）</center>\n\n|  ID  | DEPTNAME | PARENTID |\n| :--: | :------: | :------: |\n|  1   |  环卫处  |   null   |\n|  2   |  考核科  |    1     |\n|  3   |  监督科  |    1     |\n|  4   |  检查科  |    1     |\n|  5   |  接待办  |    3     |\n\n**<font color='red'>函数参考地址：</font>**[https://www.cnblogs.com/zhizhao/p/9442799.html](https://www.cnblogs.com/zhizhao/p/9442799.html)\n\n**问题一：请用 SQL 列出“环卫处”下属所有部门及各自成员数量**\n\n根据问题理解为两种状况：\n\n1）只查询出 “环卫处” 子级部门，就是向下一级。\n\n```sql\nselect p.ID,p.DEPTNAME,c.DEPTNAME,c.PARENTID,\n(select count(*) from `2-User` u where u.DEPTID = c.ID) deptcount\nfrom `2-Department` p\njoin `2-Department` c on p.ID = c.PARENTID\nwhere p.DEPTNAME = '环卫处'\n```\n\n\n\n<center>运行结果</center>\n\n![图片加载失败](database_sql_2-1.1.png)\n\n\n\n这里就是简单自连接查询，基础语句。\n\n2）查询出 “环卫处” 所有自己部门（需自己创建递归函数）\n\n<center>创建递归函数</center>\n\n```sql\ndelimiter //\nDROP FUNCTION IF EXISTS `2-getChildList`;\nCREATE FUNCTION `2-getChildList`(rootId INT)\nRETURNS VARCHAR(1000)\n\nBEGIN\n\tDECLARE sTemd VARCHAR(1000);\n\tDECLARE sTemdChd VARCHAR(1000);\n\tSET sTemd = '$';\n\tSet sTemdChd = CAST(rootId AS CHAR);\n\t\n\tWHILE sTemdChd is not null DO\n\t\tset sTemd = CONCAT(sTemd,',',sTemdChd);\n\t\tselect GROUP_CONCAT(id) INTO sTemdChd from `2-Department` where FIND_IN_SET(PARENTID,sTemdChd)>0;\n\t\tEND WHILE;\n\tRETURN sTemd;\nEND\n```\n\n\n\n<center>查询 SQL</center>\n\n```sql\nselect * ,\n(select count(*) from `2-User` u where u.DEPTID = d.ID) deptcount\nfrom `2-Department` d where FIND_IN_SET(id,`2-getChildList`(1));\n```\n\n\n\n<center>查询结果</center>\n\n![图片加载失败](database_sql_2-1.2.png)\n\n\n\n这个问题正常来说第二种状况才是对于本题目正确的理解。\n\n我认为这里的难点在于这个递归函数（其实理解之后你会发现这个函数是真的没什么技术含量的，只不过我平常涉及数据库的还是比较少，所以感觉有点难度，但是理解之后就好了。），其实这个递归函数 copy 走改一改就可以使用，但是如果你想提升自己，以防以后遇到一点都说不上来。还是建议把这个函数理解透。\n\n本题运用到的函数：\n\n- **GROUP_CONCAT(column_name)**：多行数据合并\n\n- **FIND_IN_SET(param1,param2)**：查询 para2 中包含 param1 的结果，返回 null 或者 记录。详细可查看：[https://www.cnblogs.com/lixinjun8080/p/11246632.html](https://www.cnblogs.com/lixinjun8080/p/11246632.html)\n\n其实理解了函数中的那个查询语句，整个函数也就差不多了。\n\n**问题二：请用 SQL 列出“环卫处”下属所有部门中成员数量最多的两个部门**\n\n其实这个问题我个人理解也是两种：\n\n1）不考虑并列情况，这种就很简单直接在问题一的基础上增加 order by 排序和 limit 就可以了。所以就不列出此种情况了。\n\n2）考虑并列的情况，我个人认为应该把并列的情况也考虑进去。\n\n<center>查询 SQL </center>\n\n```sql\nselect * from (\n\tselect d.* ,\n\t(select count(*) from `2-User` u where u.DEPTID = d.ID) deptcount\n\tfrom `2-Department` d where FIND_IN_SET(id,`2-getChildList`(1))\n) b\nwhere FIND_IN_SET(\n\tb.deptcount,\n    (\n    \tselect GROUP_CONCAT(deptcount) from \n        (\n        \tselect d.* ,\n\t\t\t(select count(*) from `2-User` u where u.DEPTID = d.ID) deptcount\n\t\t\tfrom `2-Department` d where FIND_IN_SET(id,`2-getChildList`(1))\n\t\t\tGROUP BY deptcount\n\t\t\tORDER BY deptcount desc\n\t\t\tLIMIT 2\n        )a\n    )\n)\n```\n\n\n\n<center>运行结果</center>\n\n![图片加载失败](database_sql_2-2.png)\n\n其实这条sql难度也不高，只要你一步一步来就可以了。\n\n大概思路如下：\n\n1. 将 “问题一” 中的查询语句增加分组，排序，并用时用 limit，获取到前两名。\n\n   ```sql\n   select d.* ,\n   (select count(*) from `2-User` u where u.DEPTID = d.ID) deptcount\n   from `2-Department` d where FIND_IN_SET(id,`2-getChildList`(1))\n   GROUP BY deptcount\n   ORDER BY deptcount desc\n   LIMIT 2\n   ```\n\n   \n\n2. 将 1 中查询出来的结果集作为一张临时表查询，使用 group_concat() 函数将 1 中的的人数合并起来。其实就是将前两名的人数查询出来，合并成 2,1 这种形式。\n\n   ```sql\n   select GROUP_CONCAT(deptcount) from \n   (\n       select d.* ,\n   \t(select count(*) from `2-User` u where u.DEPTID = d.ID) deptcount\n   \tfrom `2-Department` d where FIND_IN_SET(id,`2-getChildList`(1))\n   \tGROUP BY deptcount\n   \tORDER BY deptcount desc\n   \tLIMIT 2\n   )a\n   ```\n\n   \n\n3. 以 “问题一” 中的查询的结果集作为临时表，条件使用 FIND_IN_SET() 函数进行控制。FIND_IN_SET() 函数函数中的参数就是：主表中的人数、和 2 中的语句。到此本问题就结束了\n\n   ```sql\n   select * from (\n   \tselect d.* ,\n   \t(select count(*) from `2-User` u where u.DEPTID = d.ID) deptcount\n   \tfrom `2-Department` d where FIND_IN_SET(id,`2-getChildList`(1))\n   ) b\n   where FIND_IN_SET(\n   \tb.deptcount,\n       (\n       \tselect GROUP_CONCAT(deptcount) from \n           (\n           \tselect d.* ,\n   \t\t\t(select count(*) from `2-User` u where u.DEPTID = d.ID) deptcount\n   \t\t\tfrom `2-Department` d where FIND_IN_SET(id,`2-getChildList`(1))\n   \t\t\tGROUP BY deptcount\n   \t\t\tORDER BY deptcount desc\n   \t\t\tLIMIT 2\n           )a\n       )\n   )\n   ```\n\n   \n\n<font color='red'>此处运用到的函数都在 “问题一” 中解释过。如果有疑问就看看 “问题一”  中的解释吧。</font>\n\n\n\n**未完待续**","tags":["Java 面试"],"categories":["Java 面试题"]},{"title":"开始博客的第一天","url":"/2020/07/16/BlogOneDay/","content":"　　**注**：参考文档还有下载链接都附在本文末尾。\n\n　　这篇文章只是说明，我是从什么时候开始写博客、为什么写、参考那些文档写的，至于怎么搭建我就不说了，因为我也是一个博客小白，现在的文档都很全面，就不耽误各位了。\n\n<!-- more -->\n\n　　2020年5月1日是我开始写博客的第一天，当然也是在今天开始学习怎么写博客的。因为目前正在找工作，在刚开始找工作的时候就想搭建一个博客来记录我的成长历程。\n\n　　其实很早就想写一个博客了，但是由于我属于一时热血的那种人，所以这个事情也是一拖再拖，于是拖到了今天。至于我为什么写博客，一开始是因为面试题总是背不下来，今天背，明天就忘了一半那种。后来想自己搭建个博客吧，把看过的面试题以自己理解的方式记录在博客中。同时，也会在博客中记录我对于技术的学习。关于为什么会在今天开始行动是因为，之前在刷抖音的时候，关注了一个技术大佬，就在今天早上刷到了他更新的视频，正好最近这几天一直在想怎么提升自己，但是自己不知道该怎么学，所以给他发了一条私信，咨询了他我该学什么，该怎么学，让他给我推荐两本书。很幸运的是他回复我了，我加了他的微信，和他说了一下我目前的状况。他也给我提了一些意见，也给我推荐了两本书，还说看书的话最好是多看几遍，而且看书的时候也要实用到代码中，并写一个博客来记录自己学到了什么。所以，在今天中午开始了研究博客的路程。\n\n　　搭建博客使用的是　**github+Hexo**，当然肯定要用到的就是 **markdown**，我写 **markdown** 使用的工具是 **Typora** \n\n　　12搭建博客参考的文档我在下方就写了一个，因为遇到问题会百度，看过之后就关闭了，而且参考了很多。所以就不一一列举出来了。\n\n<font color=red>**抖音大佬**：大猿向前冲，抖音号：dyxqc。微信号我就不爆了</font>\n\nTypora 官网 windows 64位程序下载地址：[https://www.typora.io/#windows](https://www.typora.io/#windows)\n\n搭建博客参考文档：[https://www.jianshu.com/p/189fd945f38f](https://www.jianshu.com/p/189fd945f38f)\n\n博客使用的模板：[https://liuyib.github.io/reprint/](https://liuyib.github.io/reprint/)\n\n模板 github 地址：[https://github.com/liuyib/hexo-theme-stun](https://github.com/liuyib/hexo-theme-stun)\n\n模板使用文档：[https://liuyib.github.io/hexo-theme-stun/zh-CN/](https://liuyib.github.io/hexo-theme-stun/zh-CN/)\n"}]